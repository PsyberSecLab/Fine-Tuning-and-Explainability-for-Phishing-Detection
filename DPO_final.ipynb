{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ff6ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA RTX A5000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d15e66310347a391b44c89cb0411af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd87418de16443be9175fc37d63e1e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/users/skuikel/anaconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/users/skuikel/anaconda3/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/8 | Step 0/600] - Loss: 7.1610\n",
      "[Epoch 1/8 | Step 10/600] - Loss: 4.7485\n",
      "[Epoch 1/8 | Step 20/600] - Loss: 4.7732\n",
      "[Epoch 1/8 | Step 30/600] - Loss: 4.3574\n",
      "[Epoch 1/8 | Step 40/600] - Loss: 3.9310\n",
      "[Epoch 1/8 | Step 50/600] - Loss: 4.1771\n",
      "[Epoch 1/8 | Step 60/600] - Loss: 4.3604\n",
      "[Epoch 1/8 | Step 70/600] - Loss: 4.3687\n",
      "[Epoch 1/8 | Step 80/600] - Loss: 4.3960\n",
      "[Epoch 1/8 | Step 90/600] - Loss: 4.4058\n",
      "[Epoch 1/8 | Step 100/600] - Loss: 4.4079\n",
      "[Epoch 1/8 | Step 110/600] - Loss: 4.4454\n",
      "[Epoch 1/8 | Step 120/600] - Loss: 4.3950\n",
      "[Epoch 1/8 | Step 130/600] - Loss: 4.4077\n",
      "[Epoch 1/8 | Step 140/600] - Loss: 4.2805\n",
      "[Epoch 1/8 | Step 150/600] - Loss: 4.2940\n",
      "[Epoch 1/8 | Step 160/600] - Loss: 4.3175\n",
      "[Epoch 1/8 | Step 170/600] - Loss: 4.2830\n",
      "[Epoch 1/8 | Step 180/600] - Loss: 4.1601\n",
      "[Epoch 1/8 | Step 190/600] - Loss: 4.1684\n",
      "[Epoch 1/8 | Step 200/600] - Loss: 4.0842\n",
      "[Epoch 1/8 | Step 210/600] - Loss: 3.9931\n",
      "[Epoch 1/8 | Step 220/600] - Loss: 4.0245\n",
      "[Epoch 1/8 | Step 230/600] - Loss: 4.0657\n",
      "[Epoch 1/8 | Step 240/600] - Loss: 4.0987\n",
      "[Epoch 1/8 | Step 250/600] - Loss: 4.1511\n",
      "[Epoch 1/8 | Step 260/600] - Loss: 4.0919\n",
      "[Epoch 1/8 | Step 270/600] - Loss: 4.0771\n",
      "[Epoch 1/8 | Step 280/600] - Loss: 4.0971\n",
      "[Epoch 1/8 | Step 290/600] - Loss: 4.0691\n",
      "[Epoch 1/8 | Step 300/600] - Loss: 4.0609\n",
      "[Epoch 1/8 | Step 310/600] - Loss: 4.0382\n",
      "[Epoch 1/8 | Step 320/600] - Loss: 4.0325\n",
      "[Epoch 1/8 | Step 330/600] - Loss: 3.9959\n",
      "[Epoch 1/8 | Step 340/600] - Loss: 3.9901\n",
      "[Epoch 1/8 | Step 350/600] - Loss: 4.0012\n",
      "[Epoch 1/8 | Step 360/600] - Loss: 3.9756\n",
      "[Epoch 1/8 | Step 370/600] - Loss: 3.9618\n",
      "[Epoch 1/8 | Step 380/600] - Loss: 3.9883\n",
      "[Epoch 1/8 | Step 390/600] - Loss: 3.9530\n",
      "[Epoch 1/8 | Step 400/600] - Loss: 3.9717\n",
      "[Epoch 1/8 | Step 410/600] - Loss: 3.9494\n",
      "[Epoch 1/8 | Step 420/600] - Loss: 3.9303\n",
      "[Epoch 1/8 | Step 430/600] - Loss: 3.8844\n",
      "[Epoch 1/8 | Step 440/600] - Loss: 3.8707\n",
      "[Epoch 1/8 | Step 450/600] - Loss: 3.8737\n",
      "[Epoch 1/8 | Step 460/600] - Loss: 3.8573\n",
      "[Epoch 1/8 | Step 470/600] - Loss: 3.8212\n",
      "[Epoch 1/8 | Step 480/600] - Loss: 3.8024\n",
      "[Epoch 1/8 | Step 490/600] - Loss: 3.7690\n",
      "[Epoch 1/8 | Step 500/600] - Loss: 3.7630\n",
      "[Epoch 1/8 | Step 510/600] - Loss: 3.7599\n",
      "[Epoch 1/8 | Step 520/600] - Loss: 3.7516\n",
      "[Epoch 1/8 | Step 530/600] - Loss: 3.7597\n",
      "[Epoch 1/8 | Step 540/600] - Loss: 3.7438\n",
      "[Epoch 1/8 | Step 550/600] - Loss: 3.7133\n",
      "[Epoch 1/8 | Step 560/600] - Loss: 3.7017\n",
      "[Epoch 1/8 | Step 570/600] - Loss: 3.6827\n",
      "[Epoch 1/8 | Step 580/600] - Loss: 3.6648\n",
      "[Epoch 1/8 | Step 590/600] - Loss: 3.6645\n",
      "Epoch 1/8 - Avg Train Loss: 3.6570, Val Loss: 2.8847\n",
      "[Epoch 2/8 | Step 0/600] - Loss: 2.9680\n",
      "[Epoch 2/8 | Step 10/600] - Loss: 2.7954\n",
      "[Epoch 2/8 | Step 20/600] - Loss: 2.8174\n",
      "[Epoch 2/8 | Step 30/600] - Loss: 3.2073\n",
      "[Epoch 2/8 | Step 40/600] - Loss: 3.1486\n",
      "[Epoch 2/8 | Step 50/600] - Loss: 2.9515\n",
      "[Epoch 2/8 | Step 60/600] - Loss: 3.0059\n",
      "[Epoch 2/8 | Step 70/600] - Loss: 3.0401\n",
      "[Epoch 2/8 | Step 80/600] - Loss: 2.8784\n",
      "[Epoch 2/8 | Step 90/600] - Loss: 2.9332\n",
      "[Epoch 2/8 | Step 100/600] - Loss: 2.9007\n",
      "[Epoch 2/8 | Step 110/600] - Loss: 2.9610\n",
      "[Epoch 2/8 | Step 120/600] - Loss: 3.0846\n",
      "[Epoch 2/8 | Step 130/600] - Loss: 3.0043\n",
      "[Epoch 2/8 | Step 140/600] - Loss: 3.0240\n",
      "[Epoch 2/8 | Step 150/600] - Loss: 2.9792\n",
      "[Epoch 2/8 | Step 160/600] - Loss: 2.9261\n",
      "[Epoch 2/8 | Step 170/600] - Loss: 2.8666\n",
      "[Epoch 2/8 | Step 180/600] - Loss: 2.8824\n",
      "[Epoch 2/8 | Step 190/600] - Loss: 2.8927\n",
      "[Epoch 2/8 | Step 200/600] - Loss: 2.8356\n",
      "[Epoch 2/8 | Step 210/600] - Loss: 2.8066\n",
      "[Epoch 2/8 | Step 220/600] - Loss: 2.7720\n",
      "[Epoch 2/8 | Step 230/600] - Loss: 2.7630\n",
      "[Epoch 2/8 | Step 240/600] - Loss: 2.8091\n",
      "[Epoch 2/8 | Step 250/600] - Loss: 2.8047\n",
      "[Epoch 2/8 | Step 260/600] - Loss: 2.8100\n",
      "[Epoch 2/8 | Step 270/600] - Loss: 2.7907\n",
      "[Epoch 2/8 | Step 280/600] - Loss: 2.7811\n",
      "[Epoch 2/8 | Step 290/600] - Loss: 2.7956\n",
      "[Epoch 2/8 | Step 300/600] - Loss: 2.7829\n",
      "[Epoch 2/8 | Step 310/600] - Loss: 2.7534\n",
      "[Epoch 2/8 | Step 320/600] - Loss: 2.7281\n",
      "[Epoch 2/8 | Step 330/600] - Loss: 2.6920\n",
      "[Epoch 2/8 | Step 340/600] - Loss: 2.6663\n",
      "[Epoch 2/8 | Step 350/600] - Loss: 2.6324\n",
      "[Epoch 2/8 | Step 360/600] - Loss: 2.6266\n",
      "[Epoch 2/8 | Step 370/600] - Loss: 2.6182\n",
      "[Epoch 2/8 | Step 380/600] - Loss: 2.6136\n",
      "[Epoch 2/8 | Step 390/600] - Loss: 2.6036\n",
      "[Epoch 2/8 | Step 400/600] - Loss: 2.6194\n",
      "[Epoch 2/8 | Step 410/600] - Loss: 2.6119\n",
      "[Epoch 2/8 | Step 420/600] - Loss: 2.6318\n",
      "[Epoch 2/8 | Step 430/600] - Loss: 2.6280\n",
      "[Epoch 2/8 | Step 440/600] - Loss: 2.6274\n",
      "[Epoch 2/8 | Step 450/600] - Loss: 2.6208\n",
      "[Epoch 2/8 | Step 460/600] - Loss: 2.6382\n",
      "[Epoch 2/8 | Step 470/600] - Loss: 2.6331\n",
      "[Epoch 2/8 | Step 480/600] - Loss: 2.6316\n",
      "[Epoch 2/8 | Step 490/600] - Loss: 2.6368\n",
      "[Epoch 2/8 | Step 500/600] - Loss: 2.6382\n",
      "[Epoch 2/8 | Step 510/600] - Loss: 2.6306\n",
      "[Epoch 2/8 | Step 520/600] - Loss: 2.6454\n",
      "[Epoch 2/8 | Step 530/600] - Loss: 2.6230\n",
      "[Epoch 2/8 | Step 540/600] - Loss: 2.6228\n",
      "[Epoch 2/8 | Step 550/600] - Loss: 2.6116\n",
      "[Epoch 2/8 | Step 560/600] - Loss: 2.6263\n",
      "[Epoch 2/8 | Step 570/600] - Loss: 2.6006\n",
      "[Epoch 2/8 | Step 580/600] - Loss: 2.5940\n",
      "[Epoch 2/8 | Step 590/600] - Loss: 2.5830\n",
      "Epoch 2/8 - Avg Train Loss: 2.5832, Val Loss: 2.4870\n",
      "[Epoch 3/8 | Step 0/600] - Loss: 2.0107\n",
      "[Epoch 3/8 | Step 10/600] - Loss: 2.8517\n",
      "[Epoch 3/8 | Step 20/600] - Loss: 2.7114\n",
      "[Epoch 3/8 | Step 30/600] - Loss: 2.8398\n",
      "[Epoch 3/8 | Step 40/600] - Loss: 2.8149\n",
      "[Epoch 3/8 | Step 50/600] - Loss: 2.7990\n",
      "[Epoch 3/8 | Step 60/600] - Loss: 2.9714\n",
      "[Epoch 3/8 | Step 70/600] - Loss: 2.8972\n",
      "[Epoch 3/8 | Step 80/600] - Loss: 2.7504\n",
      "[Epoch 3/8 | Step 90/600] - Loss: 2.7927\n",
      "[Epoch 3/8 | Step 100/600] - Loss: 2.7793\n",
      "[Epoch 3/8 | Step 110/600] - Loss: 2.6927\n",
      "[Epoch 3/8 | Step 120/600] - Loss: 2.6163\n",
      "[Epoch 3/8 | Step 130/600] - Loss: 2.5331\n",
      "[Epoch 3/8 | Step 140/600] - Loss: 2.5349\n",
      "[Epoch 3/8 | Step 150/600] - Loss: 2.4734\n",
      "[Epoch 3/8 | Step 160/600] - Loss: 2.4218\n",
      "[Epoch 3/8 | Step 170/600] - Loss: 2.3519\n",
      "[Epoch 3/8 | Step 180/600] - Loss: 2.3959\n",
      "[Epoch 3/8 | Step 190/600] - Loss: 2.4131\n",
      "[Epoch 3/8 | Step 200/600] - Loss: 2.4316\n",
      "[Epoch 3/8 | Step 210/600] - Loss: 2.4168\n",
      "[Epoch 3/8 | Step 220/600] - Loss: 2.4445\n",
      "[Epoch 3/8 | Step 230/600] - Loss: 2.4681\n",
      "[Epoch 3/8 | Step 240/600] - Loss: 2.4757\n",
      "[Epoch 3/8 | Step 250/600] - Loss: 2.4598\n",
      "[Epoch 3/8 | Step 260/600] - Loss: 2.4441\n",
      "[Epoch 3/8 | Step 270/600] - Loss: 2.4149\n",
      "[Epoch 3/8 | Step 280/600] - Loss: 2.4006\n",
      "[Epoch 3/8 | Step 290/600] - Loss: 2.4222\n",
      "[Epoch 3/8 | Step 300/600] - Loss: 2.4251\n",
      "[Epoch 3/8 | Step 310/600] - Loss: 2.4019\n",
      "[Epoch 3/8 | Step 320/600] - Loss: 2.4449\n",
      "[Epoch 3/8 | Step 330/600] - Loss: 2.4156\n",
      "[Epoch 3/8 | Step 340/600] - Loss: 2.4294\n",
      "[Epoch 3/8 | Step 350/600] - Loss: 2.4373\n",
      "[Epoch 3/8 | Step 360/600] - Loss: 2.4122\n",
      "[Epoch 3/8 | Step 370/600] - Loss: 2.3870\n",
      "[Epoch 3/8 | Step 380/600] - Loss: 2.3730\n",
      "[Epoch 3/8 | Step 390/600] - Loss: 2.3676\n",
      "[Epoch 3/8 | Step 400/600] - Loss: 2.3779\n",
      "[Epoch 3/8 | Step 410/600] - Loss: 2.3780\n",
      "[Epoch 3/8 | Step 420/600] - Loss: 2.3845\n",
      "[Epoch 3/8 | Step 430/600] - Loss: 2.3663\n",
      "[Epoch 3/8 | Step 440/600] - Loss: 2.3598\n",
      "[Epoch 3/8 | Step 450/600] - Loss: 2.3344\n",
      "[Epoch 3/8 | Step 460/600] - Loss: 2.3359\n",
      "[Epoch 3/8 | Step 470/600] - Loss: 2.3596\n",
      "[Epoch 3/8 | Step 480/600] - Loss: 2.3709\n",
      "[Epoch 3/8 | Step 490/600] - Loss: 2.3668\n",
      "[Epoch 3/8 | Step 500/600] - Loss: 2.3458\n",
      "[Epoch 3/8 | Step 510/600] - Loss: 2.3296\n",
      "[Epoch 3/8 | Step 520/600] - Loss: 2.3372\n",
      "[Epoch 3/8 | Step 530/600] - Loss: 2.3432\n",
      "[Epoch 3/8 | Step 540/600] - Loss: 2.3516\n",
      "[Epoch 3/8 | Step 550/600] - Loss: 2.3508\n",
      "[Epoch 3/8 | Step 560/600] - Loss: 2.3405\n",
      "[Epoch 3/8 | Step 570/600] - Loss: 2.3327\n",
      "[Epoch 3/8 | Step 580/600] - Loss: 2.3221\n",
      "[Epoch 3/8 | Step 590/600] - Loss: 2.3257\n",
      "Epoch 3/8 - Avg Train Loss: 2.3226, Val Loss: 2.2425\n",
      "[Epoch 4/8 | Step 0/600] - Loss: 0.4344\n",
      "[Epoch 4/8 | Step 10/600] - Loss: 1.3993\n",
      "[Epoch 4/8 | Step 20/600] - Loss: 1.6207\n",
      "[Epoch 4/8 | Step 30/600] - Loss: 1.4907\n",
      "[Epoch 4/8 | Step 40/600] - Loss: 1.9319\n",
      "[Epoch 4/8 | Step 50/600] - Loss: 2.2199\n",
      "[Epoch 4/8 | Step 60/600] - Loss: 2.2350\n",
      "[Epoch 4/8 | Step 70/600] - Loss: 2.2774\n",
      "[Epoch 4/8 | Step 80/600] - Loss: 2.1627\n",
      "[Epoch 4/8 | Step 90/600] - Loss: 2.2212\n",
      "[Epoch 4/8 | Step 100/600] - Loss: 2.1407\n",
      "[Epoch 4/8 | Step 110/600] - Loss: 2.1813\n",
      "[Epoch 4/8 | Step 120/600] - Loss: 2.2381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/8 | Step 130/600] - Loss: 2.2164\n",
      "[Epoch 4/8 | Step 140/600] - Loss: 2.2823\n",
      "[Epoch 4/8 | Step 150/600] - Loss: 2.3189\n",
      "[Epoch 4/8 | Step 160/600] - Loss: 2.3333\n",
      "[Epoch 4/8 | Step 170/600] - Loss: 2.2912\n",
      "[Epoch 4/8 | Step 180/600] - Loss: 2.3598\n",
      "[Epoch 4/8 | Step 190/600] - Loss: 2.4061\n",
      "[Epoch 4/8 | Step 200/600] - Loss: 2.3701\n",
      "[Epoch 4/8 | Step 210/600] - Loss: 2.3815\n",
      "[Epoch 4/8 | Step 220/600] - Loss: 2.3756\n",
      "[Epoch 4/8 | Step 230/600] - Loss: 2.3394\n",
      "[Epoch 4/8 | Step 240/600] - Loss: 2.3399\n",
      "[Epoch 4/8 | Step 250/600] - Loss: 2.3257\n",
      "[Epoch 4/8 | Step 260/600] - Loss: 2.3078\n",
      "[Epoch 4/8 | Step 270/600] - Loss: 2.3147\n",
      "[Epoch 4/8 | Step 280/600] - Loss: 2.3165\n",
      "[Epoch 4/8 | Step 290/600] - Loss: 2.3023\n",
      "[Epoch 4/8 | Step 300/600] - Loss: 2.2862\n",
      "[Epoch 4/8 | Step 310/600] - Loss: 2.2724\n",
      "[Epoch 4/8 | Step 320/600] - Loss: 2.2588\n",
      "[Epoch 4/8 | Step 330/600] - Loss: 2.2219\n",
      "[Epoch 4/8 | Step 340/600] - Loss: 2.2035\n",
      "[Epoch 4/8 | Step 350/600] - Loss: 2.1889\n",
      "[Epoch 4/8 | Step 360/600] - Loss: 2.1798\n",
      "[Epoch 4/8 | Step 370/600] - Loss: 2.1743\n",
      "[Epoch 4/8 | Step 380/600] - Loss: 2.1548\n",
      "[Epoch 4/8 | Step 390/600] - Loss: 2.1548\n",
      "[Epoch 4/8 | Step 400/600] - Loss: 2.1640\n",
      "[Epoch 4/8 | Step 410/600] - Loss: 2.1906\n",
      "[Epoch 4/8 | Step 420/600] - Loss: 2.1889\n",
      "[Epoch 4/8 | Step 430/600] - Loss: 2.1748\n",
      "[Epoch 4/8 | Step 440/600] - Loss: 2.1656\n",
      "[Epoch 4/8 | Step 450/600] - Loss: 2.1981\n",
      "[Epoch 4/8 | Step 460/600] - Loss: 2.2128\n",
      "[Epoch 4/8 | Step 470/600] - Loss: 2.1958\n",
      "[Epoch 4/8 | Step 480/600] - Loss: 2.1914\n",
      "[Epoch 4/8 | Step 490/600] - Loss: 2.1987\n",
      "[Epoch 4/8 | Step 500/600] - Loss: 2.1947\n",
      "[Epoch 4/8 | Step 510/600] - Loss: 2.1898\n",
      "[Epoch 4/8 | Step 520/600] - Loss: 2.1943\n",
      "[Epoch 4/8 | Step 530/600] - Loss: 2.1796\n",
      "[Epoch 4/8 | Step 540/600] - Loss: 2.1626\n",
      "[Epoch 4/8 | Step 550/600] - Loss: 2.1520\n",
      "[Epoch 4/8 | Step 560/600] - Loss: 2.1565\n",
      "[Epoch 4/8 | Step 570/600] - Loss: 2.1451\n",
      "[Epoch 4/8 | Step 580/600] - Loss: 2.1502\n",
      "[Epoch 4/8 | Step 590/600] - Loss: 2.1444\n",
      "Epoch 4/8 - Avg Train Loss: 2.1516, Val Loss: 2.1326\n",
      "[Epoch 5/8 | Step 0/600] - Loss: 3.8760\n",
      "[Epoch 5/8 | Step 10/600] - Loss: 1.7049\n",
      "[Epoch 5/8 | Step 20/600] - Loss: 2.2077\n",
      "[Epoch 5/8 | Step 30/600] - Loss: 2.1145\n",
      "[Epoch 5/8 | Step 40/600] - Loss: 1.9776\n",
      "[Epoch 5/8 | Step 50/600] - Loss: 1.9822\n",
      "[Epoch 5/8 | Step 60/600] - Loss: 1.9938\n",
      "[Epoch 5/8 | Step 70/600] - Loss: 1.9126\n",
      "[Epoch 5/8 | Step 80/600] - Loss: 1.8306\n",
      "[Epoch 5/8 | Step 90/600] - Loss: 1.9244\n",
      "[Epoch 5/8 | Step 100/600] - Loss: 2.0151\n",
      "[Epoch 5/8 | Step 110/600] - Loss: 2.1040\n",
      "[Epoch 5/8 | Step 120/600] - Loss: 2.0784\n",
      "[Epoch 5/8 | Step 130/600] - Loss: 2.1574\n",
      "[Epoch 5/8 | Step 140/600] - Loss: 2.2021\n",
      "[Epoch 5/8 | Step 150/600] - Loss: 2.2265\n",
      "[Epoch 5/8 | Step 160/600] - Loss: 2.2267\n",
      "[Epoch 5/8 | Step 170/600] - Loss: 2.2101\n",
      "[Epoch 5/8 | Step 180/600] - Loss: 2.2306\n",
      "[Epoch 5/8 | Step 190/600] - Loss: 2.1776\n",
      "[Epoch 5/8 | Step 200/600] - Loss: 2.1667\n",
      "[Epoch 5/8 | Step 210/600] - Loss: 2.2108\n",
      "[Epoch 5/8 | Step 220/600] - Loss: 2.2147\n",
      "[Epoch 5/8 | Step 230/600] - Loss: 2.1857\n",
      "[Epoch 5/8 | Step 240/600] - Loss: 2.1678\n",
      "[Epoch 5/8 | Step 250/600] - Loss: 2.2007\n",
      "[Epoch 5/8 | Step 260/600] - Loss: 2.1753\n",
      "[Epoch 5/8 | Step 270/600] - Loss: 2.1565\n",
      "[Epoch 5/8 | Step 280/600] - Loss: 2.1473\n",
      "[Epoch 5/8 | Step 290/600] - Loss: 2.1213\n",
      "[Epoch 5/8 | Step 300/600] - Loss: 2.1210\n",
      "[Epoch 5/8 | Step 310/600] - Loss: 2.1029\n",
      "[Epoch 5/8 | Step 320/600] - Loss: 2.1230\n",
      "[Epoch 5/8 | Step 330/600] - Loss: 2.1006\n",
      "[Epoch 5/8 | Step 340/600] - Loss: 2.1013\n",
      "[Epoch 5/8 | Step 350/600] - Loss: 2.1122\n",
      "[Epoch 5/8 | Step 360/600] - Loss: 2.0903\n",
      "[Epoch 5/8 | Step 370/600] - Loss: 2.0874\n",
      "[Epoch 5/8 | Step 380/600] - Loss: 2.1271\n",
      "[Epoch 5/8 | Step 390/600] - Loss: 2.0985\n",
      "[Epoch 5/8 | Step 400/600] - Loss: 2.0934\n",
      "[Epoch 5/8 | Step 410/600] - Loss: 2.0765\n",
      "[Epoch 5/8 | Step 420/600] - Loss: 2.0597\n",
      "[Epoch 5/8 | Step 430/600] - Loss: 2.0417\n",
      "[Epoch 5/8 | Step 440/600] - Loss: 2.0426\n",
      "[Epoch 5/8 | Step 450/600] - Loss: 2.0250\n",
      "[Epoch 5/8 | Step 460/600] - Loss: 2.0226\n",
      "[Epoch 5/8 | Step 470/600] - Loss: 2.0273\n",
      "[Epoch 5/8 | Step 480/600] - Loss: 2.0127\n",
      "[Epoch 5/8 | Step 490/600] - Loss: 2.0191\n",
      "[Epoch 5/8 | Step 500/600] - Loss: 2.0154\n",
      "[Epoch 5/8 | Step 510/600] - Loss: 2.0210\n",
      "[Epoch 5/8 | Step 520/600] - Loss: 2.0200\n",
      "[Epoch 5/8 | Step 530/600] - Loss: 2.0234\n",
      "[Epoch 5/8 | Step 540/600] - Loss: 2.0546\n",
      "[Epoch 5/8 | Step 550/600] - Loss: 2.0592\n",
      "[Epoch 5/8 | Step 560/600] - Loss: 2.0536\n",
      "[Epoch 5/8 | Step 570/600] - Loss: 2.0509\n",
      "[Epoch 5/8 | Step 580/600] - Loss: 2.0346\n",
      "[Epoch 5/8 | Step 590/600] - Loss: 2.0378\n",
      "Epoch 5/8 - Avg Train Loss: 2.0481, Val Loss: 2.0687\n",
      "[Epoch 6/8 | Step 0/600] - Loss: 1.2530\n",
      "[Epoch 6/8 | Step 10/600] - Loss: 1.9807\n",
      "[Epoch 6/8 | Step 20/600] - Loss: 1.9592\n",
      "[Epoch 6/8 | Step 30/600] - Loss: 2.0172\n",
      "[Epoch 6/8 | Step 40/600] - Loss: 1.9317\n",
      "[Epoch 6/8 | Step 50/600] - Loss: 2.0160\n",
      "[Epoch 6/8 | Step 60/600] - Loss: 1.9795\n",
      "[Epoch 6/8 | Step 70/600] - Loss: 1.8915\n",
      "[Epoch 6/8 | Step 80/600] - Loss: 1.8340\n",
      "[Epoch 6/8 | Step 90/600] - Loss: 1.8492\n",
      "[Epoch 6/8 | Step 100/600] - Loss: 1.8143\n",
      "[Epoch 6/8 | Step 110/600] - Loss: 1.8149\n",
      "[Epoch 6/8 | Step 120/600] - Loss: 1.8180\n",
      "[Epoch 6/8 | Step 130/600] - Loss: 1.8276\n",
      "[Epoch 6/8 | Step 140/600] - Loss: 1.8638\n",
      "[Epoch 6/8 | Step 150/600] - Loss: 1.8429\n",
      "[Epoch 6/8 | Step 160/600] - Loss: 1.8741\n",
      "[Epoch 6/8 | Step 170/600] - Loss: 1.8707\n",
      "[Epoch 6/8 | Step 180/600] - Loss: 1.8256\n",
      "[Epoch 6/8 | Step 190/600] - Loss: 1.8205\n",
      "[Epoch 6/8 | Step 200/600] - Loss: 1.8165\n",
      "[Epoch 6/8 | Step 210/600] - Loss: 1.8310\n",
      "[Epoch 6/8 | Step 220/600] - Loss: 1.8504\n",
      "[Epoch 6/8 | Step 230/600] - Loss: 1.8871\n",
      "[Epoch 6/8 | Step 240/600] - Loss: 1.8993\n",
      "[Epoch 6/8 | Step 250/600] - Loss: 1.9322\n",
      "[Epoch 6/8 | Step 260/600] - Loss: 1.9376\n",
      "[Epoch 6/8 | Step 270/600] - Loss: 1.9651\n",
      "[Epoch 6/8 | Step 280/600] - Loss: 1.9819\n",
      "[Epoch 6/8 | Step 290/600] - Loss: 1.9710\n",
      "[Epoch 6/8 | Step 300/600] - Loss: 1.9808\n",
      "[Epoch 6/8 | Step 310/600] - Loss: 1.9848\n",
      "[Epoch 6/8 | Step 320/600] - Loss: 1.9888\n",
      "[Epoch 6/8 | Step 330/600] - Loss: 2.0052\n",
      "[Epoch 6/8 | Step 340/600] - Loss: 1.9753\n",
      "[Epoch 6/8 | Step 350/600] - Loss: 1.9578\n",
      "[Epoch 6/8 | Step 360/600] - Loss: 1.9556\n",
      "[Epoch 6/8 | Step 370/600] - Loss: 1.9432\n",
      "[Epoch 6/8 | Step 380/600] - Loss: 1.9378\n",
      "[Epoch 6/8 | Step 390/600] - Loss: 1.9341\n",
      "[Epoch 6/8 | Step 400/600] - Loss: 1.9404\n",
      "[Epoch 6/8 | Step 410/600] - Loss: 1.9432\n",
      "[Epoch 6/8 | Step 420/600] - Loss: 1.9335\n",
      "[Epoch 6/8 | Step 430/600] - Loss: 1.9499\n",
      "[Epoch 6/8 | Step 440/600] - Loss: 1.9719\n",
      "[Epoch 6/8 | Step 450/600] - Loss: 1.9885\n",
      "[Epoch 6/8 | Step 460/600] - Loss: 1.9739\n",
      "[Epoch 6/8 | Step 470/600] - Loss: 1.9763\n",
      "[Epoch 6/8 | Step 480/600] - Loss: 1.9648\n",
      "[Epoch 6/8 | Step 490/600] - Loss: 1.9841\n",
      "[Epoch 6/8 | Step 500/600] - Loss: 1.9872\n",
      "[Epoch 6/8 | Step 510/600] - Loss: 1.9969\n",
      "[Epoch 6/8 | Step 520/600] - Loss: 1.9861\n",
      "[Epoch 6/8 | Step 530/600] - Loss: 2.0025\n",
      "[Epoch 6/8 | Step 540/600] - Loss: 2.0000\n",
      "[Epoch 6/8 | Step 550/600] - Loss: 2.0144\n",
      "[Epoch 6/8 | Step 560/600] - Loss: 2.0059\n",
      "[Epoch 6/8 | Step 570/600] - Loss: 2.0030\n",
      "[Epoch 6/8 | Step 580/600] - Loss: 1.9972\n",
      "[Epoch 6/8 | Step 590/600] - Loss: 1.9976\n",
      "Epoch 6/8 - Avg Train Loss: 1.9944, Val Loss: 2.0311\n",
      "[Epoch 7/8 | Step 0/600] - Loss: 1.5646\n",
      "[Epoch 7/8 | Step 10/600] - Loss: 1.1347\n",
      "[Epoch 7/8 | Step 20/600] - Loss: 1.9659\n",
      "[Epoch 7/8 | Step 30/600] - Loss: 1.7387\n",
      "[Epoch 7/8 | Step 40/600] - Loss: 1.8461\n",
      "[Epoch 7/8 | Step 50/600] - Loss: 1.8560\n",
      "[Epoch 7/8 | Step 60/600] - Loss: 1.8089\n",
      "[Epoch 7/8 | Step 70/600] - Loss: 1.8457\n",
      "[Epoch 7/8 | Step 80/600] - Loss: 1.9066\n",
      "[Epoch 7/8 | Step 90/600] - Loss: 1.8739\n",
      "[Epoch 7/8 | Step 100/600] - Loss: 1.9258\n",
      "[Epoch 7/8 | Step 110/600] - Loss: 2.0178\n",
      "[Epoch 7/8 | Step 120/600] - Loss: 1.9963\n",
      "[Epoch 7/8 | Step 130/600] - Loss: 1.9898\n",
      "[Epoch 7/8 | Step 140/600] - Loss: 1.9727\n",
      "[Epoch 7/8 | Step 150/600] - Loss: 1.9757\n",
      "[Epoch 7/8 | Step 160/600] - Loss: 1.9709\n",
      "[Epoch 7/8 | Step 170/600] - Loss: 1.9324\n",
      "[Epoch 7/8 | Step 180/600] - Loss: 1.9486\n",
      "[Epoch 7/8 | Step 190/600] - Loss: 1.9265\n",
      "[Epoch 7/8 | Step 200/600] - Loss: 1.9250\n",
      "[Epoch 7/8 | Step 210/600] - Loss: 1.9221\n",
      "[Epoch 7/8 | Step 220/600] - Loss: 1.9047\n",
      "[Epoch 7/8 | Step 230/600] - Loss: 1.8984\n",
      "[Epoch 7/8 | Step 240/600] - Loss: 1.8913\n",
      "[Epoch 7/8 | Step 250/600] - Loss: 1.9248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/8 | Step 260/600] - Loss: 1.9099\n",
      "[Epoch 7/8 | Step 270/600] - Loss: 1.9065\n",
      "[Epoch 7/8 | Step 280/600] - Loss: 1.9100\n",
      "[Epoch 7/8 | Step 290/600] - Loss: 1.9284\n",
      "[Epoch 7/8 | Step 300/600] - Loss: 1.9345\n",
      "[Epoch 7/8 | Step 310/600] - Loss: 1.9246\n",
      "[Epoch 7/8 | Step 320/600] - Loss: 1.9375\n",
      "[Epoch 7/8 | Step 330/600] - Loss: 1.9442\n",
      "[Epoch 7/8 | Step 340/600] - Loss: 1.9410\n",
      "[Epoch 7/8 | Step 350/600] - Loss: 1.9550\n",
      "[Epoch 7/8 | Step 360/600] - Loss: 1.9500\n",
      "[Epoch 7/8 | Step 370/600] - Loss: 1.9653\n",
      "[Epoch 7/8 | Step 380/600] - Loss: 1.9542\n",
      "[Epoch 7/8 | Step 390/600] - Loss: 1.9595\n",
      "[Epoch 7/8 | Step 400/600] - Loss: 1.9346\n",
      "[Epoch 7/8 | Step 410/600] - Loss: 1.9277\n",
      "[Epoch 7/8 | Step 420/600] - Loss: 1.9251\n",
      "[Epoch 7/8 | Step 430/600] - Loss: 1.9455\n",
      "[Epoch 7/8 | Step 440/600] - Loss: 1.9610\n",
      "[Epoch 7/8 | Step 450/600] - Loss: 1.9624\n",
      "[Epoch 7/8 | Step 460/600] - Loss: 1.9748\n",
      "[Epoch 7/8 | Step 470/600] - Loss: 1.9754\n",
      "[Epoch 7/8 | Step 480/600] - Loss: 1.9762\n",
      "[Epoch 7/8 | Step 490/600] - Loss: 1.9806\n",
      "[Epoch 7/8 | Step 500/600] - Loss: 2.0045\n",
      "[Epoch 7/8 | Step 510/600] - Loss: 2.0035\n",
      "[Epoch 7/8 | Step 520/600] - Loss: 1.9930\n",
      "[Epoch 7/8 | Step 530/600] - Loss: 1.9787\n",
      "[Epoch 7/8 | Step 540/600] - Loss: 1.9752\n",
      "[Epoch 7/8 | Step 550/600] - Loss: 1.9739\n",
      "[Epoch 7/8 | Step 560/600] - Loss: 1.9899\n",
      "[Epoch 7/8 | Step 570/600] - Loss: 1.9810\n",
      "[Epoch 7/8 | Step 580/600] - Loss: 1.9628\n",
      "[Epoch 7/8 | Step 590/600] - Loss: 1.9599\n",
      "Epoch 7/8 - Avg Train Loss: 1.9750, Val Loss: 2.0028\n",
      "[Epoch 8/8 | Step 0/600] - Loss: 0.6495\n",
      "[Epoch 8/8 | Step 10/600] - Loss: 1.5627\n",
      "[Epoch 8/8 | Step 20/600] - Loss: 2.0404\n",
      "[Epoch 8/8 | Step 30/600] - Loss: 2.0535\n",
      "[Epoch 8/8 | Step 40/600] - Loss: 2.0375\n",
      "[Epoch 8/8 | Step 50/600] - Loss: 2.0299\n",
      "[Epoch 8/8 | Step 60/600] - Loss: 1.9776\n",
      "[Epoch 8/8 | Step 70/600] - Loss: 1.7877\n",
      "[Epoch 8/8 | Step 80/600] - Loss: 1.7197\n",
      "[Epoch 8/8 | Step 90/600] - Loss: 1.7733\n",
      "[Epoch 8/8 | Step 100/600] - Loss: 1.8016\n",
      "[Epoch 8/8 | Step 110/600] - Loss: 1.8072\n",
      "[Epoch 8/8 | Step 120/600] - Loss: 1.7808\n",
      "[Epoch 8/8 | Step 130/600] - Loss: 1.7723\n",
      "[Epoch 8/8 | Step 140/600] - Loss: 1.7906\n",
      "[Epoch 8/8 | Step 150/600] - Loss: 1.8290\n",
      "[Epoch 8/8 | Step 160/600] - Loss: 1.8428\n",
      "[Epoch 8/8 | Step 170/600] - Loss: 1.8892\n",
      "[Epoch 8/8 | Step 180/600] - Loss: 1.8911\n",
      "[Epoch 8/8 | Step 190/600] - Loss: 1.8580\n",
      "[Epoch 8/8 | Step 200/600] - Loss: 1.8831\n",
      "[Epoch 8/8 | Step 210/600] - Loss: 1.8946\n",
      "[Epoch 8/8 | Step 220/600] - Loss: 1.9196\n",
      "[Epoch 8/8 | Step 230/600] - Loss: 1.9117\n",
      "[Epoch 8/8 | Step 240/600] - Loss: 1.8769\n",
      "[Epoch 8/8 | Step 250/600] - Loss: 1.8408\n",
      "[Epoch 8/8 | Step 260/600] - Loss: 1.8633\n",
      "[Epoch 8/8 | Step 270/600] - Loss: 1.8462\n",
      "[Epoch 8/8 | Step 280/600] - Loss: 1.8472\n",
      "[Epoch 8/8 | Step 290/600] - Loss: 1.8278\n",
      "[Epoch 8/8 | Step 300/600] - Loss: 1.8552\n",
      "[Epoch 8/8 | Step 310/600] - Loss: 1.8291\n",
      "[Epoch 8/8 | Step 320/600] - Loss: 1.8530\n",
      "[Epoch 8/8 | Step 330/600] - Loss: 1.8535\n",
      "[Epoch 8/8 | Step 340/600] - Loss: 1.8477\n",
      "[Epoch 8/8 | Step 350/600] - Loss: 1.8516\n",
      "[Epoch 8/8 | Step 360/600] - Loss: 1.8615\n",
      "[Epoch 8/8 | Step 370/600] - Loss: 1.8496\n",
      "[Epoch 8/8 | Step 380/600] - Loss: 1.8603\n",
      "[Epoch 8/8 | Step 390/600] - Loss: 1.8821\n",
      "[Epoch 8/8 | Step 400/600] - Loss: 1.8696\n",
      "[Epoch 8/8 | Step 410/600] - Loss: 1.8798\n",
      "[Epoch 8/8 | Step 420/600] - Loss: 1.8831\n",
      "[Epoch 8/8 | Step 430/600] - Loss: 1.8913\n",
      "[Epoch 8/8 | Step 440/600] - Loss: 1.8954\n",
      "[Epoch 8/8 | Step 450/600] - Loss: 1.9069\n",
      "[Epoch 8/8 | Step 460/600] - Loss: 1.9075\n",
      "[Epoch 8/8 | Step 470/600] - Loss: 1.9103\n",
      "[Epoch 8/8 | Step 480/600] - Loss: 1.9229\n",
      "[Epoch 8/8 | Step 490/600] - Loss: 1.9137\n",
      "[Epoch 8/8 | Step 500/600] - Loss: 1.9441\n",
      "[Epoch 8/8 | Step 510/600] - Loss: 1.9584\n",
      "[Epoch 8/8 | Step 520/600] - Loss: 1.9455\n",
      "[Epoch 8/8 | Step 530/600] - Loss: 1.9389\n",
      "[Epoch 8/8 | Step 540/600] - Loss: 1.9338\n",
      "[Epoch 8/8 | Step 550/600] - Loss: 1.9427\n",
      "[Epoch 8/8 | Step 560/600] - Loss: 1.9423\n",
      "[Epoch 8/8 | Step 570/600] - Loss: 1.9381\n",
      "[Epoch 8/8 | Step 580/600] - Loss: 1.9324\n",
      "[Epoch 8/8 | Step 590/600] - Loss: 1.9345\n",
      "Epoch 8/8 - Avg Train Loss: 1.9287, Val Loss: 1.9907\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoConfig,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from huggingface_hub import login\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    LlamaForSequenceClassification,\n",
    "    LlamaTokenizer,LlamaModel,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoConfig,\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "from huggingface_hub import login\n",
    "import bitsandbytes as bnb\n",
    "import re\n",
    "import traceback\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Set up the GPU environment and return the appropriate device.\"\"\"\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    \n",
    "  \n",
    "    torch.manual_seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    return device\n",
    "\n",
    "def setup_model_and_tokenizer(model_name, device):\n",
    "    tokenizer =  AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    model_config = AutoConfig.from_pretrained(model_name)\n",
    "    model_config.num_labels = 2\n",
    "    model_config.pad_token_id = tokenizer.pad_token_id\n",
    "    model_config.use_cache = False\n",
    "\n",
    "\n",
    "    quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "    base_model = LlamaForSequenceClassification.from_pretrained(\n",
    "        model_name, \n",
    "        config=model_config, \n",
    "        torch_dtype=torch.bfloat16, \n",
    "        quantization_config=quantization_config\n",
    "    )\n",
    "\n",
    "    lora_config = LoraConfig(r=16, lora_alpha=32, target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05, bias=\"none\", task_type=\"SEQ_CLS\")\n",
    "    model = get_peft_model(base_model, lora_config)\n",
    "    model.gradient_checkpointing_enable()\n",
    "    return model, tokenizer\n",
    "\n",
    "class PreferenceEmailDataset(Dataset):\n",
    "    def __init__(self, emails_df, tokenizer, max_length=512):\n",
    "        \"\"\"\n",
    "        Dataset to create pairs of message, preferred response, and rejected response for DPO training.\n",
    "        \"\"\"\n",
    "        self.emails_df = emails_df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.pairs = self._create_preference_pairs()\n",
    "\n",
    "    def _create_preference_pairs(self):\n",
    "        \"\"\"\n",
    "        Create pairs using emails from the dataset based on their labels.\n",
    "        \"\"\"\n",
    "        pairs = []\n",
    "        for _, selected_email in self.emails_df.iterrows():\n",
    "            selected_label = selected_email['label']\n",
    "            ham_emails = self.emails_df[self.emails_df['label'] == 0]\n",
    "            phish_emails = self.emails_df[self.emails_df['label'] == 1]\n",
    "\n",
    "            if selected_label == 1:  # Phishing email\n",
    "                preferred_email = phish_emails[phish_emails.index != selected_email.name].sample(n=1).iloc[0]\n",
    "                rejected_email = ham_emails.sample(n=1).iloc[0]\n",
    "                pairs.append({\n",
    "                    'message': selected_email,\n",
    "                    'preferred': preferred_email,\n",
    "                    'rejected': rejected_email\n",
    "                })\n",
    "            elif selected_label == 0:  # Ham email\n",
    "                preferred_email = ham_emails[ham_emails.index != selected_email.name].sample(n=1).iloc[0]\n",
    "                rejected_email = phish_emails.sample(n=1).iloc[0]\n",
    "                pairs.append({\n",
    "                    'message': selected_email,\n",
    "                    'preferred': preferred_email,\n",
    "                    'rejected': rejected_email\n",
    "                })\n",
    "\n",
    "        return pairs\n",
    "\n",
    "    def _prepare_email_input(self, message, response):\n",
    "        \"\"\"\n",
    "        Prepare the input text with formatted message and response for tokenization.\n",
    "        \"\"\"\n",
    "        formatted_input = f\"<s>[INST] {message} [/INST] {response}</s>\"\n",
    "        return self.tokenizer(\n",
    "            formatted_input,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.pairs[idx]\n",
    "        \n",
    "        \n",
    "        if pair['message']['label'] == 1:\n",
    "            message_text = (\n",
    "                \"This email is flagged as a phishing email. \"\n",
    "                \"Carefully examine the sender's address, subject line, and content of the email. \"\n",
    "                f\"Sender: {pair['message']['sender']} [SEP] \"\n",
    "                f\"Subject: {pair['message']['subject']} [SEP] \"\n",
    "                f\"Body: {pair['message']['body']}\"\n",
    "            )\n",
    "        else:\n",
    "            message_text = (\n",
    "                \"This email is flagged as a legitimate email. \"\n",
    "                \"Look for consistent and clear sender details, subject relevance, and authentic body content. \"\n",
    "                f\"Sender: {pair['message']['sender']} [SEP] \"\n",
    "                f\"Subject: {pair['message']['subject']} [SEP] \"\n",
    "                f\"Body: {pair['message']['body']}\"\n",
    "            )\n",
    "        \n",
    "        \n",
    "        preferred_response = (\n",
    "            \"This is a similar email example to the one above. \"\n",
    "            f\"Sender: {pair['preferred']['sender']} [SEP] \"\n",
    "            f\"Subject: {pair['preferred']['subject']} [SEP] \"\n",
    "            f\"Body: {pair['preferred']['body']}\"\n",
    "        )\n",
    "        rejected_response = (\n",
    "            \"This email is different in intent. Notice the sender's address, subject, and content mismatch. \"\n",
    "            f\"Sender: {pair['rejected']['sender']} [SEP] \"\n",
    "            f\"Subject: {pair['rejected']['subject']} [SEP] \"\n",
    "            f\"Body: {pair['rejected']['body']}\"\n",
    "        )\n",
    "        \n",
    "        message_inputs = self._prepare_email_input(message_text, \"\")\n",
    "        preferred_inputs = self._prepare_email_input(message_text, preferred_response)\n",
    "        rejected_inputs = self._prepare_email_input(message_text, rejected_response)\n",
    "\n",
    "        return {\n",
    "            'message_input_ids': message_inputs['input_ids'].squeeze(),\n",
    "            'message_attention_mask': message_inputs['attention_mask'].squeeze(),\n",
    "            'preferred_input_ids': preferred_inputs['input_ids'].squeeze(),\n",
    "            'preferred_attention_mask': preferred_inputs['attention_mask'].squeeze(),\n",
    "            'rejected_input_ids': rejected_inputs['input_ids'].squeeze(),\n",
    "            'rejected_attention_mask': rejected_inputs['attention_mask'].squeeze(),\n",
    "        }\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "   \n",
    "    if not isinstance(text, str):\n",
    "        text = \"\"\n",
    "    #text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    #text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def compute_dpo_loss(policy_chosen_logits, policy_rejected_logits, \n",
    "                    reference_chosen_logits, reference_rejected_logits, \n",
    "                    beta=0.2):\n",
    "   \n",
    "    epsilon = 1e-8\n",
    "    \n",
    "   \n",
    "    policy_chosen_probs = F.softmax(policy_chosen_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    policy_rejected_probs = F.softmax(policy_rejected_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    ref_chosen_probs = F.softmax(reference_chosen_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    ref_rejected_probs = F.softmax(reference_rejected_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    \n",
    "  \n",
    "    chosen_rewards = (torch.log(policy_chosen_probs + epsilon) - \n",
    "                     torch.log(ref_chosen_probs + epsilon))\n",
    "    rejected_rewards = (torch.log(policy_rejected_probs + epsilon) - \n",
    "                       torch.log(ref_rejected_probs + epsilon))\n",
    "    \n",
    "    \n",
    "    max_reward = 50.0\n",
    "    chosen_rewards = torch.clamp(chosen_rewards, -max_reward, max_reward)\n",
    "    rejected_rewards = torch.clamp(rejected_rewards, -max_reward, max_reward)\n",
    "    \n",
    "    \n",
    "    logits_diff = (chosen_rewards - rejected_rewards) / beta\n",
    "    \n",
    "    valid_mask = ~torch.isnan(logits_diff)\n",
    "    if valid_mask.any():\n",
    "        loss = -F.logsigmoid(logits_diff[valid_mask]).mean()\n",
    "    else:\n",
    "        loss = torch.tensor(0.0, device=logits_diff.device)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def train_model_dpo(policy_model, reference_model, train_loader, val_loader, \n",
    "                   optimizer, scheduler, device, num_epochs=8, beta=0.2, gradient_accumulation_steps=2):\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    policy_model = policy_model.to(device).float()\n",
    "    reference_model = reference_model.to(device).float()\n",
    "    reference_model.eval()  # Ensure reference model does not get updated during training\n",
    "    \n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        policy_model.train()\n",
    "        total_loss = 0\n",
    "        valid_steps = 0\n",
    "        \n",
    "        for step, batch in enumerate(train_loader):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            try:\n",
    "                with torch.amp.autocast('cuda', dtype=torch.float32):\n",
    "                    policy_chosen_outputs = policy_model(\n",
    "                        input_ids=batch['preferred_input_ids'],\n",
    "                        attention_mask=batch['preferred_attention_mask']\n",
    "                    )\n",
    "                    policy_rejected_outputs = policy_model(\n",
    "                        input_ids=batch['rejected_input_ids'],\n",
    "                        attention_mask=batch['rejected_attention_mask']\n",
    "                    )\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        ref_chosen_outputs = reference_model(\n",
    "                            input_ids=batch['preferred_input_ids'],\n",
    "                            attention_mask=batch['preferred_attention_mask']\n",
    "                        )\n",
    "                        ref_rejected_outputs = reference_model(\n",
    "                            input_ids=batch['rejected_input_ids'],\n",
    "                            attention_mask=batch['rejected_attention_mask']\n",
    "                        )\n",
    "                    \n",
    "                    loss = compute_dpo_loss(\n",
    "                        policy_chosen_outputs.logits,\n",
    "                        policy_rejected_outputs.logits,\n",
    "                        ref_chosen_outputs.logits,\n",
    "                        ref_rejected_outputs.logits,\n",
    "                        beta=beta\n",
    "                    )\n",
    "                    \n",
    "                    if not torch.isnan(loss) and not torch.isinf(loss):\n",
    "                        scaler.scale(loss).backward()\n",
    "                        \n",
    "                        # Gradient accumulation logic\n",
    "                        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                            scaler.unscale_(optimizer)\n",
    "                            torch.nn.utils.clip_grad_norm_(policy_model.parameters(), max_norm=1.0)\n",
    "                            scaler.step(optimizer)\n",
    "                            scaler.update()\n",
    "                            scheduler.step()\n",
    "                            optimizer.zero_grad()\n",
    "                        \n",
    "                        total_loss += loss.item()\n",
    "                        valid_steps += 1\n",
    "                    \n",
    "                    if step % 10 == 0:\n",
    "                        avg_loss = total_loss / max(valid_steps, 1)\n",
    "                        print(f\"[Epoch {epoch+1}/{num_epochs} | Step {step}/{len(train_loader)}] - Loss: {avg_loss:.4f}\")\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error in batch {step}: {str(e)}\")\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        if valid_steps > 0:\n",
    "            avg_train_loss = total_loss / valid_steps\n",
    "            val_loss = evaluate_model_dpo(policy_model, reference_model, val_loader, device, beta)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Avg Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_state = {k: v.cpu() for k, v in policy_model.state_dict().items() if isinstance(v, torch.Tensor)}\n",
    "    \n",
    "    return best_model_state\n",
    "\n",
    "def evaluate_model_dpo(policy_model, reference_model, val_loader, device, beta):\n",
    "   \n",
    "    policy_model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            with torch.amp.autocast('cuda', dtype=torch.float32):\n",
    "                policy_chosen_outputs = policy_model(\n",
    "                    input_ids=batch['preferred_input_ids'],\n",
    "                    attention_mask=batch['preferred_attention_mask']\n",
    "                )\n",
    "                policy_rejected_outputs = policy_model(\n",
    "                    input_ids=batch['rejected_input_ids'],\n",
    "                    attention_mask=batch['rejected_attention_mask']\n",
    "                )\n",
    "                \n",
    "                ref_chosen_outputs = reference_model(\n",
    "                    input_ids=batch['preferred_input_ids'],\n",
    "                    attention_mask=batch['preferred_attention_mask']\n",
    "                )\n",
    "                ref_rejected_outputs = reference_model(\n",
    "                    input_ids=batch['rejected_input_ids'],\n",
    "                    attention_mask=batch['rejected_attention_mask']\n",
    "                )\n",
    "                \n",
    "                loss = compute_dpo_loss(\n",
    "                    policy_chosen_outputs.logits,\n",
    "                    policy_rejected_outputs.logits,\n",
    "                    ref_chosen_outputs.logits,\n",
    "                    ref_rejected_outputs.logits,\n",
    "                    beta=beta\n",
    "                )\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "def main():\n",
    "\n",
    "    login(token=\"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\")\n",
    "    device = setup_environment()\n",
    "    model_name = 'meta-llama/Meta-Llama-3-8B'\n",
    "    data_path = os.path.expanduser(\"~/Downloads/Tune/FineTune/newdata_cleaned.csv\")\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(f\"File not found: {data_path}\")\n",
    "\n",
    "    policy_model, tokenizer = setup_model_and_tokenizer(model_name, device)\n",
    "    reference_model, _ = setup_model_and_tokenizer(model_name, device)\n",
    "    \n",
    "\n",
    "    emails_df = pd.read_csv(data_path)\n",
    "    emails_df['sender'] = emails_df['sender'].astype(str).apply(clean_text)\n",
    "    emails_df['subject'] = emails_df['subject'].astype(str).apply(clean_text)\n",
    "    emails_df['body'] = emails_df['body'].astype(str).apply(clean_text)\n",
    "\n",
    "    train_df, val_df = train_test_split(emails_df, test_size=0.2, stratify=emails_df['label'], random_state=42)\n",
    "\n",
    "  \n",
    "    train_dataset = PreferenceEmailDataset(train_df, tokenizer, max_length=512)\n",
    "    val_dataset = PreferenceEmailDataset(val_df, tokenizer, max_length=512)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # Setup optimization\n",
    "    optimizer = torch.optim.AdamW(policy_model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "    num_epochs = 8\n",
    "    num_training_steps = len(train_loader) * num_epochs\n",
    "    num_warmup_steps = num_training_steps // 20\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "\n",
    "    best_model_state = train_model_dpo(\n",
    "        policy_model,\n",
    "        reference_model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        device,\n",
    "        num_epochs=num_epochs,\n",
    "        beta=0.2\n",
    "    )\n",
    "\n",
    "   \n",
    "    output_dir = os.path.expanduser(\"~/Downloads/Tune/FineTune/dpo_8B\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    policy_model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "    config = {\n",
    "        \"model_name\": model_name,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"batch_size\": 8,\n",
    "        \"max_length\": 512,\n",
    "        \"warmup_steps\": num_warmup_steps,\n",
    "        \"total_steps\": num_training_steps,\n",
    "        \"device\": str(device),\n",
    "        \"beta\": 0.2\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"training_config.json\"), \"w\") as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e95a20b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA RTX A5000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22468d5dc71f4848903b2b0e0f2ceaf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-2-7b-chat-hf and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b420debdbaf74a74b449c5a0f11c0c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-2-7b-chat-hf and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/users/skuikel/anaconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/users/skuikel/anaconda3/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/8 | Step 0/600] - Loss: 6.6057\n",
      "[Epoch 1/8 | Step 10/600] - Loss: 4.7892\n",
      "[Epoch 1/8 | Step 20/600] - Loss: 4.2138\n",
      "[Epoch 1/8 | Step 30/600] - Loss: 3.7690\n",
      "[Epoch 1/8 | Step 40/600] - Loss: 3.5323\n",
      "[Epoch 1/8 | Step 50/600] - Loss: 3.4411\n",
      "[Epoch 1/8 | Step 60/600] - Loss: 3.4594\n",
      "[Epoch 1/8 | Step 70/600] - Loss: 3.4469\n",
      "[Epoch 1/8 | Step 80/600] - Loss: 3.4203\n",
      "[Epoch 1/8 | Step 90/600] - Loss: 3.3946\n",
      "[Epoch 1/8 | Step 100/600] - Loss: 3.3460\n",
      "[Epoch 1/8 | Step 110/600] - Loss: 3.3276\n",
      "[Epoch 1/8 | Step 120/600] - Loss: 3.2951\n",
      "[Epoch 1/8 | Step 130/600] - Loss: 3.3332\n",
      "[Epoch 1/8 | Step 140/600] - Loss: 3.3563\n",
      "[Epoch 1/8 | Step 150/600] - Loss: 3.3373\n",
      "[Epoch 1/8 | Step 160/600] - Loss: 3.3860\n",
      "[Epoch 1/8 | Step 170/600] - Loss: 3.4165\n",
      "[Epoch 1/8 | Step 180/600] - Loss: 3.3524\n",
      "[Epoch 1/8 | Step 190/600] - Loss: 3.3358\n",
      "[Epoch 1/8 | Step 200/600] - Loss: 3.3656\n",
      "[Epoch 1/8 | Step 210/600] - Loss: 3.3729\n",
      "[Epoch 1/8 | Step 220/600] - Loss: 3.3451\n",
      "[Epoch 1/8 | Step 230/600] - Loss: 3.3427\n",
      "[Epoch 1/8 | Step 240/600] - Loss: 3.3575\n",
      "[Epoch 1/8 | Step 250/600] - Loss: 3.3436\n",
      "[Epoch 1/8 | Step 260/600] - Loss: 3.3043\n",
      "[Epoch 1/8 | Step 270/600] - Loss: 3.2852\n",
      "[Epoch 1/8 | Step 280/600] - Loss: 3.2953\n",
      "[Epoch 1/8 | Step 290/600] - Loss: 3.3166\n",
      "[Epoch 1/8 | Step 300/600] - Loss: 3.3081\n",
      "[Epoch 1/8 | Step 310/600] - Loss: 3.2941\n",
      "[Epoch 1/8 | Step 320/600] - Loss: 3.2948\n",
      "[Epoch 1/8 | Step 330/600] - Loss: 3.2891\n",
      "[Epoch 1/8 | Step 340/600] - Loss: 3.2764\n",
      "[Epoch 1/8 | Step 350/600] - Loss: 3.2638\n",
      "[Epoch 1/8 | Step 360/600] - Loss: 3.2373\n",
      "[Epoch 1/8 | Step 370/600] - Loss: 3.2077\n",
      "[Epoch 1/8 | Step 380/600] - Loss: 3.2116\n",
      "[Epoch 1/8 | Step 390/600] - Loss: 3.1920\n",
      "[Epoch 1/8 | Step 400/600] - Loss: 3.1902\n",
      "[Epoch 1/8 | Step 410/600] - Loss: 3.1981\n",
      "[Epoch 1/8 | Step 420/600] - Loss: 3.1692\n",
      "[Epoch 1/8 | Step 430/600] - Loss: 3.1560\n",
      "[Epoch 1/8 | Step 440/600] - Loss: 3.1294\n",
      "[Epoch 1/8 | Step 450/600] - Loss: 3.1369\n",
      "[Epoch 1/8 | Step 460/600] - Loss: 3.1395\n",
      "[Epoch 1/8 | Step 470/600] - Loss: 3.1411\n",
      "[Epoch 1/8 | Step 480/600] - Loss: 3.1353\n",
      "[Epoch 1/8 | Step 490/600] - Loss: 3.1315\n",
      "[Epoch 1/8 | Step 500/600] - Loss: 3.1062\n",
      "[Epoch 1/8 | Step 510/600] - Loss: 3.0884\n",
      "[Epoch 1/8 | Step 520/600] - Loss: 3.0486\n",
      "[Epoch 1/8 | Step 530/600] - Loss: 3.0355\n",
      "[Epoch 1/8 | Step 540/600] - Loss: 3.0159\n",
      "[Epoch 1/8 | Step 550/600] - Loss: 3.0090\n",
      "[Epoch 1/8 | Step 560/600] - Loss: 2.9869\n",
      "[Epoch 1/8 | Step 570/600] - Loss: 2.9614\n",
      "[Epoch 1/8 | Step 580/600] - Loss: 2.9524\n",
      "[Epoch 1/8 | Step 590/600] - Loss: 2.9465\n",
      "Epoch 1/8 - Avg Train Loss: 2.9462, Val Loss: 2.3142\n",
      "[Epoch 2/8 | Step 0/600] - Loss: 2.7277\n",
      "[Epoch 2/8 | Step 10/600] - Loss: 1.9767\n",
      "[Epoch 2/8 | Step 20/600] - Loss: 2.0448\n",
      "[Epoch 2/8 | Step 30/600] - Loss: 2.1692\n",
      "[Epoch 2/8 | Step 40/600] - Loss: 2.1182\n",
      "[Epoch 2/8 | Step 50/600] - Loss: 1.9728\n",
      "[Epoch 2/8 | Step 60/600] - Loss: 2.0347\n",
      "[Epoch 2/8 | Step 70/600] - Loss: 2.1004\n",
      "[Epoch 2/8 | Step 80/600] - Loss: 2.1585\n",
      "[Epoch 2/8 | Step 90/600] - Loss: 2.1929\n",
      "[Epoch 2/8 | Step 100/600] - Loss: 2.1284\n",
      "[Epoch 2/8 | Step 110/600] - Loss: 2.1350\n",
      "[Epoch 2/8 | Step 120/600] - Loss: 2.1891\n",
      "[Epoch 2/8 | Step 130/600] - Loss: 2.2136\n",
      "[Epoch 2/8 | Step 140/600] - Loss: 2.2253\n",
      "[Epoch 2/8 | Step 150/600] - Loss: 2.2370\n",
      "[Epoch 2/8 | Step 160/600] - Loss: 2.2434\n",
      "[Epoch 2/8 | Step 170/600] - Loss: 2.2245\n",
      "[Epoch 2/8 | Step 180/600] - Loss: 2.1926\n",
      "[Epoch 2/8 | Step 190/600] - Loss: 2.1988\n",
      "[Epoch 2/8 | Step 200/600] - Loss: 2.1851\n",
      "[Epoch 2/8 | Step 210/600] - Loss: 2.2234\n",
      "[Epoch 2/8 | Step 220/600] - Loss: 2.2159\n",
      "[Epoch 2/8 | Step 230/600] - Loss: 2.2187\n",
      "[Epoch 2/8 | Step 240/600] - Loss: 2.2042\n",
      "[Epoch 2/8 | Step 250/600] - Loss: 2.2496\n",
      "[Epoch 2/8 | Step 260/600] - Loss: 2.2183\n",
      "[Epoch 2/8 | Step 270/600] - Loss: 2.2383\n",
      "[Epoch 2/8 | Step 280/600] - Loss: 2.2252\n",
      "[Epoch 2/8 | Step 290/600] - Loss: 2.2140\n",
      "[Epoch 2/8 | Step 300/600] - Loss: 2.1984\n",
      "[Epoch 2/8 | Step 310/600] - Loss: 2.1961\n",
      "[Epoch 2/8 | Step 320/600] - Loss: 2.2138\n",
      "[Epoch 2/8 | Step 330/600] - Loss: 2.2215\n",
      "[Epoch 2/8 | Step 340/600] - Loss: 2.2072\n",
      "[Epoch 2/8 | Step 350/600] - Loss: 2.1908\n",
      "[Epoch 2/8 | Step 360/600] - Loss: 2.2075\n",
      "[Epoch 2/8 | Step 370/600] - Loss: 2.2073\n",
      "[Epoch 2/8 | Step 380/600] - Loss: 2.2113\n",
      "[Epoch 2/8 | Step 390/600] - Loss: 2.2117\n",
      "[Epoch 2/8 | Step 400/600] - Loss: 2.2049\n",
      "[Epoch 2/8 | Step 410/600] - Loss: 2.1889\n",
      "[Epoch 2/8 | Step 420/600] - Loss: 2.2131\n",
      "[Epoch 2/8 | Step 430/600] - Loss: 2.2247\n",
      "[Epoch 2/8 | Step 440/600] - Loss: 2.2271\n",
      "[Epoch 2/8 | Step 450/600] - Loss: 2.2379\n",
      "[Epoch 2/8 | Step 460/600] - Loss: 2.2250\n",
      "[Epoch 2/8 | Step 470/600] - Loss: 2.2147\n",
      "[Epoch 2/8 | Step 480/600] - Loss: 2.2229\n",
      "[Epoch 2/8 | Step 490/600] - Loss: 2.2176\n",
      "[Epoch 2/8 | Step 500/600] - Loss: 2.2179\n",
      "[Epoch 2/8 | Step 510/600] - Loss: 2.2160\n",
      "[Epoch 2/8 | Step 520/600] - Loss: 2.2071\n",
      "[Epoch 2/8 | Step 530/600] - Loss: 2.2100\n",
      "[Epoch 2/8 | Step 540/600] - Loss: 2.1964\n",
      "[Epoch 2/8 | Step 550/600] - Loss: 2.2037\n",
      "[Epoch 2/8 | Step 560/600] - Loss: 2.2163\n",
      "[Epoch 2/8 | Step 570/600] - Loss: 2.2114\n",
      "[Epoch 2/8 | Step 580/600] - Loss: 2.2062\n",
      "[Epoch 2/8 | Step 590/600] - Loss: 2.2151\n",
      "Epoch 2/8 - Avg Train Loss: 2.2094, Val Loss: 2.1657\n",
      "[Epoch 3/8 | Step 0/600] - Loss: 0.6215\n",
      "[Epoch 3/8 | Step 10/600] - Loss: 2.0842\n",
      "[Epoch 3/8 | Step 20/600] - Loss: 2.5176\n",
      "[Epoch 3/8 | Step 30/600] - Loss: 2.1886\n",
      "[Epoch 3/8 | Step 40/600] - Loss: 2.0767\n",
      "[Epoch 3/8 | Step 50/600] - Loss: 2.2448\n",
      "[Epoch 3/8 | Step 60/600] - Loss: 2.3454\n",
      "[Epoch 3/8 | Step 70/600] - Loss: 2.2756\n",
      "[Epoch 3/8 | Step 80/600] - Loss: 2.2985\n",
      "[Epoch 3/8 | Step 90/600] - Loss: 2.2870\n",
      "[Epoch 3/8 | Step 100/600] - Loss: 2.2165\n",
      "[Epoch 3/8 | Step 110/600] - Loss: 2.2534\n",
      "[Epoch 3/8 | Step 120/600] - Loss: 2.2560\n",
      "[Epoch 3/8 | Step 130/600] - Loss: 2.2778\n",
      "[Epoch 3/8 | Step 140/600] - Loss: 2.3156\n",
      "[Epoch 3/8 | Step 150/600] - Loss: 2.2846\n",
      "[Epoch 3/8 | Step 160/600] - Loss: 2.2396\n",
      "[Epoch 3/8 | Step 170/600] - Loss: 2.2251\n",
      "[Epoch 3/8 | Step 180/600] - Loss: 2.2256\n",
      "[Epoch 3/8 | Step 190/600] - Loss: 2.2451\n",
      "[Epoch 3/8 | Step 200/600] - Loss: 2.2386\n",
      "[Epoch 3/8 | Step 210/600] - Loss: 2.2216\n",
      "[Epoch 3/8 | Step 220/600] - Loss: 2.2292\n",
      "[Epoch 3/8 | Step 230/600] - Loss: 2.2001\n",
      "[Epoch 3/8 | Step 240/600] - Loss: 2.1982\n",
      "[Epoch 3/8 | Step 250/600] - Loss: 2.1724\n",
      "[Epoch 3/8 | Step 260/600] - Loss: 2.1814\n",
      "[Epoch 3/8 | Step 270/600] - Loss: 2.1925\n",
      "[Epoch 3/8 | Step 280/600] - Loss: 2.1592\n",
      "[Epoch 3/8 | Step 290/600] - Loss: 2.1394\n",
      "[Epoch 3/8 | Step 300/600] - Loss: 2.1411\n",
      "[Epoch 3/8 | Step 310/600] - Loss: 2.1604\n",
      "[Epoch 3/8 | Step 320/600] - Loss: 2.1595\n",
      "[Epoch 3/8 | Step 330/600] - Loss: 2.1765\n",
      "[Epoch 3/8 | Step 340/600] - Loss: 2.1538\n",
      "[Epoch 3/8 | Step 350/600] - Loss: 2.1795\n",
      "[Epoch 3/8 | Step 360/600] - Loss: 2.1622\n",
      "[Epoch 3/8 | Step 370/600] - Loss: 2.1461\n",
      "[Epoch 3/8 | Step 380/600] - Loss: 2.1552\n",
      "[Epoch 3/8 | Step 390/600] - Loss: 2.1352\n",
      "[Epoch 3/8 | Step 400/600] - Loss: 2.1411\n",
      "[Epoch 3/8 | Step 410/600] - Loss: 2.1397\n",
      "[Epoch 3/8 | Step 420/600] - Loss: 2.1293\n",
      "[Epoch 3/8 | Step 430/600] - Loss: 2.1264\n",
      "[Epoch 3/8 | Step 440/600] - Loss: 2.1199\n",
      "[Epoch 3/8 | Step 450/600] - Loss: 2.1181\n",
      "[Epoch 3/8 | Step 460/600] - Loss: 2.1255\n",
      "[Epoch 3/8 | Step 470/600] - Loss: 2.1105\n",
      "[Epoch 3/8 | Step 480/600] - Loss: 2.1127\n",
      "[Epoch 3/8 | Step 490/600] - Loss: 2.1175\n",
      "[Epoch 3/8 | Step 500/600] - Loss: 2.1235\n",
      "[Epoch 3/8 | Step 510/600] - Loss: 2.1251\n",
      "[Epoch 3/8 | Step 520/600] - Loss: 2.1242\n",
      "[Epoch 3/8 | Step 530/600] - Loss: 2.1107\n",
      "[Epoch 3/8 | Step 540/600] - Loss: 2.1084\n",
      "[Epoch 3/8 | Step 550/600] - Loss: 2.1055\n",
      "[Epoch 3/8 | Step 560/600] - Loss: 2.0997\n",
      "[Epoch 3/8 | Step 570/600] - Loss: 2.0852\n",
      "[Epoch 3/8 | Step 580/600] - Loss: 2.1111\n",
      "[Epoch 3/8 | Step 590/600] - Loss: 2.0975\n",
      "Epoch 3/8 - Avg Train Loss: 2.1153, Val Loss: 2.1313\n",
      "[Epoch 4/8 | Step 0/600] - Loss: 0.7313\n",
      "[Epoch 4/8 | Step 10/600] - Loss: 2.2070\n",
      "[Epoch 4/8 | Step 20/600] - Loss: 2.2370\n",
      "[Epoch 4/8 | Step 30/600] - Loss: 2.1771\n",
      "[Epoch 4/8 | Step 40/600] - Loss: 1.9496\n",
      "[Epoch 4/8 | Step 50/600] - Loss: 1.9615\n",
      "[Epoch 4/8 | Step 60/600] - Loss: 2.0120\n",
      "[Epoch 4/8 | Step 70/600] - Loss: 2.0866\n",
      "[Epoch 4/8 | Step 80/600] - Loss: 2.2453\n",
      "[Epoch 4/8 | Step 90/600] - Loss: 2.3379\n",
      "[Epoch 4/8 | Step 100/600] - Loss: 2.2900\n",
      "[Epoch 4/8 | Step 110/600] - Loss: 2.2111\n",
      "[Epoch 4/8 | Step 120/600] - Loss: 2.1794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/8 | Step 130/600] - Loss: 2.1675\n",
      "[Epoch 4/8 | Step 140/600] - Loss: 2.1429\n",
      "[Epoch 4/8 | Step 150/600] - Loss: 2.1392\n",
      "[Epoch 4/8 | Step 160/600] - Loss: 2.1490\n",
      "[Epoch 4/8 | Step 170/600] - Loss: 2.1589\n",
      "[Epoch 4/8 | Step 180/600] - Loss: 2.2471\n",
      "[Epoch 4/8 | Step 190/600] - Loss: 2.2743\n",
      "[Epoch 4/8 | Step 200/600] - Loss: 2.2375\n",
      "[Epoch 4/8 | Step 210/600] - Loss: 2.2367\n",
      "[Epoch 4/8 | Step 220/600] - Loss: 2.1950\n",
      "[Epoch 4/8 | Step 230/600] - Loss: 2.1940\n",
      "[Epoch 4/8 | Step 240/600] - Loss: 2.1836\n",
      "[Epoch 4/8 | Step 250/600] - Loss: 2.1952\n",
      "[Epoch 4/8 | Step 260/600] - Loss: 2.1980\n",
      "[Epoch 4/8 | Step 270/600] - Loss: 2.2081\n",
      "[Epoch 4/8 | Step 280/600] - Loss: 2.1927\n",
      "[Epoch 4/8 | Step 290/600] - Loss: 2.1841\n",
      "[Epoch 4/8 | Step 300/600] - Loss: 2.1527\n",
      "[Epoch 4/8 | Step 310/600] - Loss: 2.1414\n",
      "[Epoch 4/8 | Step 320/600] - Loss: 2.1488\n",
      "[Epoch 4/8 | Step 330/600] - Loss: 2.1321\n",
      "[Epoch 4/8 | Step 340/600] - Loss: 2.1533\n",
      "[Epoch 4/8 | Step 350/600] - Loss: 2.1466\n",
      "[Epoch 4/8 | Step 360/600] - Loss: 2.1822\n",
      "[Epoch 4/8 | Step 370/600] - Loss: 2.1667\n",
      "[Epoch 4/8 | Step 380/600] - Loss: 2.1620\n",
      "[Epoch 4/8 | Step 390/600] - Loss: 2.1772\n",
      "[Epoch 4/8 | Step 400/600] - Loss: 2.1798\n",
      "[Epoch 4/8 | Step 410/600] - Loss: 2.1678\n",
      "[Epoch 4/8 | Step 420/600] - Loss: 2.1749\n",
      "[Epoch 4/8 | Step 430/600] - Loss: 2.1599\n",
      "[Epoch 4/8 | Step 440/600] - Loss: 2.1390\n",
      "[Epoch 4/8 | Step 450/600] - Loss: 2.1318\n",
      "[Epoch 4/8 | Step 460/600] - Loss: 2.1287\n",
      "[Epoch 4/8 | Step 470/600] - Loss: 2.1303\n",
      "[Epoch 4/8 | Step 480/600] - Loss: 2.1145\n",
      "[Epoch 4/8 | Step 490/600] - Loss: 2.1192\n",
      "[Epoch 4/8 | Step 500/600] - Loss: 2.1129\n",
      "[Epoch 4/8 | Step 510/600] - Loss: 2.1094\n",
      "[Epoch 4/8 | Step 520/600] - Loss: 2.1049\n",
      "[Epoch 4/8 | Step 530/600] - Loss: 2.1300\n",
      "[Epoch 4/8 | Step 540/600] - Loss: 2.1224\n",
      "[Epoch 4/8 | Step 550/600] - Loss: 2.1147\n",
      "[Epoch 4/8 | Step 560/600] - Loss: 2.1060\n",
      "[Epoch 4/8 | Step 570/600] - Loss: 2.1123\n",
      "[Epoch 4/8 | Step 580/600] - Loss: 2.1046\n",
      "[Epoch 4/8 | Step 590/600] - Loss: 2.0927\n",
      "Epoch 4/8 - Avg Train Loss: 2.0821, Val Loss: 2.1150\n",
      "[Epoch 5/8 | Step 0/600] - Loss: 0.5479\n",
      "[Epoch 5/8 | Step 10/600] - Loss: 2.1535\n",
      "[Epoch 5/8 | Step 20/600] - Loss: 1.8598\n",
      "[Epoch 5/8 | Step 30/600] - Loss: 1.8803\n",
      "[Epoch 5/8 | Step 40/600] - Loss: 2.2314\n",
      "[Epoch 5/8 | Step 50/600] - Loss: 2.2374\n",
      "[Epoch 5/8 | Step 60/600] - Loss: 2.2128\n",
      "[Epoch 5/8 | Step 70/600] - Loss: 2.1638\n",
      "[Epoch 5/8 | Step 80/600] - Loss: 2.1292\n",
      "[Epoch 5/8 | Step 90/600] - Loss: 2.1120\n",
      "[Epoch 5/8 | Step 100/600] - Loss: 2.0651\n",
      "[Epoch 5/8 | Step 110/600] - Loss: 2.0607\n",
      "[Epoch 5/8 | Step 120/600] - Loss: 2.1352\n",
      "[Epoch 5/8 | Step 130/600] - Loss: 2.1156\n",
      "[Epoch 5/8 | Step 140/600] - Loss: 2.1203\n",
      "[Epoch 5/8 | Step 150/600] - Loss: 2.0714\n",
      "[Epoch 5/8 | Step 160/600] - Loss: 2.0487\n",
      "[Epoch 5/8 | Step 170/600] - Loss: 2.0234\n",
      "[Epoch 5/8 | Step 180/600] - Loss: 2.0158\n",
      "[Epoch 5/8 | Step 190/600] - Loss: 1.9924\n",
      "[Epoch 5/8 | Step 200/600] - Loss: 1.9799\n",
      "[Epoch 5/8 | Step 210/600] - Loss: 1.9583\n",
      "[Epoch 5/8 | Step 220/600] - Loss: 1.9613\n",
      "[Epoch 5/8 | Step 230/600] - Loss: 1.9526\n",
      "[Epoch 5/8 | Step 240/600] - Loss: 1.9593\n",
      "[Epoch 5/8 | Step 250/600] - Loss: 1.9587\n",
      "[Epoch 5/8 | Step 260/600] - Loss: 1.9453\n",
      "[Epoch 5/8 | Step 270/600] - Loss: 1.9273\n",
      "[Epoch 5/8 | Step 280/600] - Loss: 1.9639\n",
      "[Epoch 5/8 | Step 290/600] - Loss: 1.9524\n",
      "[Epoch 5/8 | Step 300/600] - Loss: 1.9398\n",
      "[Epoch 5/8 | Step 310/600] - Loss: 1.9273\n",
      "[Epoch 5/8 | Step 320/600] - Loss: 1.9353\n",
      "[Epoch 5/8 | Step 330/600] - Loss: 1.9544\n",
      "[Epoch 5/8 | Step 340/600] - Loss: 1.9620\n",
      "[Epoch 5/8 | Step 350/600] - Loss: 1.9624\n",
      "[Epoch 5/8 | Step 360/600] - Loss: 1.9494\n",
      "[Epoch 5/8 | Step 370/600] - Loss: 1.9484\n",
      "[Epoch 5/8 | Step 380/600] - Loss: 1.9496\n",
      "[Epoch 5/8 | Step 390/600] - Loss: 1.9587\n",
      "[Epoch 5/8 | Step 400/600] - Loss: 1.9679\n",
      "[Epoch 5/8 | Step 410/600] - Loss: 1.9709\n",
      "[Epoch 5/8 | Step 420/600] - Loss: 1.9572\n",
      "[Epoch 5/8 | Step 430/600] - Loss: 1.9453\n",
      "[Epoch 5/8 | Step 440/600] - Loss: 1.9428\n",
      "[Epoch 5/8 | Step 450/600] - Loss: 1.9361\n",
      "[Epoch 5/8 | Step 460/600] - Loss: 1.9347\n",
      "[Epoch 5/8 | Step 470/600] - Loss: 1.9424\n",
      "[Epoch 5/8 | Step 480/600] - Loss: 1.9503\n",
      "[Epoch 5/8 | Step 490/600] - Loss: 1.9595\n",
      "[Epoch 5/8 | Step 500/600] - Loss: 1.9753\n",
      "[Epoch 5/8 | Step 510/600] - Loss: 1.9801\n",
      "[Epoch 5/8 | Step 520/600] - Loss: 1.9931\n",
      "[Epoch 5/8 | Step 530/600] - Loss: 2.0017\n",
      "[Epoch 5/8 | Step 540/600] - Loss: 2.0102\n",
      "[Epoch 5/8 | Step 550/600] - Loss: 2.0241\n",
      "[Epoch 5/8 | Step 560/600] - Loss: 2.0230\n",
      "[Epoch 5/8 | Step 570/600] - Loss: 2.0213\n",
      "[Epoch 5/8 | Step 580/600] - Loss: 2.0385\n",
      "[Epoch 5/8 | Step 590/600] - Loss: 2.0405\n",
      "Epoch 5/8 - Avg Train Loss: 2.0403, Val Loss: 2.1010\n",
      "[Epoch 6/8 | Step 0/600] - Loss: 0.4718\n",
      "[Epoch 6/8 | Step 10/600] - Loss: 1.0029\n",
      "[Epoch 6/8 | Step 20/600] - Loss: 1.6073\n",
      "[Epoch 6/8 | Step 30/600] - Loss: 1.8045\n",
      "[Epoch 6/8 | Step 40/600] - Loss: 1.7334\n",
      "[Epoch 6/8 | Step 50/600] - Loss: 1.7608\n",
      "[Epoch 6/8 | Step 60/600] - Loss: 1.9736\n",
      "[Epoch 6/8 | Step 70/600] - Loss: 2.0234\n",
      "[Epoch 6/8 | Step 80/600] - Loss: 1.9620\n",
      "[Epoch 6/8 | Step 90/600] - Loss: 2.0138\n",
      "[Epoch 6/8 | Step 100/600] - Loss: 2.0331\n",
      "[Epoch 6/8 | Step 110/600] - Loss: 2.0287\n",
      "[Epoch 6/8 | Step 120/600] - Loss: 2.0128\n",
      "[Epoch 6/8 | Step 130/600] - Loss: 1.9714\n",
      "[Epoch 6/8 | Step 140/600] - Loss: 1.9905\n",
      "[Epoch 6/8 | Step 150/600] - Loss: 2.0160\n",
      "[Epoch 6/8 | Step 160/600] - Loss: 2.0084\n",
      "[Epoch 6/8 | Step 170/600] - Loss: 1.9746\n",
      "[Epoch 6/8 | Step 180/600] - Loss: 1.9574\n",
      "[Epoch 6/8 | Step 190/600] - Loss: 1.9751\n",
      "[Epoch 6/8 | Step 200/600] - Loss: 1.9622\n",
      "[Epoch 6/8 | Step 210/600] - Loss: 1.9871\n",
      "[Epoch 6/8 | Step 220/600] - Loss: 2.0121\n",
      "[Epoch 6/8 | Step 230/600] - Loss: 2.0087\n",
      "[Epoch 6/8 | Step 240/600] - Loss: 1.9762\n",
      "[Epoch 6/8 | Step 250/600] - Loss: 1.9951\n",
      "[Epoch 6/8 | Step 260/600] - Loss: 1.9887\n",
      "[Epoch 6/8 | Step 270/600] - Loss: 1.9719\n",
      "[Epoch 6/8 | Step 280/600] - Loss: 1.9950\n",
      "[Epoch 6/8 | Step 290/600] - Loss: 1.9761\n",
      "[Epoch 6/8 | Step 300/600] - Loss: 1.9774\n",
      "[Epoch 6/8 | Step 310/600] - Loss: 1.9701\n",
      "[Epoch 6/8 | Step 320/600] - Loss: 1.9914\n",
      "[Epoch 6/8 | Step 330/600] - Loss: 1.9817\n",
      "[Epoch 6/8 | Step 340/600] - Loss: 1.9948\n",
      "[Epoch 6/8 | Step 350/600] - Loss: 1.9888\n",
      "[Epoch 6/8 | Step 360/600] - Loss: 1.9894\n",
      "[Epoch 6/8 | Step 370/600] - Loss: 1.9840\n",
      "[Epoch 6/8 | Step 380/600] - Loss: 1.9763\n",
      "[Epoch 6/8 | Step 390/600] - Loss: 1.9658\n",
      "[Epoch 6/8 | Step 400/600] - Loss: 1.9458\n",
      "[Epoch 6/8 | Step 410/600] - Loss: 1.9579\n",
      "[Epoch 6/8 | Step 420/600] - Loss: 1.9602\n",
      "[Epoch 6/8 | Step 430/600] - Loss: 1.9662\n",
      "[Epoch 6/8 | Step 440/600] - Loss: 1.9462\n",
      "[Epoch 6/8 | Step 450/600] - Loss: 1.9597\n",
      "[Epoch 6/8 | Step 460/600] - Loss: 1.9725\n",
      "[Epoch 6/8 | Step 470/600] - Loss: 1.9755\n",
      "[Epoch 6/8 | Step 480/600] - Loss: 1.9582\n",
      "[Epoch 6/8 | Step 490/600] - Loss: 1.9576\n",
      "[Epoch 6/8 | Step 500/600] - Loss: 1.9658\n",
      "[Epoch 6/8 | Step 510/600] - Loss: 1.9774\n",
      "[Epoch 6/8 | Step 520/600] - Loss: 1.9767\n",
      "[Epoch 6/8 | Step 530/600] - Loss: 1.9890\n",
      "[Epoch 6/8 | Step 540/600] - Loss: 1.9915\n",
      "[Epoch 6/8 | Step 550/600] - Loss: 1.9967\n",
      "[Epoch 6/8 | Step 560/600] - Loss: 2.0115\n",
      "[Epoch 6/8 | Step 570/600] - Loss: 2.0056\n",
      "[Epoch 6/8 | Step 580/600] - Loss: 2.0115\n",
      "[Epoch 6/8 | Step 590/600] - Loss: 2.0097\n",
      "Epoch 6/8 - Avg Train Loss: 2.0241, Val Loss: 2.0884\n",
      "[Epoch 7/8 | Step 0/600] - Loss: 0.4956\n",
      "[Epoch 7/8 | Step 10/600] - Loss: 1.1749\n",
      "[Epoch 7/8 | Step 20/600] - Loss: 1.3385\n",
      "[Epoch 7/8 | Step 30/600] - Loss: 1.3466\n",
      "[Epoch 7/8 | Step 40/600] - Loss: 1.3917\n",
      "[Epoch 7/8 | Step 50/600] - Loss: 1.5930\n",
      "[Epoch 7/8 | Step 60/600] - Loss: 1.5754\n",
      "[Epoch 7/8 | Step 70/600] - Loss: 1.7495\n",
      "[Epoch 7/8 | Step 80/600] - Loss: 1.7834\n",
      "[Epoch 7/8 | Step 90/600] - Loss: 1.7706\n",
      "[Epoch 7/8 | Step 100/600] - Loss: 1.8051\n",
      "[Epoch 7/8 | Step 110/600] - Loss: 1.8128\n",
      "[Epoch 7/8 | Step 120/600] - Loss: 1.7830\n",
      "[Epoch 7/8 | Step 130/600] - Loss: 1.8565\n",
      "[Epoch 7/8 | Step 140/600] - Loss: 1.8987\n",
      "[Epoch 7/8 | Step 150/600] - Loss: 1.8897\n",
      "[Epoch 7/8 | Step 160/600] - Loss: 1.9237\n",
      "[Epoch 7/8 | Step 170/600] - Loss: 1.9120\n",
      "[Epoch 7/8 | Step 180/600] - Loss: 1.8819\n",
      "[Epoch 7/8 | Step 190/600] - Loss: 1.8935\n",
      "[Epoch 7/8 | Step 200/600] - Loss: 1.9327\n",
      "[Epoch 7/8 | Step 210/600] - Loss: 1.9305\n",
      "[Epoch 7/8 | Step 220/600] - Loss: 1.9307\n",
      "[Epoch 7/8 | Step 230/600] - Loss: 1.9492\n",
      "[Epoch 7/8 | Step 240/600] - Loss: 1.9416\n",
      "[Epoch 7/8 | Step 250/600] - Loss: 1.9263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/8 | Step 260/600] - Loss: 1.9143\n",
      "[Epoch 7/8 | Step 270/600] - Loss: 1.9063\n",
      "[Epoch 7/8 | Step 280/600] - Loss: 1.9072\n",
      "[Epoch 7/8 | Step 290/600] - Loss: 1.9237\n",
      "[Epoch 7/8 | Step 300/600] - Loss: 1.9186\n",
      "[Epoch 7/8 | Step 310/600] - Loss: 1.9316\n",
      "[Epoch 7/8 | Step 320/600] - Loss: 1.9439\n",
      "[Epoch 7/8 | Step 330/600] - Loss: 1.9432\n",
      "[Epoch 7/8 | Step 340/600] - Loss: 1.9490\n",
      "[Epoch 7/8 | Step 350/600] - Loss: 1.9423\n",
      "[Epoch 7/8 | Step 360/600] - Loss: 1.9697\n",
      "[Epoch 7/8 | Step 370/600] - Loss: 1.9886\n",
      "[Epoch 7/8 | Step 380/600] - Loss: 1.9776\n",
      "[Epoch 7/8 | Step 390/600] - Loss: 1.9746\n",
      "[Epoch 7/8 | Step 400/600] - Loss: 1.9893\n",
      "[Epoch 7/8 | Step 410/600] - Loss: 2.0007\n",
      "[Epoch 7/8 | Step 420/600] - Loss: 1.9953\n",
      "[Epoch 7/8 | Step 430/600] - Loss: 2.0069\n",
      "[Epoch 7/8 | Step 440/600] - Loss: 1.9991\n",
      "[Epoch 7/8 | Step 450/600] - Loss: 1.9922\n",
      "[Epoch 7/8 | Step 460/600] - Loss: 1.9908\n",
      "[Epoch 7/8 | Step 470/600] - Loss: 2.0038\n",
      "[Epoch 7/8 | Step 480/600] - Loss: 2.0011\n",
      "[Epoch 7/8 | Step 490/600] - Loss: 1.9838\n",
      "[Epoch 7/8 | Step 500/600] - Loss: 1.9796\n",
      "[Epoch 7/8 | Step 510/600] - Loss: 1.9827\n",
      "[Epoch 7/8 | Step 520/600] - Loss: 1.9834\n",
      "[Epoch 7/8 | Step 530/600] - Loss: 1.9954\n",
      "[Epoch 7/8 | Step 540/600] - Loss: 2.0088\n",
      "[Epoch 7/8 | Step 550/600] - Loss: 2.0063\n",
      "[Epoch 7/8 | Step 560/600] - Loss: 1.9968\n",
      "[Epoch 7/8 | Step 570/600] - Loss: 1.9961\n",
      "[Epoch 7/8 | Step 580/600] - Loss: 2.0087\n",
      "[Epoch 7/8 | Step 590/600] - Loss: 2.0122\n",
      "Epoch 7/8 - Avg Train Loss: 2.0068, Val Loss: 2.0788\n",
      "[Epoch 8/8 | Step 0/600] - Loss: 0.5349\n",
      "[Epoch 8/8 | Step 10/600] - Loss: 1.8216\n",
      "[Epoch 8/8 | Step 20/600] - Loss: 1.6870\n",
      "[Epoch 8/8 | Step 30/600] - Loss: 1.8546\n",
      "[Epoch 8/8 | Step 40/600] - Loss: 1.7199\n",
      "[Epoch 8/8 | Step 50/600] - Loss: 1.8428\n",
      "[Epoch 8/8 | Step 60/600] - Loss: 1.7409\n",
      "[Epoch 8/8 | Step 70/600] - Loss: 1.9151\n",
      "[Epoch 8/8 | Step 80/600] - Loss: 1.9387\n",
      "[Epoch 8/8 | Step 90/600] - Loss: 1.9745\n",
      "[Epoch 8/8 | Step 100/600] - Loss: 2.0234\n",
      "[Epoch 8/8 | Step 110/600] - Loss: 1.9700\n",
      "[Epoch 8/8 | Step 120/600] - Loss: 1.9125\n",
      "[Epoch 8/8 | Step 130/600] - Loss: 1.9148\n",
      "[Epoch 8/8 | Step 140/600] - Loss: 1.9162\n",
      "[Epoch 8/8 | Step 150/600] - Loss: 1.9085\n",
      "[Epoch 8/8 | Step 160/600] - Loss: 1.8783\n",
      "[Epoch 8/8 | Step 170/600] - Loss: 1.8639\n",
      "[Epoch 8/8 | Step 180/600] - Loss: 1.9004\n",
      "[Epoch 8/8 | Step 190/600] - Loss: 1.9351\n",
      "[Epoch 8/8 | Step 200/600] - Loss: 1.8915\n",
      "[Epoch 8/8 | Step 210/600] - Loss: 1.9110\n",
      "[Epoch 8/8 | Step 220/600] - Loss: 1.9384\n",
      "[Epoch 8/8 | Step 230/600] - Loss: 1.9391\n",
      "[Epoch 8/8 | Step 240/600] - Loss: 1.9692\n",
      "[Epoch 8/8 | Step 250/600] - Loss: 1.9645\n",
      "[Epoch 8/8 | Step 260/600] - Loss: 1.9422\n",
      "[Epoch 8/8 | Step 270/600] - Loss: 1.9325\n",
      "[Epoch 8/8 | Step 280/600] - Loss: 1.9357\n",
      "[Epoch 8/8 | Step 290/600] - Loss: 1.9296\n",
      "[Epoch 8/8 | Step 300/600] - Loss: 1.9121\n",
      "[Epoch 8/8 | Step 310/600] - Loss: 1.9255\n",
      "[Epoch 8/8 | Step 320/600] - Loss: 1.9174\n",
      "[Epoch 8/8 | Step 330/600] - Loss: 1.9114\n",
      "[Epoch 8/8 | Step 340/600] - Loss: 1.9111\n",
      "[Epoch 8/8 | Step 350/600] - Loss: 1.9108\n",
      "[Epoch 8/8 | Step 360/600] - Loss: 1.9163\n",
      "[Epoch 8/8 | Step 370/600] - Loss: 1.9259\n",
      "[Epoch 8/8 | Step 380/600] - Loss: 1.9152\n",
      "[Epoch 8/8 | Step 390/600] - Loss: 1.9135\n",
      "[Epoch 8/8 | Step 400/600] - Loss: 1.9078\n",
      "[Epoch 8/8 | Step 410/600] - Loss: 1.9202\n",
      "[Epoch 8/8 | Step 420/600] - Loss: 1.9255\n",
      "[Epoch 8/8 | Step 430/600] - Loss: 1.9247\n",
      "[Epoch 8/8 | Step 440/600] - Loss: 1.9268\n",
      "[Epoch 8/8 | Step 450/600] - Loss: 1.9191\n",
      "[Epoch 8/8 | Step 460/600] - Loss: 1.9118\n",
      "[Epoch 8/8 | Step 470/600] - Loss: 1.9163\n",
      "[Epoch 8/8 | Step 480/600] - Loss: 1.9258\n",
      "[Epoch 8/8 | Step 490/600] - Loss: 1.9420\n",
      "[Epoch 8/8 | Step 500/600] - Loss: 1.9484\n",
      "[Epoch 8/8 | Step 510/600] - Loss: 1.9535\n",
      "[Epoch 8/8 | Step 520/600] - Loss: 1.9554\n",
      "[Epoch 8/8 | Step 530/600] - Loss: 1.9590\n",
      "[Epoch 8/8 | Step 540/600] - Loss: 1.9649\n",
      "[Epoch 8/8 | Step 550/600] - Loss: 1.9724\n",
      "[Epoch 8/8 | Step 560/600] - Loss: 1.9671\n",
      "[Epoch 8/8 | Step 570/600] - Loss: 1.9603\n",
      "[Epoch 8/8 | Step 580/600] - Loss: 1.9714\n",
      "[Epoch 8/8 | Step 590/600] - Loss: 1.9953\n",
      "Epoch 8/8 - Avg Train Loss: 1.9953, Val Loss: 2.0701\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoConfig,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from huggingface_hub import login\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    LlamaForSequenceClassification,\n",
    "    LlamaTokenizer,LlamaModel,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoConfig,\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "from huggingface_hub import login\n",
    "import bitsandbytes as bnb\n",
    "import re\n",
    "import traceback\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Set up the GPU environment and return the appropriate device.\"\"\"\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    \n",
    "  \n",
    "    torch.manual_seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    return device\n",
    "\n",
    "def setup_model_and_tokenizer(model_name, device):\n",
    "    tokenizer =  AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    model_config = AutoConfig.from_pretrained(model_name)\n",
    "    model_config.num_labels = 2\n",
    "    model_config.pad_token_id = tokenizer.pad_token_id\n",
    "    model_config.use_cache = False\n",
    "\n",
    "\n",
    "    quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "    base_model = LlamaForSequenceClassification.from_pretrained(\n",
    "        model_name, \n",
    "        config=model_config, \n",
    "        torch_dtype=torch.bfloat16, \n",
    "        quantization_config=quantization_config\n",
    "    )\n",
    "\n",
    "    lora_config = LoraConfig(r=16, lora_alpha=32, target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05, bias=\"none\", task_type=\"SEQ_CLS\")\n",
    "    model = get_peft_model(base_model, lora_config)\n",
    "    model.gradient_checkpointing_enable()\n",
    "    return model, tokenizer\n",
    "\n",
    "class PreferenceEmailDataset(Dataset):\n",
    "    def __init__(self, emails_df, tokenizer, max_length=512):\n",
    "        \"\"\"\n",
    "        Dataset to create pairs of message, preferred response, and rejected response for DPO training.\n",
    "        \"\"\"\n",
    "        self.emails_df = emails_df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.pairs = self._create_preference_pairs()\n",
    "\n",
    "    def _create_preference_pairs(self):\n",
    "        \"\"\"\n",
    "        Create pairs using emails from the dataset based on their labels.\n",
    "        \"\"\"\n",
    "        pairs = []\n",
    "        for _, selected_email in self.emails_df.iterrows():\n",
    "            selected_label = selected_email['label']\n",
    "            ham_emails = self.emails_df[self.emails_df['label'] == 0]\n",
    "            phish_emails = self.emails_df[self.emails_df['label'] == 1]\n",
    "\n",
    "            if selected_label == 1:  # Phishing email\n",
    "                preferred_email = phish_emails[phish_emails.index != selected_email.name].sample(n=1).iloc[0]\n",
    "                rejected_email = ham_emails.sample(n=1).iloc[0]\n",
    "                pairs.append({\n",
    "                    'message': selected_email,\n",
    "                    'preferred': preferred_email,\n",
    "                    'rejected': rejected_email\n",
    "                })\n",
    "            elif selected_label == 0:  # Ham email\n",
    "                preferred_email = ham_emails[ham_emails.index != selected_email.name].sample(n=1).iloc[0]\n",
    "                rejected_email = phish_emails.sample(n=1).iloc[0]\n",
    "                pairs.append({\n",
    "                    'message': selected_email,\n",
    "                    'preferred': preferred_email,\n",
    "                    'rejected': rejected_email\n",
    "                })\n",
    "\n",
    "        return pairs\n",
    "\n",
    "    def _prepare_email_input(self, message, response):\n",
    "        \"\"\"\n",
    "        Prepare the input text with formatted message and response for tokenization.\n",
    "        \"\"\"\n",
    "        formatted_input = f\"<s>[INST] {message} [/INST] {response}</s>\"\n",
    "        return self.tokenizer(\n",
    "            formatted_input,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.pairs[idx]\n",
    "        \n",
    "        \n",
    "        if pair['message']['label'] == 1:\n",
    "            message_text = (\n",
    "                \"This email is flagged as a phishing email. \"\n",
    "                \"Carefully examine the sender's address, subject line, and content of the email. \"\n",
    "                f\"Sender: {pair['message']['sender']} [SEP] \"\n",
    "                f\"Subject: {pair['message']['subject']} [SEP] \"\n",
    "                f\"Body: {pair['message']['body']}\"\n",
    "            )\n",
    "        else:\n",
    "            message_text = (\n",
    "                \"This email is flagged as a legitimate email. \"\n",
    "                \"Look for consistent and clear sender details, subject relevance, and authentic body content. \"\n",
    "                f\"Sender: {pair['message']['sender']} [SEP] \"\n",
    "                f\"Subject: {pair['message']['subject']} [SEP] \"\n",
    "                f\"Body: {pair['message']['body']}\"\n",
    "            )\n",
    "        \n",
    "        \n",
    "        preferred_response = (\n",
    "            \"This is a similar email example to the one above. \"\n",
    "            f\"Sender: {pair['preferred']['sender']} [SEP] \"\n",
    "            f\"Subject: {pair['preferred']['subject']} [SEP] \"\n",
    "            f\"Body: {pair['preferred']['body']}\"\n",
    "        )\n",
    "        rejected_response = (\n",
    "            \"This email is different in intent. Notice the sender's address, subject, and content mismatch. \"\n",
    "            f\"Sender: {pair['rejected']['sender']} [SEP] \"\n",
    "            f\"Subject: {pair['rejected']['subject']} [SEP] \"\n",
    "            f\"Body: {pair['rejected']['body']}\"\n",
    "        )\n",
    "        \n",
    "        message_inputs = self._prepare_email_input(message_text, \"\")\n",
    "        preferred_inputs = self._prepare_email_input(message_text, preferred_response)\n",
    "        rejected_inputs = self._prepare_email_input(message_text, rejected_response)\n",
    "\n",
    "        return {\n",
    "            'message_input_ids': message_inputs['input_ids'].squeeze(),\n",
    "            'message_attention_mask': message_inputs['attention_mask'].squeeze(),\n",
    "            'preferred_input_ids': preferred_inputs['input_ids'].squeeze(),\n",
    "            'preferred_attention_mask': preferred_inputs['attention_mask'].squeeze(),\n",
    "            'rejected_input_ids': rejected_inputs['input_ids'].squeeze(),\n",
    "            'rejected_attention_mask': rejected_inputs['attention_mask'].squeeze(),\n",
    "        }\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "   \n",
    "    if not isinstance(text, str):\n",
    "        text = \"\"\n",
    "    #text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    #text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def compute_dpo_loss(policy_chosen_logits, policy_rejected_logits, \n",
    "                    reference_chosen_logits, reference_rejected_logits, \n",
    "                    beta=0.2):\n",
    "   \n",
    "    epsilon = 1e-8\n",
    "    \n",
    "   \n",
    "    policy_chosen_probs = F.softmax(policy_chosen_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    policy_rejected_probs = F.softmax(policy_rejected_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    ref_chosen_probs = F.softmax(reference_chosen_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    ref_rejected_probs = F.softmax(reference_rejected_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    \n",
    "  \n",
    "    chosen_rewards = (torch.log(policy_chosen_probs + epsilon) - \n",
    "                     torch.log(ref_chosen_probs + epsilon))\n",
    "    rejected_rewards = (torch.log(policy_rejected_probs + epsilon) - \n",
    "                       torch.log(ref_rejected_probs + epsilon))\n",
    "    \n",
    "    \n",
    "    max_reward = 50.0\n",
    "    chosen_rewards = torch.clamp(chosen_rewards, -max_reward, max_reward)\n",
    "    rejected_rewards = torch.clamp(rejected_rewards, -max_reward, max_reward)\n",
    "    \n",
    "    \n",
    "    logits_diff = (chosen_rewards - rejected_rewards) / beta\n",
    "    \n",
    "    valid_mask = ~torch.isnan(logits_diff)\n",
    "    if valid_mask.any():\n",
    "        loss = -F.logsigmoid(logits_diff[valid_mask]).mean()\n",
    "    else:\n",
    "        loss = torch.tensor(0.0, device=logits_diff.device)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def train_model_dpo(policy_model, reference_model, train_loader, val_loader, \n",
    "                   optimizer, scheduler, device, num_epochs=8, beta=0.2, gradient_accumulation_steps=2):\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    policy_model = policy_model.to(device).float()\n",
    "    reference_model = reference_model.to(device).float()\n",
    "    reference_model.eval()  # Ensure reference model does not get updated during training\n",
    "    \n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        policy_model.train()\n",
    "        total_loss = 0\n",
    "        valid_steps = 0\n",
    "        \n",
    "        for step, batch in enumerate(train_loader):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            try:\n",
    "                with torch.amp.autocast('cuda', dtype=torch.float32):\n",
    "                    policy_chosen_outputs = policy_model(\n",
    "                        input_ids=batch['preferred_input_ids'],\n",
    "                        attention_mask=batch['preferred_attention_mask']\n",
    "                    )\n",
    "                    policy_rejected_outputs = policy_model(\n",
    "                        input_ids=batch['rejected_input_ids'],\n",
    "                        attention_mask=batch['rejected_attention_mask']\n",
    "                    )\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        ref_chosen_outputs = reference_model(\n",
    "                            input_ids=batch['preferred_input_ids'],\n",
    "                            attention_mask=batch['preferred_attention_mask']\n",
    "                        )\n",
    "                        ref_rejected_outputs = reference_model(\n",
    "                            input_ids=batch['rejected_input_ids'],\n",
    "                            attention_mask=batch['rejected_attention_mask']\n",
    "                        )\n",
    "                    \n",
    "                    loss = compute_dpo_loss(\n",
    "                        policy_chosen_outputs.logits,\n",
    "                        policy_rejected_outputs.logits,\n",
    "                        ref_chosen_outputs.logits,\n",
    "                        ref_rejected_outputs.logits,\n",
    "                        beta=beta\n",
    "                    )\n",
    "                    \n",
    "                    if not torch.isnan(loss) and not torch.isinf(loss):\n",
    "                        scaler.scale(loss).backward()\n",
    "                        \n",
    "                        # Gradient accumulation logic\n",
    "                        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                            scaler.unscale_(optimizer)\n",
    "                            torch.nn.utils.clip_grad_norm_(policy_model.parameters(), max_norm=1.0)\n",
    "                            scaler.step(optimizer)\n",
    "                            scaler.update()\n",
    "                            scheduler.step()\n",
    "                            optimizer.zero_grad()\n",
    "                        \n",
    "                        total_loss += loss.item()\n",
    "                        valid_steps += 1\n",
    "                    \n",
    "                    if step % 10 == 0:\n",
    "                        avg_loss = total_loss / max(valid_steps, 1)\n",
    "                        print(f\"[Epoch {epoch+1}/{num_epochs} | Step {step}/{len(train_loader)}] - Loss: {avg_loss:.4f}\")\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error in batch {step}: {str(e)}\")\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        if valid_steps > 0:\n",
    "            avg_train_loss = total_loss / valid_steps\n",
    "            val_loss = evaluate_model_dpo(policy_model, reference_model, val_loader, device, beta)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Avg Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_state = {k: v.cpu() for k, v in policy_model.state_dict().items() if isinstance(v, torch.Tensor)}\n",
    "    \n",
    "    return best_model_state\n",
    "\n",
    "def evaluate_model_dpo(policy_model, reference_model, val_loader, device, beta):\n",
    "   \n",
    "    policy_model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            with torch.amp.autocast('cuda', dtype=torch.float32):\n",
    "                policy_chosen_outputs = policy_model(\n",
    "                    input_ids=batch['preferred_input_ids'],\n",
    "                    attention_mask=batch['preferred_attention_mask']\n",
    "                )\n",
    "                policy_rejected_outputs = policy_model(\n",
    "                    input_ids=batch['rejected_input_ids'],\n",
    "                    attention_mask=batch['rejected_attention_mask']\n",
    "                )\n",
    "                \n",
    "                ref_chosen_outputs = reference_model(\n",
    "                    input_ids=batch['preferred_input_ids'],\n",
    "                    attention_mask=batch['preferred_attention_mask']\n",
    "                )\n",
    "                ref_rejected_outputs = reference_model(\n",
    "                    input_ids=batch['rejected_input_ids'],\n",
    "                    attention_mask=batch['rejected_attention_mask']\n",
    "                )\n",
    "                \n",
    "                loss = compute_dpo_loss(\n",
    "                    policy_chosen_outputs.logits,\n",
    "                    policy_rejected_outputs.logits,\n",
    "                    ref_chosen_outputs.logits,\n",
    "                    ref_rejected_outputs.logits,\n",
    "                    beta=beta\n",
    "                )\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "def main():\n",
    "\n",
    "    login(token=\"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\")\n",
    "    device = setup_environment()\n",
    "    model_name =  'meta-llama/Llama-2-7b-chat-hf'\n",
    "    data_path = os.path.expanduser(\"~/Downloads/Tune/FineTune/newdata_cleaned.csv\")\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(f\"File not found: {data_path}\")\n",
    "\n",
    "    policy_model, tokenizer = setup_model_and_tokenizer(model_name, device)\n",
    "    reference_model, _ = setup_model_and_tokenizer(model_name, device)\n",
    "    \n",
    "\n",
    "    emails_df = pd.read_csv(data_path)\n",
    "    emails_df['sender'] = emails_df['sender'].astype(str).apply(clean_text)\n",
    "    emails_df['subject'] = emails_df['subject'].astype(str).apply(clean_text)\n",
    "    emails_df['body'] = emails_df['body'].astype(str).apply(clean_text)\n",
    "\n",
    "    train_df, val_df = train_test_split(emails_df, test_size=0.2, stratify=emails_df['label'], random_state=42)\n",
    "\n",
    "  \n",
    "    train_dataset = PreferenceEmailDataset(train_df, tokenizer, max_length=512)\n",
    "    val_dataset = PreferenceEmailDataset(val_df, tokenizer, max_length=512)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # Setup optimization\n",
    "    optimizer = torch.optim.AdamW(policy_model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "    num_epochs = 8\n",
    "    num_training_steps = len(train_loader) * num_epochs\n",
    "    num_warmup_steps = num_training_steps // 20\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "\n",
    "    best_model_state = train_model_dpo(\n",
    "        policy_model,\n",
    "        reference_model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        device,\n",
    "        num_epochs=num_epochs,\n",
    "        beta=0.2\n",
    "    )\n",
    "\n",
    "   \n",
    "    output_dir = os.path.expanduser(\"~/Downloads/Tune/FineTune/dpo_7B\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    policy_model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "    config = {\n",
    "        \"model_name\": model_name,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"batch_size\": 8,\n",
    "        \"max_length\": 512,\n",
    "        \"warmup_steps\": num_warmup_steps,\n",
    "        \"total_steps\": num_training_steps,\n",
    "        \"device\": str(device),\n",
    "        \"beta\": 0.2\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"training_config.json\"), \"w\") as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5042f613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA RTX A5000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73635c52b2641af9b1f0379105265ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at dreamgen/WizardLM-2-7B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f48f61a798414eb32d798af5abf26e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at dreamgen/WizardLM-2-7B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/users/skuikel/anaconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/8 | Step 0/600] - Loss: 28.3284\n",
      "[Epoch 1/8 | Step 10/600] - Loss: 21.6973\n",
      "[Epoch 1/8 | Step 20/600] - Loss: 17.3904\n",
      "[Epoch 1/8 | Step 30/600] - Loss: 16.5516\n",
      "[Epoch 1/8 | Step 40/600] - Loss: 14.3947\n",
      "[Epoch 1/8 | Step 50/600] - Loss: 13.9590\n",
      "[Epoch 1/8 | Step 60/600] - Loss: 13.7488\n",
      "[Epoch 1/8 | Step 70/600] - Loss: 14.6531\n",
      "[Epoch 1/8 | Step 80/600] - Loss: 14.5961\n",
      "[Epoch 1/8 | Step 90/600] - Loss: 14.3592\n",
      "[Epoch 1/8 | Step 100/600] - Loss: 13.8593\n",
      "[Epoch 1/8 | Step 110/600] - Loss: 13.9053\n",
      "[Epoch 1/8 | Step 120/600] - Loss: 13.8606\n",
      "[Epoch 1/8 | Step 130/600] - Loss: 13.7220\n",
      "[Epoch 1/8 | Step 140/600] - Loss: 13.5348\n",
      "[Epoch 1/8 | Step 150/600] - Loss: 13.5671\n",
      "[Epoch 1/8 | Step 160/600] - Loss: 13.1902\n",
      "[Epoch 1/8 | Step 170/600] - Loss: 13.4731\n",
      "[Epoch 1/8 | Step 180/600] - Loss: 13.5168\n",
      "[Epoch 1/8 | Step 190/600] - Loss: 13.6146\n",
      "[Epoch 1/8 | Step 200/600] - Loss: 13.5607\n",
      "[Epoch 1/8 | Step 210/600] - Loss: 13.6931\n",
      "[Epoch 1/8 | Step 220/600] - Loss: 13.9038\n",
      "[Epoch 1/8 | Step 230/600] - Loss: 13.9643\n",
      "[Epoch 1/8 | Step 240/600] - Loss: 13.9866\n",
      "[Epoch 1/8 | Step 250/600] - Loss: 13.9732\n",
      "[Epoch 1/8 | Step 260/600] - Loss: 13.9243\n",
      "[Epoch 1/8 | Step 270/600] - Loss: 13.8057\n",
      "[Epoch 1/8 | Step 280/600] - Loss: 13.7493\n",
      "[Epoch 1/8 | Step 290/600] - Loss: 13.8063\n",
      "[Epoch 1/8 | Step 300/600] - Loss: 13.6723\n",
      "[Epoch 1/8 | Step 310/600] - Loss: 13.6774\n",
      "[Epoch 1/8 | Step 320/600] - Loss: 13.5738\n",
      "[Epoch 1/8 | Step 330/600] - Loss: 13.5605\n",
      "[Epoch 1/8 | Step 340/600] - Loss: 13.5132\n",
      "[Epoch 1/8 | Step 350/600] - Loss: 13.4996\n",
      "[Epoch 1/8 | Step 360/600] - Loss: 13.3899\n",
      "[Epoch 1/8 | Step 370/600] - Loss: 13.4283\n",
      "[Epoch 1/8 | Step 380/600] - Loss: 13.4063\n",
      "[Epoch 1/8 | Step 390/600] - Loss: 13.3344\n",
      "[Epoch 1/8 | Step 400/600] - Loss: 13.4265\n",
      "[Epoch 1/8 | Step 410/600] - Loss: 13.4140\n",
      "[Epoch 1/8 | Step 420/600] - Loss: 13.4613\n",
      "[Epoch 1/8 | Step 430/600] - Loss: 13.6193\n",
      "[Epoch 1/8 | Step 440/600] - Loss: 13.5901\n",
      "[Epoch 1/8 | Step 450/600] - Loss: 13.5705\n",
      "[Epoch 1/8 | Step 460/600] - Loss: 13.4843\n",
      "[Epoch 1/8 | Step 470/600] - Loss: 13.4291\n",
      "[Epoch 1/8 | Step 480/600] - Loss: 13.3677\n",
      "[Epoch 1/8 | Step 490/600] - Loss: 13.3239\n",
      "[Epoch 1/8 | Step 500/600] - Loss: 13.3258\n",
      "[Epoch 1/8 | Step 510/600] - Loss: 13.3321\n",
      "[Epoch 1/8 | Step 520/600] - Loss: 13.3023\n",
      "[Epoch 1/8 | Step 530/600] - Loss: 13.3141\n",
      "[Epoch 1/8 | Step 540/600] - Loss: 13.2647\n",
      "[Epoch 1/8 | Step 550/600] - Loss: 13.2096\n",
      "[Epoch 1/8 | Step 560/600] - Loss: 13.1529\n",
      "[Epoch 1/8 | Step 570/600] - Loss: 13.0640\n",
      "[Epoch 1/8 | Step 580/600] - Loss: 13.0166\n",
      "[Epoch 1/8 | Step 590/600] - Loss: 12.9696\n",
      "Epoch 1/8 - Avg Train Loss: 12.9879, Val Loss: 13.4035\n",
      "[Epoch 2/8 | Step 0/600] - Loss: 14.8780\n",
      "[Epoch 2/8 | Step 10/600] - Loss: 14.7770\n",
      "[Epoch 2/8 | Step 20/600] - Loss: 14.1212\n",
      "[Epoch 2/8 | Step 30/600] - Loss: 12.9302\n",
      "[Epoch 2/8 | Step 40/600] - Loss: 12.2818\n",
      "[Epoch 2/8 | Step 50/600] - Loss: 13.2176\n",
      "[Epoch 2/8 | Step 60/600] - Loss: 12.8005\n",
      "[Epoch 2/8 | Step 70/600] - Loss: 12.9672\n",
      "[Epoch 2/8 | Step 80/600] - Loss: 13.0119\n",
      "[Epoch 2/8 | Step 90/600] - Loss: 12.8506\n",
      "[Epoch 2/8 | Step 100/600] - Loss: 12.7853\n",
      "[Epoch 2/8 | Step 110/600] - Loss: 13.1428\n",
      "[Epoch 2/8 | Step 120/600] - Loss: 13.0169\n",
      "[Epoch 2/8 | Step 130/600] - Loss: 12.9068\n",
      "[Epoch 2/8 | Step 140/600] - Loss: 12.9393\n",
      "[Epoch 2/8 | Step 150/600] - Loss: 12.8760\n",
      "[Epoch 2/8 | Step 160/600] - Loss: 12.9765\n",
      "[Epoch 2/8 | Step 170/600] - Loss: 12.8067\n",
      "[Epoch 2/8 | Step 180/600] - Loss: 12.7133\n",
      "[Epoch 2/8 | Step 190/600] - Loss: 12.5164\n",
      "[Epoch 2/8 | Step 200/600] - Loss: 12.3610\n",
      "[Epoch 2/8 | Step 210/600] - Loss: 12.4293\n",
      "[Epoch 2/8 | Step 220/600] - Loss: 12.1700\n",
      "[Epoch 2/8 | Step 230/600] - Loss: 12.0476\n",
      "[Epoch 2/8 | Step 240/600] - Loss: 11.9524\n",
      "[Epoch 2/8 | Step 250/600] - Loss: 12.1092\n",
      "[Epoch 2/8 | Step 260/600] - Loss: 12.0026\n",
      "[Epoch 2/8 | Step 270/600] - Loss: 12.1638\n",
      "[Epoch 2/8 | Step 280/600] - Loss: 12.2009\n",
      "[Epoch 2/8 | Step 290/600] - Loss: 12.1099\n",
      "[Epoch 2/8 | Step 300/600] - Loss: 12.1432\n",
      "[Epoch 2/8 | Step 310/600] - Loss: 12.0396\n",
      "[Epoch 2/8 | Step 320/600] - Loss: 12.1513\n",
      "[Epoch 2/8 | Step 330/600] - Loss: 12.2245\n",
      "[Epoch 2/8 | Step 340/600] - Loss: 12.1012\n",
      "[Epoch 2/8 | Step 350/600] - Loss: 12.0844\n",
      "[Epoch 2/8 | Step 360/600] - Loss: 12.0873\n",
      "[Epoch 2/8 | Step 370/600] - Loss: 12.0882\n",
      "[Epoch 2/8 | Step 380/600] - Loss: 12.1458\n",
      "[Epoch 2/8 | Step 390/600] - Loss: 12.1708\n",
      "[Epoch 2/8 | Step 400/600] - Loss: 12.1333\n",
      "[Epoch 2/8 | Step 410/600] - Loss: 12.1032\n",
      "[Epoch 2/8 | Step 420/600] - Loss: 12.0341\n",
      "[Epoch 2/8 | Step 430/600] - Loss: 12.0267\n",
      "[Epoch 2/8 | Step 440/600] - Loss: 12.0024\n",
      "[Epoch 2/8 | Step 450/600] - Loss: 12.0406\n",
      "[Epoch 2/8 | Step 460/600] - Loss: 12.0562\n",
      "[Epoch 2/8 | Step 470/600] - Loss: 11.9954\n",
      "[Epoch 2/8 | Step 480/600] - Loss: 12.0679\n",
      "[Epoch 2/8 | Step 490/600] - Loss: 12.1081\n",
      "[Epoch 2/8 | Step 500/600] - Loss: 12.0684\n",
      "[Epoch 2/8 | Step 510/600] - Loss: 12.0212\n",
      "[Epoch 2/8 | Step 520/600] - Loss: 11.9635\n",
      "[Epoch 2/8 | Step 530/600] - Loss: 11.8672\n",
      "[Epoch 2/8 | Step 540/600] - Loss: 11.7857\n",
      "[Epoch 2/8 | Step 550/600] - Loss: 11.7414\n",
      "[Epoch 2/8 | Step 560/600] - Loss: 11.7947\n",
      "[Epoch 2/8 | Step 570/600] - Loss: 11.7613\n",
      "[Epoch 2/8 | Step 580/600] - Loss: 11.7645\n",
      "[Epoch 2/8 | Step 590/600] - Loss: 11.7943\n",
      "Epoch 2/8 - Avg Train Loss: 11.7887, Val Loss: 12.6885\n",
      "[Epoch 3/8 | Step 0/600] - Loss: 21.8575\n",
      "[Epoch 3/8 | Step 10/600] - Loss: 15.6985\n",
      "[Epoch 3/8 | Step 20/600] - Loss: 14.1497\n",
      "[Epoch 3/8 | Step 30/600] - Loss: 12.5798\n",
      "[Epoch 3/8 | Step 40/600] - Loss: 12.7680\n",
      "[Epoch 3/8 | Step 50/600] - Loss: 12.1643\n",
      "[Epoch 3/8 | Step 60/600] - Loss: 12.4313\n",
      "[Epoch 3/8 | Step 70/600] - Loss: 11.9262\n",
      "[Epoch 3/8 | Step 80/600] - Loss: 11.9440\n",
      "[Epoch 3/8 | Step 90/600] - Loss: 11.8760\n",
      "[Epoch 3/8 | Step 100/600] - Loss: 11.6611\n",
      "[Epoch 3/8 | Step 110/600] - Loss: 11.5583\n",
      "[Epoch 3/8 | Step 120/600] - Loss: 11.3917\n",
      "[Epoch 3/8 | Step 130/600] - Loss: 11.5536\n",
      "[Epoch 3/8 | Step 140/600] - Loss: 11.4944\n",
      "[Epoch 3/8 | Step 150/600] - Loss: 11.6309\n",
      "[Epoch 3/8 | Step 160/600] - Loss: 11.7281\n",
      "[Epoch 3/8 | Step 170/600] - Loss: 11.7907\n",
      "[Epoch 3/8 | Step 180/600] - Loss: 12.0062\n",
      "[Epoch 3/8 | Step 190/600] - Loss: 12.0391\n",
      "[Epoch 3/8 | Step 200/600] - Loss: 11.7302\n",
      "[Epoch 3/8 | Step 210/600] - Loss: 11.7573\n",
      "[Epoch 3/8 | Step 220/600] - Loss: 11.8416\n",
      "[Epoch 3/8 | Step 230/600] - Loss: 11.7958\n",
      "[Epoch 3/8 | Step 240/600] - Loss: 11.8855\n",
      "[Epoch 3/8 | Step 250/600] - Loss: 11.9625\n",
      "[Epoch 3/8 | Step 260/600] - Loss: 11.9780\n",
      "[Epoch 3/8 | Step 270/600] - Loss: 11.8046\n",
      "[Epoch 3/8 | Step 280/600] - Loss: 11.7790\n",
      "[Epoch 3/8 | Step 290/600] - Loss: 11.8037\n",
      "[Epoch 3/8 | Step 300/600] - Loss: 11.7852\n",
      "[Epoch 3/8 | Step 310/600] - Loss: 11.7263\n",
      "[Epoch 3/8 | Step 320/600] - Loss: 11.6803\n",
      "[Epoch 3/8 | Step 330/600] - Loss: 11.7477\n",
      "[Epoch 3/8 | Step 340/600] - Loss: 11.7625\n",
      "[Epoch 3/8 | Step 350/600] - Loss: 11.8284\n",
      "[Epoch 3/8 | Step 360/600] - Loss: 11.8291\n",
      "[Epoch 3/8 | Step 370/600] - Loss: 11.7310\n",
      "[Epoch 3/8 | Step 380/600] - Loss: 11.7840\n",
      "[Epoch 3/8 | Step 390/600] - Loss: 11.6957\n",
      "[Epoch 3/8 | Step 400/600] - Loss: 11.6344\n",
      "[Epoch 3/8 | Step 410/600] - Loss: 11.5289\n",
      "[Epoch 3/8 | Step 420/600] - Loss: 11.5046\n",
      "[Epoch 3/8 | Step 430/600] - Loss: 11.4756\n",
      "[Epoch 3/8 | Step 440/600] - Loss: 11.4479\n",
      "[Epoch 3/8 | Step 450/600] - Loss: 11.4321\n",
      "[Epoch 3/8 | Step 460/600] - Loss: 11.3816\n",
      "[Epoch 3/8 | Step 470/600] - Loss: 11.3155\n",
      "[Epoch 3/8 | Step 480/600] - Loss: 11.2770\n",
      "[Epoch 3/8 | Step 490/600] - Loss: 11.3588\n",
      "[Epoch 3/8 | Step 500/600] - Loss: 11.3844\n",
      "[Epoch 3/8 | Step 510/600] - Loss: 11.3388\n",
      "[Epoch 3/8 | Step 520/600] - Loss: 11.2881\n",
      "[Epoch 3/8 | Step 530/600] - Loss: 11.3341\n",
      "[Epoch 3/8 | Step 540/600] - Loss: 11.2985\n",
      "[Epoch 3/8 | Step 550/600] - Loss: 11.2934\n",
      "[Epoch 3/8 | Step 560/600] - Loss: 11.3176\n",
      "[Epoch 3/8 | Step 570/600] - Loss: 11.3194\n",
      "[Epoch 3/8 | Step 580/600] - Loss: 11.3478\n",
      "[Epoch 3/8 | Step 590/600] - Loss: 11.3311\n",
      "Epoch 3/8 - Avg Train Loss: 11.3818, Val Loss: 12.4803\n",
      "[Epoch 4/8 | Step 0/600] - Loss: 14.9130\n",
      "[Epoch 4/8 | Step 10/600] - Loss: 11.9936\n",
      "[Epoch 4/8 | Step 20/600] - Loss: 10.2038\n",
      "[Epoch 4/8 | Step 30/600] - Loss: 9.8308\n",
      "[Epoch 4/8 | Step 40/600] - Loss: 10.5420\n",
      "[Epoch 4/8 | Step 50/600] - Loss: 11.2123\n",
      "[Epoch 4/8 | Step 60/600] - Loss: 10.7474\n",
      "[Epoch 4/8 | Step 70/600] - Loss: 11.0085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/8 | Step 80/600] - Loss: 10.9356\n",
      "[Epoch 4/8 | Step 90/600] - Loss: 11.3245\n",
      "[Epoch 4/8 | Step 100/600] - Loss: 10.9931\n",
      "[Epoch 4/8 | Step 110/600] - Loss: 11.1235\n",
      "[Epoch 4/8 | Step 120/600] - Loss: 11.0677\n",
      "[Epoch 4/8 | Step 130/600] - Loss: 10.9019\n",
      "[Epoch 4/8 | Step 140/600] - Loss: 11.0965\n",
      "[Epoch 4/8 | Step 150/600] - Loss: 11.0333\n",
      "[Epoch 4/8 | Step 160/600] - Loss: 10.7755\n",
      "[Epoch 4/8 | Step 170/600] - Loss: 10.8889\n",
      "[Epoch 4/8 | Step 180/600] - Loss: 10.9961\n",
      "[Epoch 4/8 | Step 190/600] - Loss: 11.2042\n",
      "[Epoch 4/8 | Step 200/600] - Loss: 11.7233\n",
      "[Epoch 4/8 | Step 210/600] - Loss: 11.6215\n",
      "[Epoch 4/8 | Step 220/600] - Loss: 11.6170\n",
      "[Epoch 4/8 | Step 230/600] - Loss: 11.5105\n",
      "[Epoch 4/8 | Step 240/600] - Loss: 11.4006\n",
      "[Epoch 4/8 | Step 250/600] - Loss: 11.3751\n",
      "[Epoch 4/8 | Step 260/600] - Loss: 11.4267\n",
      "[Epoch 4/8 | Step 270/600] - Loss: 11.3620\n",
      "[Epoch 4/8 | Step 280/600] - Loss: 11.3083\n",
      "[Epoch 4/8 | Step 290/600] - Loss: 11.1863\n",
      "[Epoch 4/8 | Step 300/600] - Loss: 11.1607\n",
      "[Epoch 4/8 | Step 310/600] - Loss: 11.2165\n",
      "[Epoch 4/8 | Step 320/600] - Loss: 11.0607\n",
      "[Epoch 4/8 | Step 330/600] - Loss: 11.0389\n",
      "[Epoch 4/8 | Step 340/600] - Loss: 11.0937\n",
      "[Epoch 4/8 | Step 350/600] - Loss: 11.1449\n",
      "[Epoch 4/8 | Step 360/600] - Loss: 11.2840\n",
      "[Epoch 4/8 | Step 370/600] - Loss: 11.1685\n",
      "[Epoch 4/8 | Step 380/600] - Loss: 11.1194\n",
      "[Epoch 4/8 | Step 390/600] - Loss: 11.0479\n",
      "[Epoch 4/8 | Step 400/600] - Loss: 11.0083\n",
      "[Epoch 4/8 | Step 410/600] - Loss: 11.0856\n",
      "[Epoch 4/8 | Step 420/600] - Loss: 11.1045\n",
      "[Epoch 4/8 | Step 430/600] - Loss: 11.0613\n",
      "[Epoch 4/8 | Step 440/600] - Loss: 11.0255\n",
      "[Epoch 4/8 | Step 450/600] - Loss: 11.0927\n",
      "[Epoch 4/8 | Step 460/600] - Loss: 11.2105\n",
      "[Epoch 4/8 | Step 470/600] - Loss: 11.1761\n",
      "[Epoch 4/8 | Step 480/600] - Loss: 11.1692\n",
      "[Epoch 4/8 | Step 490/600] - Loss: 11.2118\n",
      "[Epoch 4/8 | Step 500/600] - Loss: 11.2035\n",
      "[Epoch 4/8 | Step 510/600] - Loss: 11.2484\n",
      "[Epoch 4/8 | Step 520/600] - Loss: 11.3004\n",
      "[Epoch 4/8 | Step 530/600] - Loss: 11.2074\n",
      "[Epoch 4/8 | Step 540/600] - Loss: 11.1905\n",
      "[Epoch 4/8 | Step 550/600] - Loss: 11.1181\n",
      "[Epoch 4/8 | Step 560/600] - Loss: 11.1191\n",
      "[Epoch 4/8 | Step 570/600] - Loss: 11.1396\n",
      "[Epoch 4/8 | Step 580/600] - Loss: 11.1558\n",
      "[Epoch 4/8 | Step 590/600] - Loss: 11.2218\n",
      "Epoch 4/8 - Avg Train Loss: 11.1818, Val Loss: 12.3642\n",
      "[Epoch 5/8 | Step 0/600] - Loss: 25.8097\n",
      "[Epoch 5/8 | Step 10/600] - Loss: 10.6261\n",
      "[Epoch 5/8 | Step 20/600] - Loss: 9.4847\n",
      "[Epoch 5/8 | Step 30/600] - Loss: 10.3928\n",
      "[Epoch 5/8 | Step 40/600] - Loss: 10.4938\n",
      "[Epoch 5/8 | Step 50/600] - Loss: 10.1036\n",
      "[Epoch 5/8 | Step 60/600] - Loss: 10.5953\n",
      "[Epoch 5/8 | Step 70/600] - Loss: 10.8785\n",
      "[Epoch 5/8 | Step 80/600] - Loss: 10.6216\n",
      "[Epoch 5/8 | Step 90/600] - Loss: 10.7942\n",
      "[Epoch 5/8 | Step 100/600] - Loss: 10.9408\n",
      "[Epoch 5/8 | Step 110/600] - Loss: 10.9053\n",
      "[Epoch 5/8 | Step 120/600] - Loss: 10.9610\n",
      "[Epoch 5/8 | Step 130/600] - Loss: 10.7722\n",
      "[Epoch 5/8 | Step 140/600] - Loss: 10.7786\n",
      "[Epoch 5/8 | Step 150/600] - Loss: 10.9294\n",
      "[Epoch 5/8 | Step 160/600] - Loss: 10.7966\n",
      "[Epoch 5/8 | Step 170/600] - Loss: 10.8907\n",
      "[Epoch 5/8 | Step 180/600] - Loss: 10.9884\n",
      "[Epoch 5/8 | Step 190/600] - Loss: 11.0081\n",
      "[Epoch 5/8 | Step 200/600] - Loss: 11.0454\n",
      "[Epoch 5/8 | Step 210/600] - Loss: 11.0884\n",
      "[Epoch 5/8 | Step 220/600] - Loss: 11.1094\n",
      "[Epoch 5/8 | Step 230/600] - Loss: 11.2319\n",
      "[Epoch 5/8 | Step 240/600] - Loss: 11.0168\n",
      "[Epoch 5/8 | Step 250/600] - Loss: 10.9072\n",
      "[Epoch 5/8 | Step 260/600] - Loss: 11.0342\n",
      "[Epoch 5/8 | Step 270/600] - Loss: 11.1748\n",
      "[Epoch 5/8 | Step 280/600] - Loss: 11.2016\n",
      "[Epoch 5/8 | Step 290/600] - Loss: 11.1624\n",
      "[Epoch 5/8 | Step 300/600] - Loss: 11.1317\n",
      "[Epoch 5/8 | Step 310/600] - Loss: 11.0088\n",
      "[Epoch 5/8 | Step 320/600] - Loss: 10.9322\n",
      "[Epoch 5/8 | Step 330/600] - Loss: 10.9761\n",
      "[Epoch 5/8 | Step 340/600] - Loss: 11.0388\n",
      "[Epoch 5/8 | Step 350/600] - Loss: 11.0226\n",
      "[Epoch 5/8 | Step 360/600] - Loss: 11.0733\n",
      "[Epoch 5/8 | Step 370/600] - Loss: 11.1020\n",
      "[Epoch 5/8 | Step 380/600] - Loss: 11.0837\n",
      "[Epoch 5/8 | Step 390/600] - Loss: 11.1403\n",
      "[Epoch 5/8 | Step 400/600] - Loss: 11.1037\n",
      "[Epoch 5/8 | Step 410/600] - Loss: 11.1547\n",
      "[Epoch 5/8 | Step 420/600] - Loss: 11.1131\n",
      "[Epoch 5/8 | Step 430/600] - Loss: 11.1349\n",
      "[Epoch 5/8 | Step 440/600] - Loss: 11.1710\n",
      "[Epoch 5/8 | Step 450/600] - Loss: 11.1521\n",
      "[Epoch 5/8 | Step 460/600] - Loss: 11.1596\n",
      "[Epoch 5/8 | Step 470/600] - Loss: 11.2265\n",
      "[Epoch 5/8 | Step 480/600] - Loss: 11.1596\n",
      "[Epoch 5/8 | Step 490/600] - Loss: 11.1781\n",
      "[Epoch 5/8 | Step 500/600] - Loss: 11.2052\n",
      "[Epoch 5/8 | Step 510/600] - Loss: 11.0944\n",
      "[Epoch 5/8 | Step 520/600] - Loss: 11.1206\n",
      "[Epoch 5/8 | Step 530/600] - Loss: 11.1188\n",
      "[Epoch 5/8 | Step 540/600] - Loss: 11.1137\n",
      "[Epoch 5/8 | Step 550/600] - Loss: 11.0939\n",
      "[Epoch 5/8 | Step 560/600] - Loss: 11.0829\n",
      "[Epoch 5/8 | Step 570/600] - Loss: 11.0478\n",
      "[Epoch 5/8 | Step 580/600] - Loss: 11.1064\n",
      "[Epoch 5/8 | Step 590/600] - Loss: 11.0874\n",
      "Epoch 5/8 - Avg Train Loss: 11.0381, Val Loss: 12.2938\n",
      "[Epoch 6/8 | Step 0/600] - Loss: 11.3661\n",
      "[Epoch 6/8 | Step 10/600] - Loss: 10.3551\n",
      "[Epoch 6/8 | Step 20/600] - Loss: 11.5488\n",
      "[Epoch 6/8 | Step 30/600] - Loss: 11.5521\n",
      "[Epoch 6/8 | Step 40/600] - Loss: 11.2872\n",
      "[Epoch 6/8 | Step 50/600] - Loss: 10.4138\n",
      "[Epoch 6/8 | Step 60/600] - Loss: 10.7641\n",
      "[Epoch 6/8 | Step 70/600] - Loss: 10.4653\n",
      "[Epoch 6/8 | Step 80/600] - Loss: 9.9876\n",
      "[Epoch 6/8 | Step 90/600] - Loss: 10.1008\n",
      "[Epoch 6/8 | Step 100/600] - Loss: 10.2028\n",
      "[Epoch 6/8 | Step 110/600] - Loss: 10.5905\n",
      "[Epoch 6/8 | Step 120/600] - Loss: 10.6811\n",
      "[Epoch 6/8 | Step 130/600] - Loss: 11.1083\n",
      "[Epoch 6/8 | Step 140/600] - Loss: 11.0430\n",
      "[Epoch 6/8 | Step 150/600] - Loss: 10.9896\n",
      "[Epoch 6/8 | Step 160/600] - Loss: 10.8457\n",
      "[Epoch 6/8 | Step 170/600] - Loss: 10.8342\n",
      "[Epoch 6/8 | Step 180/600] - Loss: 11.0380\n",
      "[Epoch 6/8 | Step 190/600] - Loss: 11.0049\n",
      "[Epoch 6/8 | Step 200/600] - Loss: 11.1347\n",
      "[Epoch 6/8 | Step 210/600] - Loss: 11.2750\n",
      "[Epoch 6/8 | Step 220/600] - Loss: 11.1527\n",
      "[Epoch 6/8 | Step 230/600] - Loss: 11.1209\n",
      "[Epoch 6/8 | Step 240/600] - Loss: 11.2322\n",
      "[Epoch 6/8 | Step 250/600] - Loss: 11.1806\n",
      "[Epoch 6/8 | Step 260/600] - Loss: 11.1555\n",
      "[Epoch 6/8 | Step 270/600] - Loss: 11.0626\n",
      "[Epoch 6/8 | Step 280/600] - Loss: 10.9782\n",
      "[Epoch 6/8 | Step 290/600] - Loss: 10.9888\n",
      "[Epoch 6/8 | Step 300/600] - Loss: 11.0668\n",
      "[Epoch 6/8 | Step 310/600] - Loss: 11.0126\n",
      "[Epoch 6/8 | Step 320/600] - Loss: 11.0308\n",
      "[Epoch 6/8 | Step 330/600] - Loss: 11.0211\n",
      "[Epoch 6/8 | Step 340/600] - Loss: 10.9290\n",
      "[Epoch 6/8 | Step 350/600] - Loss: 10.9369\n",
      "[Epoch 6/8 | Step 360/600] - Loss: 10.9109\n",
      "[Epoch 6/8 | Step 370/600] - Loss: 10.8152\n",
      "[Epoch 6/8 | Step 380/600] - Loss: 10.8187\n",
      "[Epoch 6/8 | Step 390/600] - Loss: 10.7812\n",
      "[Epoch 6/8 | Step 400/600] - Loss: 10.7995\n",
      "[Epoch 6/8 | Step 410/600] - Loss: 10.7828\n",
      "[Epoch 6/8 | Step 420/600] - Loss: 10.7334\n",
      "[Epoch 6/8 | Step 430/600] - Loss: 10.7681\n",
      "[Epoch 6/8 | Step 440/600] - Loss: 10.8845\n",
      "[Epoch 6/8 | Step 450/600] - Loss: 10.8846\n",
      "[Epoch 6/8 | Step 460/600] - Loss: 10.9951\n",
      "[Epoch 6/8 | Step 470/600] - Loss: 10.9490\n",
      "[Epoch 6/8 | Step 480/600] - Loss: 10.9581\n",
      "[Epoch 6/8 | Step 490/600] - Loss: 10.9338\n",
      "[Epoch 6/8 | Step 500/600] - Loss: 10.8611\n",
      "[Epoch 6/8 | Step 510/600] - Loss: 10.9520\n",
      "[Epoch 6/8 | Step 520/600] - Loss: 10.8686\n",
      "[Epoch 6/8 | Step 530/600] - Loss: 10.8078\n",
      "[Epoch 6/8 | Step 540/600] - Loss: 10.8261\n",
      "[Epoch 6/8 | Step 550/600] - Loss: 10.7651\n",
      "[Epoch 6/8 | Step 560/600] - Loss: 10.8020\n",
      "[Epoch 6/8 | Step 570/600] - Loss: 10.8266\n",
      "[Epoch 6/8 | Step 580/600] - Loss: 10.8182\n",
      "[Epoch 6/8 | Step 590/600] - Loss: 10.8737\n",
      "Epoch 6/8 - Avg Train Loss: 10.9336, Val Loss: 12.2642\n",
      "[Epoch 7/8 | Step 0/600] - Loss: 26.7544\n",
      "[Epoch 7/8 | Step 10/600] - Loss: 9.5192\n",
      "[Epoch 7/8 | Step 20/600] - Loss: 8.6277\n",
      "[Epoch 7/8 | Step 30/600] - Loss: 9.2856\n",
      "[Epoch 7/8 | Step 40/600] - Loss: 9.9949\n",
      "[Epoch 7/8 | Step 50/600] - Loss: 10.0775\n",
      "[Epoch 7/8 | Step 60/600] - Loss: 10.8794\n",
      "[Epoch 7/8 | Step 70/600] - Loss: 10.2053\n",
      "[Epoch 7/8 | Step 80/600] - Loss: 10.5390\n",
      "[Epoch 7/8 | Step 90/600] - Loss: 10.2851\n",
      "[Epoch 7/8 | Step 100/600] - Loss: 10.2878\n",
      "[Epoch 7/8 | Step 110/600] - Loss: 10.6758\n",
      "[Epoch 7/8 | Step 120/600] - Loss: 10.5886\n",
      "[Epoch 7/8 | Step 130/600] - Loss: 10.5260\n",
      "[Epoch 7/8 | Step 140/600] - Loss: 10.7378\n",
      "[Epoch 7/8 | Step 150/600] - Loss: 10.7862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/8 | Step 160/600] - Loss: 10.7205\n",
      "[Epoch 7/8 | Step 170/600] - Loss: 10.6518\n",
      "[Epoch 7/8 | Step 180/600] - Loss: 10.4557\n",
      "[Epoch 7/8 | Step 190/600] - Loss: 10.5396\n",
      "[Epoch 7/8 | Step 200/600] - Loss: 10.5080\n",
      "[Epoch 7/8 | Step 210/600] - Loss: 10.5458\n",
      "[Epoch 7/8 | Step 220/600] - Loss: 10.4530\n",
      "[Epoch 7/8 | Step 230/600] - Loss: 10.5861\n",
      "[Epoch 7/8 | Step 240/600] - Loss: 10.4968\n",
      "[Epoch 7/8 | Step 250/600] - Loss: 10.4275\n",
      "[Epoch 7/8 | Step 260/600] - Loss: 10.3452\n",
      "[Epoch 7/8 | Step 270/600] - Loss: 10.4414\n",
      "[Epoch 7/8 | Step 280/600] - Loss: 10.4256\n",
      "[Epoch 7/8 | Step 290/600] - Loss: 10.5070\n",
      "[Epoch 7/8 | Step 300/600] - Loss: 10.3550\n",
      "[Epoch 7/8 | Step 310/600] - Loss: 10.3921\n",
      "[Epoch 7/8 | Step 320/600] - Loss: 10.4178\n",
      "[Epoch 7/8 | Step 330/600] - Loss: 10.4925\n",
      "[Epoch 7/8 | Step 340/600] - Loss: 10.5791\n",
      "[Epoch 7/8 | Step 350/600] - Loss: 10.5651\n",
      "[Epoch 7/8 | Step 360/600] - Loss: 10.5216\n",
      "[Epoch 7/8 | Step 370/600] - Loss: 10.4972\n",
      "[Epoch 7/8 | Step 380/600] - Loss: 10.4062\n",
      "[Epoch 7/8 | Step 390/600] - Loss: 10.5484\n",
      "[Epoch 7/8 | Step 400/600] - Loss: 10.5476\n",
      "[Epoch 7/8 | Step 410/600] - Loss: 10.5768\n",
      "[Epoch 7/8 | Step 420/600] - Loss: 10.5682\n",
      "[Epoch 7/8 | Step 430/600] - Loss: 10.6284\n",
      "[Epoch 7/8 | Step 440/600] - Loss: 10.6145\n",
      "[Epoch 7/8 | Step 450/600] - Loss: 10.5829\n",
      "[Epoch 7/8 | Step 460/600] - Loss: 10.5740\n",
      "[Epoch 7/8 | Step 470/600] - Loss: 10.5833\n",
      "[Epoch 7/8 | Step 480/600] - Loss: 10.6241\n",
      "[Epoch 7/8 | Step 490/600] - Loss: 10.6201\n",
      "[Epoch 7/8 | Step 500/600] - Loss: 10.6611\n",
      "[Epoch 7/8 | Step 510/600] - Loss: 10.7223\n",
      "[Epoch 7/8 | Step 520/600] - Loss: 10.7289\n",
      "[Epoch 7/8 | Step 530/600] - Loss: 10.7280\n",
      "[Epoch 7/8 | Step 540/600] - Loss: 10.7019\n",
      "[Epoch 7/8 | Step 550/600] - Loss: 10.7570\n",
      "[Epoch 7/8 | Step 560/600] - Loss: 10.7819\n",
      "[Epoch 7/8 | Step 570/600] - Loss: 10.7576\n",
      "[Epoch 7/8 | Step 580/600] - Loss: 10.8319\n",
      "[Epoch 7/8 | Step 590/600] - Loss: 10.8150\n",
      "Epoch 7/8 - Avg Train Loss: 10.8455, Val Loss: 12.2432\n",
      "[Epoch 8/8 | Step 0/600] - Loss: 4.3006\n",
      "[Epoch 8/8 | Step 10/600] - Loss: 11.5177\n",
      "[Epoch 8/8 | Step 20/600] - Loss: 10.2245\n",
      "[Epoch 8/8 | Step 30/600] - Loss: 10.9881\n",
      "[Epoch 8/8 | Step 40/600] - Loss: 10.0225\n",
      "[Epoch 8/8 | Step 50/600] - Loss: 9.8413\n",
      "[Epoch 8/8 | Step 60/600] - Loss: 9.5850\n",
      "[Epoch 8/8 | Step 70/600] - Loss: 9.5756\n",
      "[Epoch 8/8 | Step 80/600] - Loss: 10.1648\n",
      "[Epoch 8/8 | Step 90/600] - Loss: 10.4834\n",
      "[Epoch 8/8 | Step 100/600] - Loss: 10.5543\n",
      "[Epoch 8/8 | Step 110/600] - Loss: 10.9973\n",
      "[Epoch 8/8 | Step 120/600] - Loss: 10.7158\n",
      "[Epoch 8/8 | Step 130/600] - Loss: 10.6028\n",
      "[Epoch 8/8 | Step 140/600] - Loss: 10.4214\n",
      "[Epoch 8/8 | Step 150/600] - Loss: 10.2926\n",
      "[Epoch 8/8 | Step 160/600] - Loss: 10.3493\n",
      "[Epoch 8/8 | Step 170/600] - Loss: 10.4034\n",
      "[Epoch 8/8 | Step 180/600] - Loss: 10.2744\n",
      "[Epoch 8/8 | Step 190/600] - Loss: 10.2839\n",
      "[Epoch 8/8 | Step 200/600] - Loss: 10.2279\n",
      "[Epoch 8/8 | Step 210/600] - Loss: 10.4157\n",
      "[Epoch 8/8 | Step 220/600] - Loss: 10.3427\n",
      "[Epoch 8/8 | Step 230/600] - Loss: 10.2037\n",
      "[Epoch 8/8 | Step 240/600] - Loss: 10.0303\n",
      "[Epoch 8/8 | Step 250/600] - Loss: 10.0633\n",
      "[Epoch 8/8 | Step 260/600] - Loss: 10.0005\n",
      "[Epoch 8/8 | Step 270/600] - Loss: 9.9934\n",
      "[Epoch 8/8 | Step 280/600] - Loss: 10.0027\n",
      "[Epoch 8/8 | Step 290/600] - Loss: 10.0169\n",
      "[Epoch 8/8 | Step 300/600] - Loss: 10.2042\n",
      "[Epoch 8/8 | Step 310/600] - Loss: 10.3361\n",
      "[Epoch 8/8 | Step 320/600] - Loss: 10.3617\n",
      "[Epoch 8/8 | Step 330/600] - Loss: 10.3324\n",
      "[Epoch 8/8 | Step 340/600] - Loss: 10.4120\n",
      "[Epoch 8/8 | Step 350/600] - Loss: 10.3836\n",
      "[Epoch 8/8 | Step 360/600] - Loss: 10.3862\n",
      "[Epoch 8/8 | Step 370/600] - Loss: 10.3111\n",
      "[Epoch 8/8 | Step 380/600] - Loss: 10.3467\n",
      "[Epoch 8/8 | Step 390/600] - Loss: 10.3846\n",
      "[Epoch 8/8 | Step 400/600] - Loss: 10.3119\n",
      "[Epoch 8/8 | Step 410/600] - Loss: 10.3219\n",
      "[Epoch 8/8 | Step 420/600] - Loss: 10.3782\n",
      "[Epoch 8/8 | Step 430/600] - Loss: 10.4167\n",
      "[Epoch 8/8 | Step 440/600] - Loss: 10.4225\n",
      "[Epoch 8/8 | Step 450/600] - Loss: 10.5222\n",
      "[Epoch 8/8 | Step 460/600] - Loss: 10.5428\n",
      "[Epoch 8/8 | Step 470/600] - Loss: 10.5669\n",
      "[Epoch 8/8 | Step 480/600] - Loss: 10.5522\n",
      "[Epoch 8/8 | Step 490/600] - Loss: 10.6104\n",
      "[Epoch 8/8 | Step 500/600] - Loss: 10.5454\n",
      "[Epoch 8/8 | Step 510/600] - Loss: 10.4940\n",
      "[Epoch 8/8 | Step 520/600] - Loss: 10.5313\n",
      "[Epoch 8/8 | Step 530/600] - Loss: 10.5279\n",
      "[Epoch 8/8 | Step 540/600] - Loss: 10.5319\n",
      "[Epoch 8/8 | Step 550/600] - Loss: 10.5096\n",
      "[Epoch 8/8 | Step 560/600] - Loss: 10.5354\n",
      "[Epoch 8/8 | Step 570/600] - Loss: 10.6095\n",
      "[Epoch 8/8 | Step 580/600] - Loss: 10.6965\n",
      "[Epoch 8/8 | Step 590/600] - Loss: 10.7679\n",
      "Epoch 8/8 - Avg Train Loss: 10.7720, Val Loss: 12.2357\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoConfig,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from huggingface_hub import login\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    LlamaForSequenceClassification,\n",
    "    LlamaTokenizer,LlamaModel,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoConfig,\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "from huggingface_hub import login\n",
    "import bitsandbytes as bnb\n",
    "import re\n",
    "import traceback\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Set up the GPU environment and return the appropriate device.\"\"\"\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    \n",
    "  \n",
    "    torch.manual_seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    return device\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "\n",
    "def setup_model_and_tokenizer(model_name, device):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    model_config = AutoConfig.from_pretrained(model_name)\n",
    "    model_config.num_labels = 2\n",
    "    model_config.pad_token_id = tokenizer.pad_token_id\n",
    "    model_config.use_cache = False\n",
    "\n",
    "   \n",
    "    quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        config=model_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        quantization_config=quantization_config\n",
    "    )\n",
    "\n",
    "    lora_config = LoraConfig(r=16, lora_alpha=32, target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05, bias=\"none\", task_type=\"SEQ_CLS\")\n",
    "    model = get_peft_model(base_model, lora_config)\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "class PreferenceEmailDataset(Dataset):\n",
    "    def __init__(self, emails_df, tokenizer, max_length=512):\n",
    "        \"\"\"\n",
    "        Dataset to create pairs of message, preferred response, and rejected response for DPO training.\n",
    "        \"\"\"\n",
    "        self.emails_df = emails_df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.pairs = self._create_preference_pairs()\n",
    "\n",
    "    def _create_preference_pairs(self):\n",
    "        \"\"\"\n",
    "        Create pairs using emails from the dataset based on their labels.\n",
    "        \"\"\"\n",
    "        pairs = []\n",
    "        for _, selected_email in self.emails_df.iterrows():\n",
    "            selected_label = selected_email['label']\n",
    "            ham_emails = self.emails_df[self.emails_df['label'] == 0]\n",
    "            phish_emails = self.emails_df[self.emails_df['label'] == 1]\n",
    "\n",
    "            if selected_label == 1:  # Phishing email\n",
    "                preferred_email = phish_emails[phish_emails.index != selected_email.name].sample(n=1).iloc[0]\n",
    "                rejected_email = ham_emails.sample(n=1).iloc[0]\n",
    "                pairs.append({\n",
    "                    'message': selected_email,\n",
    "                    'preferred': preferred_email,\n",
    "                    'rejected': rejected_email\n",
    "                })\n",
    "            elif selected_label == 0:  # Ham email\n",
    "                preferred_email = ham_emails[ham_emails.index != selected_email.name].sample(n=1).iloc[0]\n",
    "                rejected_email = phish_emails.sample(n=1).iloc[0]\n",
    "                pairs.append({\n",
    "                    'message': selected_email,\n",
    "                    'preferred': preferred_email,\n",
    "                    'rejected': rejected_email\n",
    "                })\n",
    "\n",
    "        return pairs\n",
    "\n",
    "    def _prepare_email_input(self, message, response):\n",
    "        \"\"\"\n",
    "        Prepare the input text with formatted message and response for tokenization.\n",
    "        \"\"\"\n",
    "        formatted_input = f\"<s>[INST] {message} [/INST] {response}</s>\"\n",
    "        return self.tokenizer(\n",
    "            formatted_input,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.pairs[idx]\n",
    "        \n",
    "        \n",
    "        if pair['message']['label'] == 1:\n",
    "            message_text = (\n",
    "                \"This email is flagged as a phishing email. \"\n",
    "                \"Carefully examine the sender's address, subject line, and content of the email. \"\n",
    "                f\"Sender: {pair['message']['sender']} [SEP] \"\n",
    "                f\"Subject: {pair['message']['subject']} [SEP] \"\n",
    "                f\"Body: {pair['message']['body']}\"\n",
    "            )\n",
    "        else:\n",
    "            message_text = (\n",
    "                \"This email is flagged as a legitimate email. \"\n",
    "                \"Look for consistent and clear sender details, subject relevance, and authentic body content. \"\n",
    "                f\"Sender: {pair['message']['sender']} [SEP] \"\n",
    "                f\"Subject: {pair['message']['subject']} [SEP] \"\n",
    "                f\"Body: {pair['message']['body']}\"\n",
    "            )\n",
    "        \n",
    "        \n",
    "        preferred_response = (\n",
    "            \"This is a similar email example to the one above. \"\n",
    "            f\"Sender: {pair['preferred']['sender']} [SEP] \"\n",
    "            f\"Subject: {pair['preferred']['subject']} [SEP] \"\n",
    "            f\"Body: {pair['preferred']['body']}\"\n",
    "        )\n",
    "        rejected_response = (\n",
    "            \"This email is different in intent. Notice the sender's address, subject, and content mismatch. \"\n",
    "            f\"Sender: {pair['rejected']['sender']} [SEP] \"\n",
    "            f\"Subject: {pair['rejected']['subject']} [SEP] \"\n",
    "            f\"Body: {pair['rejected']['body']}\"\n",
    "        )\n",
    "        \n",
    "        message_inputs = self._prepare_email_input(message_text, \"\")\n",
    "        preferred_inputs = self._prepare_email_input(message_text, preferred_response)\n",
    "        rejected_inputs = self._prepare_email_input(message_text, rejected_response)\n",
    "\n",
    "        return {\n",
    "            'message_input_ids': message_inputs['input_ids'].squeeze(),\n",
    "            'message_attention_mask': message_inputs['attention_mask'].squeeze(),\n",
    "            'preferred_input_ids': preferred_inputs['input_ids'].squeeze(),\n",
    "            'preferred_attention_mask': preferred_inputs['attention_mask'].squeeze(),\n",
    "            'rejected_input_ids': rejected_inputs['input_ids'].squeeze(),\n",
    "            'rejected_attention_mask': rejected_inputs['attention_mask'].squeeze(),\n",
    "        }\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "   \n",
    "    if not isinstance(text, str):\n",
    "        text = \"\"\n",
    "    #text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    #text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def compute_dpo_loss(policy_chosen_logits, policy_rejected_logits, \n",
    "                    reference_chosen_logits, reference_rejected_logits, \n",
    "                    beta=0.2):\n",
    "   \n",
    "    epsilon = 1e-8\n",
    "    \n",
    "   \n",
    "    policy_chosen_probs = F.softmax(policy_chosen_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    policy_rejected_probs = F.softmax(policy_rejected_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    ref_chosen_probs = F.softmax(reference_chosen_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    ref_rejected_probs = F.softmax(reference_rejected_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    \n",
    "  \n",
    "    chosen_rewards = (torch.log(policy_chosen_probs + epsilon) - \n",
    "                     torch.log(ref_chosen_probs + epsilon))\n",
    "    rejected_rewards = (torch.log(policy_rejected_probs + epsilon) - \n",
    "                       torch.log(ref_rejected_probs + epsilon))\n",
    "    \n",
    "    \n",
    "    max_reward = 50.0\n",
    "    chosen_rewards = torch.clamp(chosen_rewards, -max_reward, max_reward)\n",
    "    rejected_rewards = torch.clamp(rejected_rewards, -max_reward, max_reward)\n",
    "    \n",
    "    \n",
    "    logits_diff = (chosen_rewards - rejected_rewards) / beta\n",
    "    \n",
    "    valid_mask = ~torch.isnan(logits_diff)\n",
    "    if valid_mask.any():\n",
    "        loss = -F.logsigmoid(logits_diff[valid_mask]).mean()\n",
    "    else:\n",
    "        loss = torch.tensor(0.0, device=logits_diff.device)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def train_model_dpo(policy_model, reference_model, train_loader, val_loader, \n",
    "                   optimizer, scheduler, device, num_epochs=8, beta=0.2, gradient_accumulation_steps=2):\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    policy_model = policy_model.to(device).float()\n",
    "    reference_model = reference_model.to(device).float()\n",
    "    reference_model.eval()  # Ensure reference model does not get updated during training\n",
    "    \n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        policy_model.train()\n",
    "        total_loss = 0\n",
    "        valid_steps = 0\n",
    "        \n",
    "        for step, batch in enumerate(train_loader):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            try:\n",
    "                with torch.amp.autocast('cuda', dtype=torch.float32):\n",
    "                    policy_chosen_outputs = policy_model(\n",
    "                        input_ids=batch['preferred_input_ids'],\n",
    "                        attention_mask=batch['preferred_attention_mask']\n",
    "                    )\n",
    "                    policy_rejected_outputs = policy_model(\n",
    "                        input_ids=batch['rejected_input_ids'],\n",
    "                        attention_mask=batch['rejected_attention_mask']\n",
    "                    )\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        ref_chosen_outputs = reference_model(\n",
    "                            input_ids=batch['preferred_input_ids'],\n",
    "                            attention_mask=batch['preferred_attention_mask']\n",
    "                        )\n",
    "                        ref_rejected_outputs = reference_model(\n",
    "                            input_ids=batch['rejected_input_ids'],\n",
    "                            attention_mask=batch['rejected_attention_mask']\n",
    "                        )\n",
    "                    \n",
    "                    loss = compute_dpo_loss(\n",
    "                        policy_chosen_outputs.logits,\n",
    "                        policy_rejected_outputs.logits,\n",
    "                        ref_chosen_outputs.logits,\n",
    "                        ref_rejected_outputs.logits,\n",
    "                        beta=beta\n",
    "                    )\n",
    "                    \n",
    "                    if not torch.isnan(loss) and not torch.isinf(loss):\n",
    "                        scaler.scale(loss).backward()\n",
    "                        \n",
    "                        # Gradient accumulation logic\n",
    "                        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                            scaler.unscale_(optimizer)\n",
    "                            torch.nn.utils.clip_grad_norm_(policy_model.parameters(), max_norm=1.0)\n",
    "                            scaler.step(optimizer)\n",
    "                            scaler.update()\n",
    "                            scheduler.step()\n",
    "                            optimizer.zero_grad()\n",
    "                        \n",
    "                        total_loss += loss.item()\n",
    "                        valid_steps += 1\n",
    "                    \n",
    "                    if step % 10 == 0:\n",
    "                        avg_loss = total_loss / max(valid_steps, 1)\n",
    "                        print(f\"[Epoch {epoch+1}/{num_epochs} | Step {step}/{len(train_loader)}] - Loss: {avg_loss:.4f}\")\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error in batch {step}: {str(e)}\")\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        if valid_steps > 0:\n",
    "            avg_train_loss = total_loss / valid_steps\n",
    "            val_loss = evaluate_model_dpo(policy_model, reference_model, val_loader, device, beta)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Avg Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_state = {k: v.cpu() for k, v in policy_model.state_dict().items() if isinstance(v, torch.Tensor)}\n",
    "    \n",
    "    return best_model_state\n",
    "\n",
    "def evaluate_model_dpo(policy_model, reference_model, val_loader, device, beta):\n",
    "   \n",
    "    policy_model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            with torch.amp.autocast('cuda', dtype=torch.float32):\n",
    "                policy_chosen_outputs = policy_model(\n",
    "                    input_ids=batch['preferred_input_ids'],\n",
    "                    attention_mask=batch['preferred_attention_mask']\n",
    "                )\n",
    "                policy_rejected_outputs = policy_model(\n",
    "                    input_ids=batch['rejected_input_ids'],\n",
    "                    attention_mask=batch['rejected_attention_mask']\n",
    "                )\n",
    "                \n",
    "                ref_chosen_outputs = reference_model(\n",
    "                    input_ids=batch['preferred_input_ids'],\n",
    "                    attention_mask=batch['preferred_attention_mask']\n",
    "                )\n",
    "                ref_rejected_outputs = reference_model(\n",
    "                    input_ids=batch['rejected_input_ids'],\n",
    "                    attention_mask=batch['rejected_attention_mask']\n",
    "                )\n",
    "                \n",
    "                loss = compute_dpo_loss(\n",
    "                    policy_chosen_outputs.logits,\n",
    "                    policy_rejected_outputs.logits,\n",
    "                    ref_chosen_outputs.logits,\n",
    "                    ref_rejected_outputs.logits,\n",
    "                    beta=beta\n",
    "                )\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "def main():\n",
    "\n",
    "    login(token=\"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\")\n",
    "    device = setup_environment()\n",
    "    model_name =   'dreamgen/WizardLM-2-7B'\n",
    "    data_path = os.path.expanduser(\"~/Downloads/Tune/FineTune/newdata_cleaned.csv\")\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(f\"File not found: {data_path}\")\n",
    "\n",
    "    policy_model, tokenizer = setup_model_and_tokenizer(model_name, device)\n",
    "    reference_model, _ = setup_model_and_tokenizer(model_name, device)\n",
    "    \n",
    "\n",
    "    emails_df = pd.read_csv(data_path)\n",
    "    emails_df['sender'] = emails_df['sender'].astype(str).apply(clean_text)\n",
    "    emails_df['subject'] = emails_df['subject'].astype(str).apply(clean_text)\n",
    "    emails_df['body'] = emails_df['body'].astype(str).apply(clean_text)\n",
    "\n",
    "    train_df, val_df = train_test_split(emails_df, test_size=0.2, stratify=emails_df['label'], random_state=42)\n",
    "\n",
    "  \n",
    "    train_dataset = PreferenceEmailDataset(train_df, tokenizer, max_length=512)\n",
    "    val_dataset = PreferenceEmailDataset(val_df, tokenizer, max_length=512)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # Setup optimization\n",
    "    optimizer = torch.optim.AdamW(policy_model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "    num_epochs = 8\n",
    "    num_training_steps = len(train_loader) * num_epochs\n",
    "    num_warmup_steps = num_training_steps // 20\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "\n",
    "    best_model_state = train_model_dpo(\n",
    "        policy_model,\n",
    "        reference_model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        device,\n",
    "        num_epochs=num_epochs,\n",
    "        beta=0.2\n",
    "    )\n",
    "\n",
    "   \n",
    "    output_dir = os.path.expanduser(\"~/Downloads/Tune/FineTune/dpo_7B_Wizard\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    policy_model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "    config = {\n",
    "        \"model_name\": model_name,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"batch_size\": 8,\n",
    "        \"max_length\": 512,\n",
    "        \"warmup_steps\": num_warmup_steps,\n",
    "        \"total_steps\": num_training_steps,\n",
    "        \"device\": str(device),\n",
    "        \"beta\": 0.2\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"training_config.json\"), \"w\") as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "747a2a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA RTX A5000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fad9ec31ac4eb093c8cee3962788b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8681fda464d411686c150d4f1f733ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/users/skuikel/anaconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/8 | Step 0/600] - Loss: 5.9304\n",
      "[Epoch 1/8 | Step 10/600] - Loss: 3.0329\n",
      "[Epoch 1/8 | Step 20/600] - Loss: 2.3218\n",
      "[Epoch 1/8 | Step 30/600] - Loss: 2.3063\n",
      "[Epoch 1/8 | Step 40/600] - Loss: 2.3573\n",
      "[Epoch 1/8 | Step 50/600] - Loss: 2.3593\n",
      "[Epoch 1/8 | Step 60/600] - Loss: 2.3306\n",
      "[Epoch 1/8 | Step 70/600] - Loss: 2.2590\n",
      "[Epoch 1/8 | Step 80/600] - Loss: 2.2863\n",
      "[Epoch 1/8 | Step 90/600] - Loss: 2.2815\n",
      "[Epoch 1/8 | Step 100/600] - Loss: 2.2803\n",
      "[Epoch 1/8 | Step 110/600] - Loss: 2.2747\n",
      "[Epoch 1/8 | Step 120/600] - Loss: 2.2263\n",
      "[Epoch 1/8 | Step 130/600] - Loss: 2.2265\n",
      "[Epoch 1/8 | Step 140/600] - Loss: 2.2109\n",
      "[Epoch 1/8 | Step 150/600] - Loss: 2.1348\n",
      "[Epoch 1/8 | Step 160/600] - Loss: 2.1920\n",
      "[Epoch 1/8 | Step 170/600] - Loss: 2.2194\n",
      "[Epoch 1/8 | Step 180/600] - Loss: 2.2029\n",
      "[Epoch 1/8 | Step 190/600] - Loss: 2.1642\n",
      "[Epoch 1/8 | Step 200/600] - Loss: 2.1566\n",
      "[Epoch 1/8 | Step 210/600] - Loss: 2.1663\n",
      "[Epoch 1/8 | Step 220/600] - Loss: 2.1831\n",
      "[Epoch 1/8 | Step 230/600] - Loss: 2.1866\n",
      "[Epoch 1/8 | Step 240/600] - Loss: 2.1659\n",
      "[Epoch 1/8 | Step 250/600] - Loss: 2.1604\n",
      "[Epoch 1/8 | Step 260/600] - Loss: 2.1623\n",
      "[Epoch 1/8 | Step 270/600] - Loss: 2.1296\n",
      "[Epoch 1/8 | Step 280/600] - Loss: 2.1536\n",
      "[Epoch 1/8 | Step 290/600] - Loss: 2.1656\n",
      "[Epoch 1/8 | Step 300/600] - Loss: 2.1866\n",
      "[Epoch 1/8 | Step 310/600] - Loss: 2.2141\n",
      "[Epoch 1/8 | Step 320/600] - Loss: 2.2065\n",
      "[Epoch 1/8 | Step 330/600] - Loss: 2.2035\n",
      "[Epoch 1/8 | Step 340/600] - Loss: 2.1945\n",
      "[Epoch 1/8 | Step 350/600] - Loss: 2.1954\n",
      "[Epoch 1/8 | Step 360/600] - Loss: 2.1782\n",
      "[Epoch 1/8 | Step 370/600] - Loss: 2.1624\n",
      "[Epoch 1/8 | Step 380/600] - Loss: 2.1846\n",
      "[Epoch 1/8 | Step 390/600] - Loss: 2.1793\n",
      "[Epoch 1/8 | Step 400/600] - Loss: 2.1897\n",
      "[Epoch 1/8 | Step 410/600] - Loss: 2.1649\n",
      "[Epoch 1/8 | Step 420/600] - Loss: 2.1457\n",
      "[Epoch 1/8 | Step 430/600] - Loss: 2.1365\n",
      "[Epoch 1/8 | Step 440/600] - Loss: 2.1371\n",
      "[Epoch 1/8 | Step 450/600] - Loss: 2.1384\n",
      "[Epoch 1/8 | Step 460/600] - Loss: 2.1312\n",
      "[Epoch 1/8 | Step 470/600] - Loss: 2.1124\n",
      "[Epoch 1/8 | Step 480/600] - Loss: 2.1130\n",
      "[Epoch 1/8 | Step 490/600] - Loss: 2.1257\n",
      "[Epoch 1/8 | Step 500/600] - Loss: 2.1205\n",
      "[Epoch 1/8 | Step 510/600] - Loss: 2.1048\n",
      "[Epoch 1/8 | Step 520/600] - Loss: 2.0912\n",
      "[Epoch 1/8 | Step 530/600] - Loss: 2.0853\n",
      "[Epoch 1/8 | Step 540/600] - Loss: 2.0773\n",
      "[Epoch 1/8 | Step 550/600] - Loss: 2.0735\n",
      "[Epoch 1/8 | Step 560/600] - Loss: 2.0552\n",
      "[Epoch 1/8 | Step 570/600] - Loss: 2.0423\n",
      "[Epoch 1/8 | Step 580/600] - Loss: 2.0208\n",
      "[Epoch 1/8 | Step 590/600] - Loss: 2.0070\n",
      "Epoch 1/8 - Avg Train Loss: 2.0039, Val Loss: 1.6029\n",
      "[Epoch 2/8 | Step 0/600] - Loss: 0.9850\n",
      "[Epoch 2/8 | Step 10/600] - Loss: 1.0529\n",
      "[Epoch 2/8 | Step 20/600] - Loss: 1.0662\n",
      "[Epoch 2/8 | Step 30/600] - Loss: 1.2141\n",
      "[Epoch 2/8 | Step 40/600] - Loss: 1.3710\n",
      "[Epoch 2/8 | Step 50/600] - Loss: 1.3978\n",
      "[Epoch 2/8 | Step 60/600] - Loss: 1.3274\n",
      "[Epoch 2/8 | Step 70/600] - Loss: 1.3728\n",
      "[Epoch 2/8 | Step 80/600] - Loss: 1.4299\n",
      "[Epoch 2/8 | Step 90/600] - Loss: 1.4137\n",
      "[Epoch 2/8 | Step 100/600] - Loss: 1.3553\n",
      "[Epoch 2/8 | Step 110/600] - Loss: 1.3650\n",
      "[Epoch 2/8 | Step 120/600] - Loss: 1.3268\n",
      "[Epoch 2/8 | Step 130/600] - Loss: 1.3357\n",
      "[Epoch 2/8 | Step 140/600] - Loss: 1.3229\n",
      "[Epoch 2/8 | Step 150/600] - Loss: 1.3490\n",
      "[Epoch 2/8 | Step 160/600] - Loss: 1.3580\n",
      "[Epoch 2/8 | Step 170/600] - Loss: 1.3563\n",
      "[Epoch 2/8 | Step 180/600] - Loss: 1.3834\n",
      "[Epoch 2/8 | Step 190/600] - Loss: 1.3802\n",
      "[Epoch 2/8 | Step 200/600] - Loss: 1.3962\n",
      "[Epoch 2/8 | Step 210/600] - Loss: 1.3825\n",
      "[Epoch 2/8 | Step 220/600] - Loss: 1.3589\n",
      "[Epoch 2/8 | Step 230/600] - Loss: 1.3506\n",
      "[Epoch 2/8 | Step 240/600] - Loss: 1.3290\n",
      "[Epoch 2/8 | Step 250/600] - Loss: 1.3301\n",
      "[Epoch 2/8 | Step 260/600] - Loss: 1.3275\n",
      "[Epoch 2/8 | Step 270/600] - Loss: 1.3414\n",
      "[Epoch 2/8 | Step 280/600] - Loss: 1.3282\n",
      "[Epoch 2/8 | Step 290/600] - Loss: 1.3191\n",
      "[Epoch 2/8 | Step 300/600] - Loss: 1.3156\n",
      "[Epoch 2/8 | Step 310/600] - Loss: 1.3143\n",
      "[Epoch 2/8 | Step 320/600] - Loss: 1.3247\n",
      "[Epoch 2/8 | Step 330/600] - Loss: 1.3301\n",
      "[Epoch 2/8 | Step 340/600] - Loss: 1.3192\n",
      "[Epoch 2/8 | Step 350/600] - Loss: 1.3389\n",
      "[Epoch 2/8 | Step 360/600] - Loss: 1.3444\n",
      "[Epoch 2/8 | Step 370/600] - Loss: 1.3435\n",
      "[Epoch 2/8 | Step 380/600] - Loss: 1.3332\n",
      "[Epoch 2/8 | Step 390/600] - Loss: 1.3227\n",
      "[Epoch 2/8 | Step 400/600] - Loss: 1.3295\n",
      "[Epoch 2/8 | Step 410/600] - Loss: 1.3300\n",
      "[Epoch 2/8 | Step 420/600] - Loss: 1.3322\n",
      "[Epoch 2/8 | Step 430/600] - Loss: 1.3349\n",
      "[Epoch 2/8 | Step 440/600] - Loss: 1.3506\n",
      "[Epoch 2/8 | Step 450/600] - Loss: 1.3591\n",
      "[Epoch 2/8 | Step 460/600] - Loss: 1.3515\n",
      "[Epoch 2/8 | Step 470/600] - Loss: 1.3502\n",
      "[Epoch 2/8 | Step 480/600] - Loss: 1.3500\n",
      "[Epoch 2/8 | Step 490/600] - Loss: 1.3526\n",
      "[Epoch 2/8 | Step 500/600] - Loss: 1.3503\n",
      "[Epoch 2/8 | Step 510/600] - Loss: 1.3486\n",
      "[Epoch 2/8 | Step 520/600] - Loss: 1.3649\n",
      "[Epoch 2/8 | Step 530/600] - Loss: 1.3490\n",
      "[Epoch 2/8 | Step 540/600] - Loss: 1.3380\n",
      "[Epoch 2/8 | Step 550/600] - Loss: 1.3277\n",
      "[Epoch 2/8 | Step 560/600] - Loss: 1.3357\n",
      "[Epoch 2/8 | Step 570/600] - Loss: 1.3277\n",
      "[Epoch 2/8 | Step 580/600] - Loss: 1.3146\n",
      "[Epoch 2/8 | Step 590/600] - Loss: 1.3008\n",
      "Epoch 2/8 - Avg Train Loss: 1.2928, Val Loss: 1.0966\n",
      "[Epoch 3/8 | Step 0/600] - Loss: 1.0602\n",
      "[Epoch 3/8 | Step 10/600] - Loss: 1.1358\n",
      "[Epoch 3/8 | Step 20/600] - Loss: 1.3771\n",
      "[Epoch 3/8 | Step 30/600] - Loss: 1.1438\n",
      "[Epoch 3/8 | Step 40/600] - Loss: 1.2387\n",
      "[Epoch 3/8 | Step 50/600] - Loss: 1.1992\n",
      "[Epoch 3/8 | Step 60/600] - Loss: 1.1024\n",
      "[Epoch 3/8 | Step 70/600] - Loss: 1.1172\n",
      "[Epoch 3/8 | Step 80/600] - Loss: 1.0697\n",
      "[Epoch 3/8 | Step 90/600] - Loss: 1.0310\n",
      "[Epoch 3/8 | Step 100/600] - Loss: 0.9994\n",
      "[Epoch 3/8 | Step 110/600] - Loss: 0.9589\n",
      "[Epoch 3/8 | Step 120/600] - Loss: 0.9726\n",
      "[Epoch 3/8 | Step 130/600] - Loss: 0.9613\n",
      "[Epoch 3/8 | Step 140/600] - Loss: 0.9532\n",
      "[Epoch 3/8 | Step 150/600] - Loss: 1.0040\n",
      "[Epoch 3/8 | Step 160/600] - Loss: 1.0188\n",
      "[Epoch 3/8 | Step 170/600] - Loss: 1.0226\n",
      "[Epoch 3/8 | Step 180/600] - Loss: 1.0146\n",
      "[Epoch 3/8 | Step 190/600] - Loss: 1.0183\n",
      "[Epoch 3/8 | Step 200/600] - Loss: 1.0049\n",
      "[Epoch 3/8 | Step 210/600] - Loss: 1.0121\n",
      "[Epoch 3/8 | Step 220/600] - Loss: 1.0137\n",
      "[Epoch 3/8 | Step 230/600] - Loss: 1.0046\n",
      "[Epoch 3/8 | Step 240/600] - Loss: 1.0086\n",
      "[Epoch 3/8 | Step 250/600] - Loss: 1.0065\n",
      "[Epoch 3/8 | Step 260/600] - Loss: 1.0084\n",
      "[Epoch 3/8 | Step 270/600] - Loss: 1.0057\n",
      "[Epoch 3/8 | Step 280/600] - Loss: 0.9900\n",
      "[Epoch 3/8 | Step 290/600] - Loss: 0.9712\n",
      "[Epoch 3/8 | Step 300/600] - Loss: 0.9658\n",
      "[Epoch 3/8 | Step 310/600] - Loss: 0.9876\n",
      "[Epoch 3/8 | Step 320/600] - Loss: 0.9789\n",
      "[Epoch 3/8 | Step 330/600] - Loss: 0.9648\n",
      "[Epoch 3/8 | Step 340/600] - Loss: 0.9543\n",
      "[Epoch 3/8 | Step 350/600] - Loss: 0.9634\n",
      "[Epoch 3/8 | Step 360/600] - Loss: 0.9758\n",
      "[Epoch 3/8 | Step 370/600] - Loss: 0.9649\n",
      "[Epoch 3/8 | Step 380/600] - Loss: 0.9647\n",
      "[Epoch 3/8 | Step 390/600] - Loss: 0.9649\n",
      "[Epoch 3/8 | Step 400/600] - Loss: 0.9875\n",
      "[Epoch 3/8 | Step 410/600] - Loss: 0.9859\n",
      "[Epoch 3/8 | Step 420/600] - Loss: 0.9921\n",
      "[Epoch 3/8 | Step 430/600] - Loss: 0.9964\n",
      "[Epoch 3/8 | Step 440/600] - Loss: 0.9860\n",
      "[Epoch 3/8 | Step 450/600] - Loss: 0.9838\n",
      "[Epoch 3/8 | Step 460/600] - Loss: 0.9967\n",
      "[Epoch 3/8 | Step 470/600] - Loss: 0.9990\n",
      "[Epoch 3/8 | Step 480/600] - Loss: 0.9986\n",
      "[Epoch 3/8 | Step 490/600] - Loss: 1.0005\n",
      "[Epoch 3/8 | Step 500/600] - Loss: 0.9972\n",
      "[Epoch 3/8 | Step 510/600] - Loss: 0.9927\n",
      "[Epoch 3/8 | Step 520/600] - Loss: 0.9852\n",
      "[Epoch 3/8 | Step 530/600] - Loss: 1.0078\n",
      "[Epoch 3/8 | Step 540/600] - Loss: 0.9983\n",
      "[Epoch 3/8 | Step 550/600] - Loss: 0.9908\n",
      "[Epoch 3/8 | Step 560/600] - Loss: 0.9919\n",
      "[Epoch 3/8 | Step 570/600] - Loss: 0.9872\n",
      "[Epoch 3/8 | Step 580/600] - Loss: 0.9773\n",
      "[Epoch 3/8 | Step 590/600] - Loss: 0.9855\n",
      "Epoch 3/8 - Avg Train Loss: 0.9881, Val Loss: 0.9162\n",
      "[Epoch 4/8 | Step 0/600] - Loss: 0.2684\n",
      "[Epoch 4/8 | Step 10/600] - Loss: 1.5596\n",
      "[Epoch 4/8 | Step 20/600] - Loss: 1.1148\n",
      "[Epoch 4/8 | Step 30/600] - Loss: 1.0398\n",
      "[Epoch 4/8 | Step 40/600] - Loss: 0.9916\n",
      "[Epoch 4/8 | Step 50/600] - Loss: 0.9581\n",
      "[Epoch 4/8 | Step 60/600] - Loss: 0.9281\n",
      "[Epoch 4/8 | Step 70/600] - Loss: 0.9870\n",
      "[Epoch 4/8 | Step 80/600] - Loss: 0.9998\n",
      "[Epoch 4/8 | Step 90/600] - Loss: 0.9897\n",
      "[Epoch 4/8 | Step 100/600] - Loss: 0.9688\n",
      "[Epoch 4/8 | Step 110/600] - Loss: 0.9996\n",
      "[Epoch 4/8 | Step 120/600] - Loss: 0.9947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/8 | Step 130/600] - Loss: 0.9724\n",
      "[Epoch 4/8 | Step 140/600] - Loss: 1.0226\n",
      "[Epoch 4/8 | Step 150/600] - Loss: 1.0120\n",
      "[Epoch 4/8 | Step 160/600] - Loss: 0.9889\n",
      "[Epoch 4/8 | Step 170/600] - Loss: 0.9860\n",
      "[Epoch 4/8 | Step 180/600] - Loss: 0.9755\n",
      "[Epoch 4/8 | Step 190/600] - Loss: 0.9811\n",
      "[Epoch 4/8 | Step 200/600] - Loss: 0.9684\n",
      "[Epoch 4/8 | Step 210/600] - Loss: 0.9457\n",
      "[Epoch 4/8 | Step 220/600] - Loss: 0.9333\n",
      "[Epoch 4/8 | Step 230/600] - Loss: 0.9288\n",
      "[Epoch 4/8 | Step 240/600] - Loss: 0.9455\n",
      "[Epoch 4/8 | Step 250/600] - Loss: 0.9327\n",
      "[Epoch 4/8 | Step 260/600] - Loss: 0.9565\n",
      "[Epoch 4/8 | Step 270/600] - Loss: 0.9415\n",
      "[Epoch 4/8 | Step 280/600] - Loss: 0.9294\n",
      "[Epoch 4/8 | Step 290/600] - Loss: 0.9316\n",
      "[Epoch 4/8 | Step 300/600] - Loss: 0.9449\n",
      "[Epoch 4/8 | Step 310/600] - Loss: 0.9489\n",
      "[Epoch 4/8 | Step 320/600] - Loss: 0.9358\n",
      "[Epoch 4/8 | Step 330/600] - Loss: 0.9417\n",
      "[Epoch 4/8 | Step 340/600] - Loss: 0.9286\n",
      "[Epoch 4/8 | Step 350/600] - Loss: 0.9347\n",
      "[Epoch 4/8 | Step 360/600] - Loss: 0.9556\n",
      "[Epoch 4/8 | Step 370/600] - Loss: 0.9558\n",
      "[Epoch 4/8 | Step 380/600] - Loss: 0.9543\n",
      "[Epoch 4/8 | Step 390/600] - Loss: 0.9587\n",
      "[Epoch 4/8 | Step 400/600] - Loss: 0.9486\n",
      "[Epoch 4/8 | Step 410/600] - Loss: 0.9442\n",
      "[Epoch 4/8 | Step 420/600] - Loss: 0.9319\n",
      "[Epoch 4/8 | Step 430/600] - Loss: 0.9233\n",
      "[Epoch 4/8 | Step 440/600] - Loss: 0.9124\n",
      "[Epoch 4/8 | Step 450/600] - Loss: 0.9040\n",
      "[Epoch 4/8 | Step 460/600] - Loss: 0.9072\n",
      "[Epoch 4/8 | Step 470/600] - Loss: 0.9039\n",
      "[Epoch 4/8 | Step 480/600] - Loss: 0.8969\n",
      "[Epoch 4/8 | Step 490/600] - Loss: 0.8897\n",
      "[Epoch 4/8 | Step 500/600] - Loss: 0.8825\n",
      "[Epoch 4/8 | Step 510/600] - Loss: 0.8754\n",
      "[Epoch 4/8 | Step 520/600] - Loss: 0.8665\n",
      "[Epoch 4/8 | Step 530/600] - Loss: 0.8598\n",
      "[Epoch 4/8 | Step 540/600] - Loss: 0.8596\n",
      "[Epoch 4/8 | Step 550/600] - Loss: 0.8618\n",
      "[Epoch 4/8 | Step 560/600] - Loss: 0.8563\n",
      "[Epoch 4/8 | Step 570/600] - Loss: 0.8509\n",
      "[Epoch 4/8 | Step 580/600] - Loss: 0.8562\n",
      "[Epoch 4/8 | Step 590/600] - Loss: 0.8652\n",
      "Epoch 4/8 - Avg Train Loss: 0.8605, Val Loss: 0.8131\n",
      "[Epoch 5/8 | Step 0/600] - Loss: 1.4387\n",
      "[Epoch 5/8 | Step 10/600] - Loss: 0.7635\n",
      "[Epoch 5/8 | Step 20/600] - Loss: 0.8527\n",
      "[Epoch 5/8 | Step 30/600] - Loss: 0.8879\n",
      "[Epoch 5/8 | Step 40/600] - Loss: 0.7956\n",
      "[Epoch 5/8 | Step 50/600] - Loss: 0.7739\n",
      "[Epoch 5/8 | Step 60/600] - Loss: 0.7294\n",
      "[Epoch 5/8 | Step 70/600] - Loss: 0.7098\n",
      "[Epoch 5/8 | Step 80/600] - Loss: 0.6860\n",
      "[Epoch 5/8 | Step 90/600] - Loss: 0.6681\n",
      "[Epoch 5/8 | Step 100/600] - Loss: 0.6581\n",
      "[Epoch 5/8 | Step 110/600] - Loss: 0.6764\n",
      "[Epoch 5/8 | Step 120/600] - Loss: 0.6775\n",
      "[Epoch 5/8 | Step 130/600] - Loss: 0.6945\n",
      "[Epoch 5/8 | Step 140/600] - Loss: 0.6874\n",
      "[Epoch 5/8 | Step 150/600] - Loss: 0.6937\n",
      "[Epoch 5/8 | Step 160/600] - Loss: 0.7530\n",
      "[Epoch 5/8 | Step 170/600] - Loss: 0.7893\n",
      "[Epoch 5/8 | Step 180/600] - Loss: 0.7721\n",
      "[Epoch 5/8 | Step 190/600] - Loss: 0.7674\n",
      "[Epoch 5/8 | Step 200/600] - Loss: 0.7925\n",
      "[Epoch 5/8 | Step 210/600] - Loss: 0.7877\n",
      "[Epoch 5/8 | Step 220/600] - Loss: 0.7761\n",
      "[Epoch 5/8 | Step 230/600] - Loss: 0.7820\n",
      "[Epoch 5/8 | Step 240/600] - Loss: 0.7715\n",
      "[Epoch 5/8 | Step 250/600] - Loss: 0.7851\n",
      "[Epoch 5/8 | Step 260/600] - Loss: 0.7719\n",
      "[Epoch 5/8 | Step 270/600] - Loss: 0.7758\n",
      "[Epoch 5/8 | Step 280/600] - Loss: 0.7651\n",
      "[Epoch 5/8 | Step 290/600] - Loss: 0.7606\n",
      "[Epoch 5/8 | Step 300/600] - Loss: 0.7752\n",
      "[Epoch 5/8 | Step 310/600] - Loss: 0.7718\n",
      "[Epoch 5/8 | Step 320/600] - Loss: 0.7638\n",
      "[Epoch 5/8 | Step 330/600] - Loss: 0.7680\n",
      "[Epoch 5/8 | Step 340/600] - Loss: 0.7582\n",
      "[Epoch 5/8 | Step 350/600] - Loss: 0.7517\n",
      "[Epoch 5/8 | Step 360/600] - Loss: 0.7601\n",
      "[Epoch 5/8 | Step 370/600] - Loss: 0.7537\n",
      "[Epoch 5/8 | Step 380/600] - Loss: 0.7768\n",
      "[Epoch 5/8 | Step 390/600] - Loss: 0.7820\n",
      "[Epoch 5/8 | Step 400/600] - Loss: 0.7719\n",
      "[Epoch 5/8 | Step 410/600] - Loss: 0.7679\n",
      "[Epoch 5/8 | Step 420/600] - Loss: 0.7778\n",
      "[Epoch 5/8 | Step 430/600] - Loss: 0.7816\n",
      "[Epoch 5/8 | Step 440/600] - Loss: 0.7790\n",
      "[Epoch 5/8 | Step 450/600] - Loss: 0.7771\n",
      "[Epoch 5/8 | Step 460/600] - Loss: 0.7826\n",
      "[Epoch 5/8 | Step 470/600] - Loss: 0.7837\n",
      "[Epoch 5/8 | Step 480/600] - Loss: 0.7926\n",
      "[Epoch 5/8 | Step 490/600] - Loss: 0.7941\n",
      "[Epoch 5/8 | Step 500/600] - Loss: 0.7998\n",
      "[Epoch 5/8 | Step 510/600] - Loss: 0.8017\n",
      "[Epoch 5/8 | Step 520/600] - Loss: 0.7958\n",
      "[Epoch 5/8 | Step 530/600] - Loss: 0.7983\n",
      "[Epoch 5/8 | Step 540/600] - Loss: 0.7939\n",
      "[Epoch 5/8 | Step 550/600] - Loss: 0.7900\n",
      "[Epoch 5/8 | Step 560/600] - Loss: 0.7933\n",
      "[Epoch 5/8 | Step 570/600] - Loss: 0.7929\n",
      "[Epoch 5/8 | Step 580/600] - Loss: 0.7943\n",
      "[Epoch 5/8 | Step 590/600] - Loss: 0.7911\n",
      "Epoch 5/8 - Avg Train Loss: 0.7879, Val Loss: 0.7676\n",
      "[Epoch 6/8 | Step 0/600] - Loss: 1.2234\n",
      "[Epoch 6/8 | Step 10/600] - Loss: 0.5093\n",
      "[Epoch 6/8 | Step 20/600] - Loss: 0.5990\n",
      "[Epoch 6/8 | Step 30/600] - Loss: 0.5246\n",
      "[Epoch 6/8 | Step 40/600] - Loss: 0.6678\n",
      "[Epoch 6/8 | Step 50/600] - Loss: 0.6264\n",
      "[Epoch 6/8 | Step 60/600] - Loss: 0.6804\n",
      "[Epoch 6/8 | Step 70/600] - Loss: 0.6685\n",
      "[Epoch 6/8 | Step 80/600] - Loss: 0.6470\n",
      "[Epoch 6/8 | Step 90/600] - Loss: 0.6696\n",
      "[Epoch 6/8 | Step 100/600] - Loss: 0.6856\n",
      "[Epoch 6/8 | Step 110/600] - Loss: 0.7175\n",
      "[Epoch 6/8 | Step 120/600] - Loss: 0.7015\n",
      "[Epoch 6/8 | Step 130/600] - Loss: 0.7156\n",
      "[Epoch 6/8 | Step 140/600] - Loss: 0.7259\n",
      "[Epoch 6/8 | Step 150/600] - Loss: 0.7181\n",
      "[Epoch 6/8 | Step 160/600] - Loss: 0.6975\n",
      "[Epoch 6/8 | Step 170/600] - Loss: 0.7238\n",
      "[Epoch 6/8 | Step 180/600] - Loss: 0.7175\n",
      "[Epoch 6/8 | Step 190/600] - Loss: 0.7424\n",
      "[Epoch 6/8 | Step 200/600] - Loss: 0.7298\n",
      "[Epoch 6/8 | Step 210/600] - Loss: 0.7234\n",
      "[Epoch 6/8 | Step 220/600] - Loss: 0.7106\n",
      "[Epoch 6/8 | Step 230/600] - Loss: 0.7130\n",
      "[Epoch 6/8 | Step 240/600] - Loss: 0.7239\n",
      "[Epoch 6/8 | Step 250/600] - Loss: 0.7120\n",
      "[Epoch 6/8 | Step 260/600] - Loss: 0.7199\n",
      "[Epoch 6/8 | Step 270/600] - Loss: 0.7092\n",
      "[Epoch 6/8 | Step 280/600] - Loss: 0.7069\n",
      "[Epoch 6/8 | Step 290/600] - Loss: 0.7201\n",
      "[Epoch 6/8 | Step 300/600] - Loss: 0.7206\n",
      "[Epoch 6/8 | Step 310/600] - Loss: 0.7350\n",
      "[Epoch 6/8 | Step 320/600] - Loss: 0.7280\n",
      "[Epoch 6/8 | Step 330/600] - Loss: 0.7228\n",
      "[Epoch 6/8 | Step 340/600] - Loss: 0.7222\n",
      "[Epoch 6/8 | Step 350/600] - Loss: 0.7240\n",
      "[Epoch 6/8 | Step 360/600] - Loss: 0.7156\n",
      "[Epoch 6/8 | Step 370/600] - Loss: 0.7102\n",
      "[Epoch 6/8 | Step 380/600] - Loss: 0.7080\n",
      "[Epoch 6/8 | Step 390/600] - Loss: 0.7063\n",
      "[Epoch 6/8 | Step 400/600] - Loss: 0.7209\n",
      "[Epoch 6/8 | Step 410/600] - Loss: 0.7146\n",
      "[Epoch 6/8 | Step 420/600] - Loss: 0.7049\n",
      "[Epoch 6/8 | Step 430/600] - Loss: 0.7040\n",
      "[Epoch 6/8 | Step 440/600] - Loss: 0.7102\n",
      "[Epoch 6/8 | Step 450/600] - Loss: 0.7270\n",
      "[Epoch 6/8 | Step 460/600] - Loss: 0.7212\n",
      "[Epoch 6/8 | Step 470/600] - Loss: 0.7203\n",
      "[Epoch 6/8 | Step 480/600] - Loss: 0.7138\n",
      "[Epoch 6/8 | Step 490/600] - Loss: 0.7188\n",
      "[Epoch 6/8 | Step 500/600] - Loss: 0.7144\n",
      "[Epoch 6/8 | Step 510/600] - Loss: 0.7243\n",
      "[Epoch 6/8 | Step 520/600] - Loss: 0.7262\n",
      "[Epoch 6/8 | Step 530/600] - Loss: 0.7223\n",
      "[Epoch 6/8 | Step 540/600] - Loss: 0.7339\n",
      "[Epoch 6/8 | Step 550/600] - Loss: 0.7328\n",
      "[Epoch 6/8 | Step 560/600] - Loss: 0.7334\n",
      "[Epoch 6/8 | Step 570/600] - Loss: 0.7303\n",
      "[Epoch 6/8 | Step 580/600] - Loss: 0.7442\n",
      "[Epoch 6/8 | Step 590/600] - Loss: 0.7465\n",
      "Epoch 6/8 - Avg Train Loss: 0.7520, Val Loss: 0.7402\n",
      "[Epoch 7/8 | Step 0/600] - Loss: 2.0302\n",
      "[Epoch 7/8 | Step 10/600] - Loss: 0.6173\n",
      "[Epoch 7/8 | Step 20/600] - Loss: 1.3473\n",
      "[Epoch 7/8 | Step 30/600] - Loss: 1.2186\n",
      "[Epoch 7/8 | Step 40/600] - Loss: 1.0583\n",
      "[Epoch 7/8 | Step 50/600] - Loss: 0.9766\n",
      "[Epoch 7/8 | Step 60/600] - Loss: 0.9247\n",
      "[Epoch 7/8 | Step 70/600] - Loss: 0.8684\n",
      "[Epoch 7/8 | Step 80/600] - Loss: 0.8215\n",
      "[Epoch 7/8 | Step 90/600] - Loss: 0.7791\n",
      "[Epoch 7/8 | Step 100/600] - Loss: 0.7694\n",
      "[Epoch 7/8 | Step 110/600] - Loss: 0.7521\n",
      "[Epoch 7/8 | Step 120/600] - Loss: 0.7168\n",
      "[Epoch 7/8 | Step 130/600] - Loss: 0.6954\n",
      "[Epoch 7/8 | Step 140/600] - Loss: 0.7024\n",
      "[Epoch 7/8 | Step 150/600] - Loss: 0.6981\n",
      "[Epoch 7/8 | Step 160/600] - Loss: 0.7096\n",
      "[Epoch 7/8 | Step 170/600] - Loss: 0.7395\n",
      "[Epoch 7/8 | Step 180/600] - Loss: 0.7380\n",
      "[Epoch 7/8 | Step 190/600] - Loss: 0.7260\n",
      "[Epoch 7/8 | Step 200/600] - Loss: 0.7198\n",
      "[Epoch 7/8 | Step 210/600] - Loss: 0.7109\n",
      "[Epoch 7/8 | Step 220/600] - Loss: 0.6974\n",
      "[Epoch 7/8 | Step 230/600] - Loss: 0.6848\n",
      "[Epoch 7/8 | Step 240/600] - Loss: 0.6959\n",
      "[Epoch 7/8 | Step 250/600] - Loss: 0.7243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/8 | Step 260/600] - Loss: 0.7218\n",
      "[Epoch 7/8 | Step 270/600] - Loss: 0.7169\n",
      "[Epoch 7/8 | Step 280/600] - Loss: 0.7073\n",
      "[Epoch 7/8 | Step 290/600] - Loss: 0.7014\n",
      "[Epoch 7/8 | Step 300/600] - Loss: 0.6977\n",
      "[Epoch 7/8 | Step 310/600] - Loss: 0.7218\n",
      "[Epoch 7/8 | Step 320/600] - Loss: 0.7158\n",
      "[Epoch 7/8 | Step 330/600] - Loss: 0.7160\n",
      "[Epoch 7/8 | Step 340/600] - Loss: 0.7093\n",
      "[Epoch 7/8 | Step 350/600] - Loss: 0.7091\n",
      "[Epoch 7/8 | Step 360/600] - Loss: 0.7374\n",
      "[Epoch 7/8 | Step 370/600] - Loss: 0.7418\n",
      "[Epoch 7/8 | Step 380/600] - Loss: 0.7449\n",
      "[Epoch 7/8 | Step 390/600] - Loss: 0.7386\n",
      "[Epoch 7/8 | Step 400/600] - Loss: 0.7340\n",
      "[Epoch 7/8 | Step 410/600] - Loss: 0.7479\n",
      "[Epoch 7/8 | Step 420/600] - Loss: 0.7658\n",
      "[Epoch 7/8 | Step 430/600] - Loss: 0.7604\n",
      "[Epoch 7/8 | Step 440/600] - Loss: 0.7537\n",
      "[Epoch 7/8 | Step 450/600] - Loss: 0.7491\n",
      "[Epoch 7/8 | Step 460/600] - Loss: 0.7460\n",
      "[Epoch 7/8 | Step 470/600] - Loss: 0.7500\n",
      "[Epoch 7/8 | Step 480/600] - Loss: 0.7517\n",
      "[Epoch 7/8 | Step 490/600] - Loss: 0.7524\n",
      "[Epoch 7/8 | Step 500/600] - Loss: 0.7551\n",
      "[Epoch 7/8 | Step 510/600] - Loss: 0.7502\n",
      "[Epoch 7/8 | Step 520/600] - Loss: 0.7489\n",
      "[Epoch 7/8 | Step 530/600] - Loss: 0.7559\n",
      "[Epoch 7/8 | Step 540/600] - Loss: 0.7498\n",
      "[Epoch 7/8 | Step 550/600] - Loss: 0.7487\n",
      "[Epoch 7/8 | Step 560/600] - Loss: 0.7440\n",
      "[Epoch 7/8 | Step 570/600] - Loss: 0.7374\n",
      "[Epoch 7/8 | Step 580/600] - Loss: 0.7405\n",
      "[Epoch 7/8 | Step 590/600] - Loss: 0.7351\n",
      "Epoch 7/8 - Avg Train Loss: 0.7301, Val Loss: 0.7194\n",
      "[Epoch 8/8 | Step 0/600] - Loss: 0.3468\n",
      "[Epoch 8/8 | Step 10/600] - Loss: 0.5390\n",
      "[Epoch 8/8 | Step 20/600] - Loss: 0.4909\n",
      "[Epoch 8/8 | Step 30/600] - Loss: 0.5320\n",
      "[Epoch 8/8 | Step 40/600] - Loss: 0.5554\n",
      "[Epoch 8/8 | Step 50/600] - Loss: 0.5442\n",
      "[Epoch 8/8 | Step 60/600] - Loss: 0.5248\n",
      "[Epoch 8/8 | Step 70/600] - Loss: 0.5263\n",
      "[Epoch 8/8 | Step 80/600] - Loss: 0.5203\n",
      "[Epoch 8/8 | Step 90/600] - Loss: 0.5097\n",
      "[Epoch 8/8 | Step 100/600] - Loss: 0.5224\n",
      "[Epoch 8/8 | Step 110/600] - Loss: 0.5159\n",
      "[Epoch 8/8 | Step 120/600] - Loss: 0.5257\n",
      "[Epoch 8/8 | Step 130/600] - Loss: 0.5171\n",
      "[Epoch 8/8 | Step 140/600] - Loss: 0.5450\n",
      "[Epoch 8/8 | Step 150/600] - Loss: 0.5622\n",
      "[Epoch 8/8 | Step 160/600] - Loss: 0.5685\n",
      "[Epoch 8/8 | Step 170/600] - Loss: 0.5891\n",
      "[Epoch 8/8 | Step 180/600] - Loss: 0.6252\n",
      "[Epoch 8/8 | Step 190/600] - Loss: 0.6172\n",
      "[Epoch 8/8 | Step 200/600] - Loss: 0.6192\n",
      "[Epoch 8/8 | Step 210/600] - Loss: 0.6289\n",
      "[Epoch 8/8 | Step 220/600] - Loss: 0.6329\n",
      "[Epoch 8/8 | Step 230/600] - Loss: 0.6390\n",
      "[Epoch 8/8 | Step 240/600] - Loss: 0.6496\n",
      "[Epoch 8/8 | Step 250/600] - Loss: 0.6619\n",
      "[Epoch 8/8 | Step 260/600] - Loss: 0.6832\n",
      "[Epoch 8/8 | Step 270/600] - Loss: 0.6984\n",
      "[Epoch 8/8 | Step 280/600] - Loss: 0.6929\n",
      "[Epoch 8/8 | Step 290/600] - Loss: 0.6904\n",
      "[Epoch 8/8 | Step 300/600] - Loss: 0.6801\n",
      "[Epoch 8/8 | Step 310/600] - Loss: 0.6808\n",
      "[Epoch 8/8 | Step 320/600] - Loss: 0.6784\n",
      "[Epoch 8/8 | Step 330/600] - Loss: 0.6860\n",
      "[Epoch 8/8 | Step 340/600] - Loss: 0.6829\n",
      "[Epoch 8/8 | Step 350/600] - Loss: 0.6783\n",
      "[Epoch 8/8 | Step 360/600] - Loss: 0.6887\n",
      "[Epoch 8/8 | Step 370/600] - Loss: 0.7029\n",
      "[Epoch 8/8 | Step 380/600] - Loss: 0.7177\n",
      "[Epoch 8/8 | Step 390/600] - Loss: 0.7136\n",
      "[Epoch 8/8 | Step 400/600] - Loss: 0.7176\n",
      "[Epoch 8/8 | Step 410/600] - Loss: 0.7259\n",
      "[Epoch 8/8 | Step 420/600] - Loss: 0.7424\n",
      "[Epoch 8/8 | Step 430/600] - Loss: 0.7431\n",
      "[Epoch 8/8 | Step 440/600] - Loss: 0.7364\n",
      "[Epoch 8/8 | Step 450/600] - Loss: 0.7295\n",
      "[Epoch 8/8 | Step 460/600] - Loss: 0.7238\n",
      "[Epoch 8/8 | Step 470/600] - Loss: 0.7216\n",
      "[Epoch 8/8 | Step 480/600] - Loss: 0.7220\n",
      "[Epoch 8/8 | Step 490/600] - Loss: 0.7256\n",
      "[Epoch 8/8 | Step 500/600] - Loss: 0.7199\n",
      "[Epoch 8/8 | Step 510/600] - Loss: 0.7190\n",
      "[Epoch 8/8 | Step 520/600] - Loss: 0.7170\n",
      "[Epoch 8/8 | Step 530/600] - Loss: 0.7266\n",
      "[Epoch 8/8 | Step 540/600] - Loss: 0.7247\n",
      "[Epoch 8/8 | Step 550/600] - Loss: 0.7185\n",
      "[Epoch 8/8 | Step 560/600] - Loss: 0.7147\n",
      "[Epoch 8/8 | Step 570/600] - Loss: 0.7107\n",
      "[Epoch 8/8 | Step 580/600] - Loss: 0.7037\n",
      "[Epoch 8/8 | Step 590/600] - Loss: 0.7058\n",
      "Epoch 8/8 - Avg Train Loss: 0.7137, Val Loss: 0.7058\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoConfig,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from huggingface_hub import login\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    LlamaForSequenceClassification,\n",
    "    LlamaTokenizer,LlamaModel,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoConfig,\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "from huggingface_hub import login\n",
    "import bitsandbytes as bnb\n",
    "import re\n",
    "import traceback\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Set up the GPU environment and return the appropriate device.\"\"\"\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    \n",
    "  \n",
    "    torch.manual_seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    return device\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "\n",
    "def setup_model_and_tokenizer(model_name, device):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    model_config = AutoConfig.from_pretrained(model_name)\n",
    "    model_config.num_labels = 2\n",
    "    model_config.pad_token_id = tokenizer.pad_token_id\n",
    "    model_config.use_cache = False\n",
    "\n",
    "   \n",
    "    quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        config=model_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        quantization_config=quantization_config\n",
    "    )\n",
    "\n",
    "    lora_config = LoraConfig(r=16, lora_alpha=32, target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05, bias=\"none\", task_type=\"SEQ_CLS\")\n",
    "    model = get_peft_model(base_model, lora_config)\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "class PreferenceEmailDataset(Dataset):\n",
    "    def __init__(self, emails_df, tokenizer, max_length=512):\n",
    "        \"\"\"\n",
    "        Dataset to create pairs of message, preferred response, and rejected response for DPO training.\n",
    "        \"\"\"\n",
    "        self.emails_df = emails_df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.pairs = self._create_preference_pairs()\n",
    "\n",
    "    def _create_preference_pairs(self):\n",
    "        \"\"\"\n",
    "        Create pairs using emails from the dataset based on their labels.\n",
    "        \"\"\"\n",
    "        pairs = []\n",
    "        for _, selected_email in self.emails_df.iterrows():\n",
    "            selected_label = selected_email['label']\n",
    "            ham_emails = self.emails_df[self.emails_df['label'] == 0]\n",
    "            phish_emails = self.emails_df[self.emails_df['label'] == 1]\n",
    "\n",
    "            if selected_label == 1:  # Phishing email\n",
    "                preferred_email = phish_emails[phish_emails.index != selected_email.name].sample(n=1).iloc[0]\n",
    "                rejected_email = ham_emails.sample(n=1).iloc[0]\n",
    "                pairs.append({\n",
    "                    'message': selected_email,\n",
    "                    'preferred': preferred_email,\n",
    "                    'rejected': rejected_email\n",
    "                })\n",
    "            elif selected_label == 0:  # Ham email\n",
    "                preferred_email = ham_emails[ham_emails.index != selected_email.name].sample(n=1).iloc[0]\n",
    "                rejected_email = phish_emails.sample(n=1).iloc[0]\n",
    "                pairs.append({\n",
    "                    'message': selected_email,\n",
    "                    'preferred': preferred_email,\n",
    "                    'rejected': rejected_email\n",
    "                })\n",
    "\n",
    "        return pairs\n",
    "\n",
    "    def _prepare_email_input(self, message, response):\n",
    "        \"\"\"\n",
    "        Prepare the input text with formatted message and response for tokenization.\n",
    "        \"\"\"\n",
    "        formatted_input = f\"<s>[INST] {message} [/INST] {response}</s>\"\n",
    "        return self.tokenizer(\n",
    "            formatted_input,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.pairs[idx]\n",
    "        \n",
    "        \n",
    "        if pair['message']['label'] == 1:\n",
    "            message_text = (\n",
    "                \"This email is flagged as a phishing email. \"\n",
    "                \"Carefully examine the sender's address, subject line, and content of the email. \"\n",
    "                f\"Sender: {pair['message']['sender']} [SEP] \"\n",
    "                f\"Subject: {pair['message']['subject']} [SEP] \"\n",
    "                f\"Body: {pair['message']['body']}\"\n",
    "            )\n",
    "        else:\n",
    "            message_text = (\n",
    "                \"This email is flagged as a legitimate email. \"\n",
    "                \"Look for consistent and clear sender details, subject relevance, and authentic body content. \"\n",
    "                f\"Sender: {pair['message']['sender']} [SEP] \"\n",
    "                f\"Subject: {pair['message']['subject']} [SEP] \"\n",
    "                f\"Body: {pair['message']['body']}\"\n",
    "            )\n",
    "        \n",
    "        \n",
    "        preferred_response = (\n",
    "            \"This is a similar email example to the one above. \"\n",
    "            f\"Sender: {pair['preferred']['sender']} [SEP] \"\n",
    "            f\"Subject: {pair['preferred']['subject']} [SEP] \"\n",
    "            f\"Body: {pair['preferred']['body']}\"\n",
    "        )\n",
    "        rejected_response = (\n",
    "            \"This email is different in intent. Notice the sender's address, subject, and content mismatch. \"\n",
    "            f\"Sender: {pair['rejected']['sender']} [SEP] \"\n",
    "            f\"Subject: {pair['rejected']['subject']} [SEP] \"\n",
    "            f\"Body: {pair['rejected']['body']}\"\n",
    "        )\n",
    "        \n",
    "        message_inputs = self._prepare_email_input(message_text, \"\")\n",
    "        preferred_inputs = self._prepare_email_input(message_text, preferred_response)\n",
    "        rejected_inputs = self._prepare_email_input(message_text, rejected_response)\n",
    "\n",
    "        return {\n",
    "            'message_input_ids': message_inputs['input_ids'].squeeze(),\n",
    "            'message_attention_mask': message_inputs['attention_mask'].squeeze(),\n",
    "            'preferred_input_ids': preferred_inputs['input_ids'].squeeze(),\n",
    "            'preferred_attention_mask': preferred_inputs['attention_mask'].squeeze(),\n",
    "            'rejected_input_ids': rejected_inputs['input_ids'].squeeze(),\n",
    "            'rejected_attention_mask': rejected_inputs['attention_mask'].squeeze(),\n",
    "        }\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "   \n",
    "    if not isinstance(text, str):\n",
    "        text = \"\"\n",
    "    #text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    #text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def compute_dpo_loss(policy_chosen_logits, policy_rejected_logits, \n",
    "                    reference_chosen_logits, reference_rejected_logits, \n",
    "                    beta=0.2):\n",
    "   \n",
    "    epsilon = 1e-8\n",
    "    \n",
    "   \n",
    "    policy_chosen_probs = F.softmax(policy_chosen_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    policy_rejected_probs = F.softmax(policy_rejected_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    ref_chosen_probs = F.softmax(reference_chosen_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    ref_rejected_probs = F.softmax(reference_rejected_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    \n",
    "  \n",
    "    chosen_rewards = (torch.log(policy_chosen_probs + epsilon) - \n",
    "                     torch.log(ref_chosen_probs + epsilon))\n",
    "    rejected_rewards = (torch.log(policy_rejected_probs + epsilon) - \n",
    "                       torch.log(ref_rejected_probs + epsilon))\n",
    "    \n",
    "    \n",
    "    max_reward = 50.0\n",
    "    chosen_rewards = torch.clamp(chosen_rewards, -max_reward, max_reward)\n",
    "    rejected_rewards = torch.clamp(rejected_rewards, -max_reward, max_reward)\n",
    "    \n",
    "    \n",
    "    logits_diff = (chosen_rewards - rejected_rewards) / beta\n",
    "    \n",
    "    valid_mask = ~torch.isnan(logits_diff)\n",
    "    if valid_mask.any():\n",
    "        loss = -F.logsigmoid(logits_diff[valid_mask]).mean()\n",
    "    else:\n",
    "        loss = torch.tensor(0.0, device=logits_diff.device)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def train_model_dpo(policy_model, reference_model, train_loader, val_loader, \n",
    "                   optimizer, scheduler, device, num_epochs=8, beta=0.2, gradient_accumulation_steps=2):\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    policy_model = policy_model.to(device).float()\n",
    "    reference_model = reference_model.to(device).float()\n",
    "    reference_model.eval()  # Ensure reference model does not get updated during training\n",
    "    \n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        policy_model.train()\n",
    "        total_loss = 0\n",
    "        valid_steps = 0\n",
    "        \n",
    "        for step, batch in enumerate(train_loader):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            try:\n",
    "                with torch.amp.autocast('cuda', dtype=torch.float32):\n",
    "                    policy_chosen_outputs = policy_model(\n",
    "                        input_ids=batch['preferred_input_ids'],\n",
    "                        attention_mask=batch['preferred_attention_mask']\n",
    "                    )\n",
    "                    policy_rejected_outputs = policy_model(\n",
    "                        input_ids=batch['rejected_input_ids'],\n",
    "                        attention_mask=batch['rejected_attention_mask']\n",
    "                    )\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        ref_chosen_outputs = reference_model(\n",
    "                            input_ids=batch['preferred_input_ids'],\n",
    "                            attention_mask=batch['preferred_attention_mask']\n",
    "                        )\n",
    "                        ref_rejected_outputs = reference_model(\n",
    "                            input_ids=batch['rejected_input_ids'],\n",
    "                            attention_mask=batch['rejected_attention_mask']\n",
    "                        )\n",
    "                    \n",
    "                    loss = compute_dpo_loss(\n",
    "                        policy_chosen_outputs.logits,\n",
    "                        policy_rejected_outputs.logits,\n",
    "                        ref_chosen_outputs.logits,\n",
    "                        ref_rejected_outputs.logits,\n",
    "                        beta=beta\n",
    "                    )\n",
    "                    \n",
    "                    if not torch.isnan(loss) and not torch.isinf(loss):\n",
    "                        scaler.scale(loss).backward()\n",
    "                        \n",
    "                        # Gradient accumulation logic\n",
    "                        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                            scaler.unscale_(optimizer)\n",
    "                            torch.nn.utils.clip_grad_norm_(policy_model.parameters(), max_norm=1.0)\n",
    "                            scaler.step(optimizer)\n",
    "                            scaler.update()\n",
    "                            scheduler.step()\n",
    "                            optimizer.zero_grad()\n",
    "                        \n",
    "                        total_loss += loss.item()\n",
    "                        valid_steps += 1\n",
    "                    \n",
    "                    if step % 10 == 0:\n",
    "                        avg_loss = total_loss / max(valid_steps, 1)\n",
    "                        print(f\"[Epoch {epoch+1}/{num_epochs} | Step {step}/{len(train_loader)}] - Loss: {avg_loss:.4f}\")\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error in batch {step}: {str(e)}\")\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        if valid_steps > 0:\n",
    "            avg_train_loss = total_loss / valid_steps\n",
    "            val_loss = evaluate_model_dpo(policy_model, reference_model, val_loader, device, beta)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Avg Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_state = {k: v.cpu() for k, v in policy_model.state_dict().items() if isinstance(v, torch.Tensor)}\n",
    "    \n",
    "    return best_model_state\n",
    "\n",
    "def evaluate_model_dpo(policy_model, reference_model, val_loader, device, beta):\n",
    "   \n",
    "    policy_model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            with torch.amp.autocast('cuda', dtype=torch.float32):\n",
    "                policy_chosen_outputs = policy_model(\n",
    "                    input_ids=batch['preferred_input_ids'],\n",
    "                    attention_mask=batch['preferred_attention_mask']\n",
    "                )\n",
    "                policy_rejected_outputs = policy_model(\n",
    "                    input_ids=batch['rejected_input_ids'],\n",
    "                    attention_mask=batch['rejected_attention_mask']\n",
    "                )\n",
    "                \n",
    "                ref_chosen_outputs = reference_model(\n",
    "                    input_ids=batch['preferred_input_ids'],\n",
    "                    attention_mask=batch['preferred_attention_mask']\n",
    "                )\n",
    "                ref_rejected_outputs = reference_model(\n",
    "                    input_ids=batch['rejected_input_ids'],\n",
    "                    attention_mask=batch['rejected_attention_mask']\n",
    "                )\n",
    "                \n",
    "                loss = compute_dpo_loss(\n",
    "                    policy_chosen_outputs.logits,\n",
    "                    policy_rejected_outputs.logits,\n",
    "                    ref_chosen_outputs.logits,\n",
    "                    ref_rejected_outputs.logits,\n",
    "                    beta=beta\n",
    "                )\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "def main():\n",
    "\n",
    "    login(token=\"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\")\n",
    "    device = setup_environment()\n",
    "    model_name = 'Qwen/Qwen3-8B'\n",
    "    data_path = os.path.expanduser(\"~/Downloads/Tune/FineTune/newdata_cleaned.csv\")\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(f\"File not found: {data_path}\")\n",
    "\n",
    "    policy_model, tokenizer = setup_model_and_tokenizer(model_name, device)\n",
    "    reference_model, _ = setup_model_and_tokenizer(model_name, device)\n",
    "    \n",
    "\n",
    "    emails_df = pd.read_csv(data_path)\n",
    "    emails_df['sender'] = emails_df['sender'].astype(str).apply(clean_text)\n",
    "    emails_df['subject'] = emails_df['subject'].astype(str).apply(clean_text)\n",
    "    emails_df['body'] = emails_df['body'].astype(str).apply(clean_text)\n",
    "\n",
    "    train_df, val_df = train_test_split(emails_df, test_size=0.2, stratify=emails_df['label'], random_state=42)\n",
    "\n",
    "  \n",
    "    train_dataset = PreferenceEmailDataset(train_df, tokenizer, max_length=512)\n",
    "    val_dataset = PreferenceEmailDataset(val_df, tokenizer, max_length=512)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # Setup optimization\n",
    "    optimizer = torch.optim.AdamW(policy_model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "    num_epochs = 8\n",
    "    num_training_steps = len(train_loader) * num_epochs\n",
    "    num_warmup_steps = num_training_steps // 20\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "\n",
    "    best_model_state = train_model_dpo(\n",
    "        policy_model,\n",
    "        reference_model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        device,\n",
    "        num_epochs=num_epochs,\n",
    "        beta=0.2\n",
    "    )\n",
    "\n",
    "   \n",
    "    output_dir = os.path.expanduser(\"~/Downloads/Tune/FineTune/dpo_Qwen\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    policy_model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "    config = {\n",
    "        \"model_name\": model_name,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"batch_size\": 8,\n",
    "        \"max_length\": 512,\n",
    "        \"warmup_steps\": num_warmup_steps,\n",
    "        \"total_steps\": num_training_steps,\n",
    "        \"device\": str(device),\n",
    "        \"beta\": 0.2\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"training_config.json\"), \"w\") as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aa8cebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA RTX A5000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea62f4b7ae704d9a833438df9f4e46ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at mistralai/Mistral-7B-v0.1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d7fd786e4d4030b4ea187951b7eda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at mistralai/Mistral-7B-v0.1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/users/skuikel/anaconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/8 | Step 0/600] - Loss: 27.1476\n",
      "[Epoch 1/8 | Step 10/600] - Loss: 18.4292\n",
      "[Epoch 1/8 | Step 20/600] - Loss: 15.6888\n",
      "[Epoch 1/8 | Step 30/600] - Loss: 15.2943\n",
      "[Epoch 1/8 | Step 40/600] - Loss: 13.4584\n",
      "[Epoch 1/8 | Step 50/600] - Loss: 12.8521\n",
      "[Epoch 1/8 | Step 60/600] - Loss: 12.7043\n",
      "[Epoch 1/8 | Step 70/600] - Loss: 13.4286\n",
      "[Epoch 1/8 | Step 80/600] - Loss: 13.3973\n",
      "[Epoch 1/8 | Step 90/600] - Loss: 12.9480\n",
      "[Epoch 1/8 | Step 100/600] - Loss: 12.9068\n",
      "[Epoch 1/8 | Step 110/600] - Loss: 13.0340\n",
      "[Epoch 1/8 | Step 120/600] - Loss: 12.8922\n",
      "[Epoch 1/8 | Step 130/600] - Loss: 13.0055\n",
      "[Epoch 1/8 | Step 140/600] - Loss: 12.6378\n",
      "[Epoch 1/8 | Step 150/600] - Loss: 12.9118\n",
      "[Epoch 1/8 | Step 160/600] - Loss: 12.6558\n",
      "[Epoch 1/8 | Step 170/600] - Loss: 12.8433\n",
      "[Epoch 1/8 | Step 180/600] - Loss: 12.7878\n",
      "[Epoch 1/8 | Step 190/600] - Loss: 12.5438\n",
      "[Epoch 1/8 | Step 200/600] - Loss: 12.5616\n",
      "[Epoch 1/8 | Step 210/600] - Loss: 12.7078\n",
      "[Epoch 1/8 | Step 220/600] - Loss: 12.8436\n",
      "[Epoch 1/8 | Step 230/600] - Loss: 12.7660\n",
      "[Epoch 1/8 | Step 240/600] - Loss: 12.7570\n",
      "[Epoch 1/8 | Step 250/600] - Loss: 12.7618\n",
      "[Epoch 1/8 | Step 260/600] - Loss: 12.7133\n",
      "[Epoch 1/8 | Step 270/600] - Loss: 12.6447\n",
      "[Epoch 1/8 | Step 280/600] - Loss: 12.5268\n",
      "[Epoch 1/8 | Step 290/600] - Loss: 12.5906\n",
      "[Epoch 1/8 | Step 300/600] - Loss: 12.3910\n",
      "[Epoch 1/8 | Step 310/600] - Loss: 12.3351\n",
      "[Epoch 1/8 | Step 320/600] - Loss: 12.2780\n",
      "[Epoch 1/8 | Step 330/600] - Loss: 12.2461\n",
      "[Epoch 1/8 | Step 340/600] - Loss: 12.1044\n",
      "[Epoch 1/8 | Step 350/600] - Loss: 12.1820\n",
      "[Epoch 1/8 | Step 360/600] - Loss: 12.2097\n",
      "[Epoch 1/8 | Step 370/600] - Loss: 12.1730\n",
      "[Epoch 1/8 | Step 380/600] - Loss: 12.1264\n",
      "[Epoch 1/8 | Step 390/600] - Loss: 12.0474\n",
      "[Epoch 1/8 | Step 400/600] - Loss: 12.0277\n",
      "[Epoch 1/8 | Step 410/600] - Loss: 12.0267\n",
      "[Epoch 1/8 | Step 420/600] - Loss: 12.0401\n",
      "[Epoch 1/8 | Step 430/600] - Loss: 12.0661\n",
      "[Epoch 1/8 | Step 440/600] - Loss: 12.0116\n",
      "[Epoch 1/8 | Step 450/600] - Loss: 12.0406\n",
      "[Epoch 1/8 | Step 460/600] - Loss: 11.9425\n",
      "[Epoch 1/8 | Step 470/600] - Loss: 11.8811\n",
      "[Epoch 1/8 | Step 480/600] - Loss: 11.7523\n",
      "[Epoch 1/8 | Step 490/600] - Loss: 11.7457\n",
      "[Epoch 1/8 | Step 500/600] - Loss: 11.7335\n",
      "[Epoch 1/8 | Step 510/600] - Loss: 11.7258\n",
      "[Epoch 1/8 | Step 520/600] - Loss: 11.6315\n",
      "[Epoch 1/8 | Step 530/600] - Loss: 11.6599\n",
      "[Epoch 1/8 | Step 540/600] - Loss: 11.6175\n",
      "[Epoch 1/8 | Step 550/600] - Loss: 11.5563\n",
      "[Epoch 1/8 | Step 560/600] - Loss: 11.5158\n",
      "[Epoch 1/8 | Step 570/600] - Loss: 11.4113\n",
      "[Epoch 1/8 | Step 580/600] - Loss: 11.3995\n",
      "[Epoch 1/8 | Step 590/600] - Loss: 11.3743\n",
      "Epoch 1/8 - Avg Train Loss: 11.3922, Val Loss: 10.2877\n",
      "[Epoch 2/8 | Step 0/600] - Loss: 24.5434\n",
      "[Epoch 2/8 | Step 10/600] - Loss: 11.6089\n",
      "[Epoch 2/8 | Step 20/600] - Loss: 11.1481\n",
      "[Epoch 2/8 | Step 30/600] - Loss: 10.5785\n",
      "[Epoch 2/8 | Step 40/600] - Loss: 10.5802\n",
      "[Epoch 2/8 | Step 50/600] - Loss: 11.0395\n",
      "[Epoch 2/8 | Step 60/600] - Loss: 10.8237\n",
      "[Epoch 2/8 | Step 70/600] - Loss: 10.8395\n",
      "[Epoch 2/8 | Step 80/600] - Loss: 10.6868\n",
      "[Epoch 2/8 | Step 90/600] - Loss: 10.3825\n",
      "[Epoch 2/8 | Step 100/600] - Loss: 10.4503\n",
      "[Epoch 2/8 | Step 110/600] - Loss: 10.7511\n",
      "[Epoch 2/8 | Step 120/600] - Loss: 10.6796\n",
      "[Epoch 2/8 | Step 130/600] - Loss: 10.5575\n",
      "[Epoch 2/8 | Step 140/600] - Loss: 10.7247\n",
      "[Epoch 2/8 | Step 150/600] - Loss: 10.6405\n",
      "[Epoch 2/8 | Step 160/600] - Loss: 10.4188\n",
      "[Epoch 2/8 | Step 170/600] - Loss: 10.3168\n",
      "[Epoch 2/8 | Step 180/600] - Loss: 10.2475\n",
      "[Epoch 2/8 | Step 190/600] - Loss: 10.1550\n",
      "[Epoch 2/8 | Step 200/600] - Loss: 9.9899\n",
      "[Epoch 2/8 | Step 210/600] - Loss: 9.9141\n",
      "[Epoch 2/8 | Step 220/600] - Loss: 9.8441\n",
      "[Epoch 2/8 | Step 230/600] - Loss: 9.7619\n",
      "[Epoch 2/8 | Step 240/600] - Loss: 9.6435\n",
      "[Epoch 2/8 | Step 250/600] - Loss: 9.6674\n",
      "[Epoch 2/8 | Step 260/600] - Loss: 9.6119\n",
      "[Epoch 2/8 | Step 270/600] - Loss: 9.6750\n",
      "[Epoch 2/8 | Step 280/600] - Loss: 9.6461\n",
      "[Epoch 2/8 | Step 290/600] - Loss: 9.5560\n",
      "[Epoch 2/8 | Step 300/600] - Loss: 9.5449\n",
      "[Epoch 2/8 | Step 310/600] - Loss: 9.5056\n",
      "[Epoch 2/8 | Step 320/600] - Loss: 9.5419\n",
      "[Epoch 2/8 | Step 330/600] - Loss: 9.5923\n",
      "[Epoch 2/8 | Step 340/600] - Loss: 9.5671\n",
      "[Epoch 2/8 | Step 350/600] - Loss: 9.6549\n",
      "[Epoch 2/8 | Step 360/600] - Loss: 9.6185\n",
      "[Epoch 2/8 | Step 370/600] - Loss: 9.5722\n",
      "[Epoch 2/8 | Step 380/600] - Loss: 9.5754\n",
      "[Epoch 2/8 | Step 390/600] - Loss: 9.6047\n",
      "[Epoch 2/8 | Step 400/600] - Loss: 9.5364\n",
      "[Epoch 2/8 | Step 410/600] - Loss: 9.5501\n",
      "[Epoch 2/8 | Step 420/600] - Loss: 9.5218\n",
      "[Epoch 2/8 | Step 430/600] - Loss: 9.4542\n",
      "[Epoch 2/8 | Step 440/600] - Loss: 9.3920\n",
      "[Epoch 2/8 | Step 450/600] - Loss: 9.4100\n",
      "[Epoch 2/8 | Step 460/600] - Loss: 9.4715\n",
      "[Epoch 2/8 | Step 470/600] - Loss: 9.4195\n",
      "[Epoch 2/8 | Step 480/600] - Loss: 9.4576\n",
      "[Epoch 2/8 | Step 490/600] - Loss: 9.4621\n",
      "[Epoch 2/8 | Step 500/600] - Loss: 9.4431\n",
      "[Epoch 2/8 | Step 510/600] - Loss: 9.4464\n",
      "[Epoch 2/8 | Step 520/600] - Loss: 9.4270\n",
      "[Epoch 2/8 | Step 530/600] - Loss: 9.3926\n",
      "[Epoch 2/8 | Step 540/600] - Loss: 9.3043\n",
      "[Epoch 2/8 | Step 550/600] - Loss: 9.3200\n",
      "[Epoch 2/8 | Step 560/600] - Loss: 9.3705\n",
      "[Epoch 2/8 | Step 570/600] - Loss: 9.3430\n",
      "[Epoch 2/8 | Step 580/600] - Loss: 9.3863\n",
      "[Epoch 2/8 | Step 590/600] - Loss: 9.4338\n",
      "Epoch 2/8 - Avg Train Loss: 9.4102, Val Loss: 9.5868\n",
      "[Epoch 3/8 | Step 0/600] - Loss: 5.8831\n",
      "[Epoch 3/8 | Step 10/600] - Loss: 13.5676\n",
      "[Epoch 3/8 | Step 20/600] - Loss: 11.1653\n",
      "[Epoch 3/8 | Step 30/600] - Loss: 10.2239\n",
      "[Epoch 3/8 | Step 40/600] - Loss: 10.4279\n",
      "[Epoch 3/8 | Step 50/600] - Loss: 9.6902\n",
      "[Epoch 3/8 | Step 60/600] - Loss: 10.0787\n",
      "[Epoch 3/8 | Step 70/600] - Loss: 9.8138\n",
      "[Epoch 3/8 | Step 80/600] - Loss: 9.7139\n",
      "[Epoch 3/8 | Step 90/600] - Loss: 9.8844\n",
      "[Epoch 3/8 | Step 100/600] - Loss: 9.5320\n",
      "[Epoch 3/8 | Step 110/600] - Loss: 9.5304\n",
      "[Epoch 3/8 | Step 120/600] - Loss: 9.7900\n",
      "[Epoch 3/8 | Step 130/600] - Loss: 9.7623\n",
      "[Epoch 3/8 | Step 140/600] - Loss: 9.6270\n",
      "[Epoch 3/8 | Step 150/600] - Loss: 9.7027\n",
      "[Epoch 3/8 | Step 160/600] - Loss: 9.6796\n",
      "[Epoch 3/8 | Step 170/600] - Loss: 9.5917\n",
      "[Epoch 3/8 | Step 180/600] - Loss: 9.6130\n",
      "[Epoch 3/8 | Step 190/600] - Loss: 9.7382\n",
      "[Epoch 3/8 | Step 200/600] - Loss: 9.6314\n",
      "[Epoch 3/8 | Step 210/600] - Loss: 9.7296\n",
      "[Epoch 3/8 | Step 220/600] - Loss: 9.6901\n",
      "[Epoch 3/8 | Step 230/600] - Loss: 9.7950\n",
      "[Epoch 3/8 | Step 240/600] - Loss: 9.7622\n",
      "[Epoch 3/8 | Step 250/600] - Loss: 9.6800\n",
      "[Epoch 3/8 | Step 260/600] - Loss: 9.6529\n",
      "[Epoch 3/8 | Step 270/600] - Loss: 9.6139\n",
      "[Epoch 3/8 | Step 280/600] - Loss: 9.5375\n",
      "[Epoch 3/8 | Step 290/600] - Loss: 9.5587\n",
      "[Epoch 3/8 | Step 300/600] - Loss: 9.5386\n",
      "[Epoch 3/8 | Step 310/600] - Loss: 9.5964\n",
      "[Epoch 3/8 | Step 320/600] - Loss: 9.4869\n",
      "[Epoch 3/8 | Step 330/600] - Loss: 9.5008\n",
      "[Epoch 3/8 | Step 340/600] - Loss: 9.5329\n",
      "[Epoch 3/8 | Step 350/600] - Loss: 9.5747\n",
      "[Epoch 3/8 | Step 360/600] - Loss: 9.5427\n",
      "[Epoch 3/8 | Step 370/600] - Loss: 9.5056\n",
      "[Epoch 3/8 | Step 380/600] - Loss: 9.5891\n",
      "[Epoch 3/8 | Step 390/600] - Loss: 9.6205\n",
      "[Epoch 3/8 | Step 400/600] - Loss: 9.5349\n",
      "[Epoch 3/8 | Step 410/600] - Loss: 9.4439\n",
      "[Epoch 3/8 | Step 420/600] - Loss: 9.4474\n",
      "[Epoch 3/8 | Step 430/600] - Loss: 9.3978\n",
      "[Epoch 3/8 | Step 440/600] - Loss: 9.4321\n",
      "[Epoch 3/8 | Step 450/600] - Loss: 9.3984\n",
      "[Epoch 3/8 | Step 460/600] - Loss: 9.3593\n",
      "[Epoch 3/8 | Step 470/600] - Loss: 9.3208\n",
      "[Epoch 3/8 | Step 480/600] - Loss: 9.2751\n",
      "[Epoch 3/8 | Step 490/600] - Loss: 9.3416\n",
      "[Epoch 3/8 | Step 500/600] - Loss: 9.3030\n",
      "[Epoch 3/8 | Step 510/600] - Loss: 9.2750\n",
      "[Epoch 3/8 | Step 520/600] - Loss: 9.2299\n",
      "[Epoch 3/8 | Step 530/600] - Loss: 9.2099\n",
      "[Epoch 3/8 | Step 540/600] - Loss: 9.1842\n",
      "[Epoch 3/8 | Step 550/600] - Loss: 9.1656\n",
      "[Epoch 3/8 | Step 560/600] - Loss: 9.1525\n",
      "[Epoch 3/8 | Step 570/600] - Loss: 9.1094\n",
      "[Epoch 3/8 | Step 580/600] - Loss: 9.0773\n",
      "[Epoch 3/8 | Step 590/600] - Loss: 9.0534\n",
      "Epoch 3/8 - Avg Train Loss: 9.0370, Val Loss: 9.4337\n",
      "[Epoch 4/8 | Step 0/600] - Loss: 11.5900\n",
      "[Epoch 4/8 | Step 10/600] - Loss: 9.3092\n",
      "[Epoch 4/8 | Step 20/600] - Loss: 8.1298\n",
      "[Epoch 4/8 | Step 30/600] - Loss: 8.6932\n",
      "[Epoch 4/8 | Step 40/600] - Loss: 8.8555\n",
      "[Epoch 4/8 | Step 50/600] - Loss: 9.4904\n",
      "[Epoch 4/8 | Step 60/600] - Loss: 9.4598\n",
      "[Epoch 4/8 | Step 70/600] - Loss: 9.7832\n",
      "[Epoch 4/8 | Step 80/600] - Loss: 9.5488\n",
      "[Epoch 4/8 | Step 90/600] - Loss: 9.4478\n",
      "[Epoch 4/8 | Step 100/600] - Loss: 9.3743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/8 | Step 110/600] - Loss: 9.3907\n",
      "[Epoch 4/8 | Step 120/600] - Loss: 9.2223\n",
      "[Epoch 4/8 | Step 130/600] - Loss: 9.0087\n",
      "[Epoch 4/8 | Step 140/600] - Loss: 9.2886\n",
      "[Epoch 4/8 | Step 150/600] - Loss: 9.1104\n",
      "[Epoch 4/8 | Step 160/600] - Loss: 9.0967\n",
      "[Epoch 4/8 | Step 170/600] - Loss: 9.1297\n",
      "[Epoch 4/8 | Step 180/600] - Loss: 9.1980\n",
      "[Epoch 4/8 | Step 190/600] - Loss: 9.2380\n",
      "[Epoch 4/8 | Step 200/600] - Loss: 9.3561\n",
      "[Epoch 4/8 | Step 210/600] - Loss: 9.2624\n",
      "[Epoch 4/8 | Step 220/600] - Loss: 9.2286\n",
      "[Epoch 4/8 | Step 230/600] - Loss: 9.3336\n",
      "[Epoch 4/8 | Step 240/600] - Loss: 9.1521\n",
      "[Epoch 4/8 | Step 250/600] - Loss: 9.2610\n",
      "[Epoch 4/8 | Step 260/600] - Loss: 9.2316\n",
      "[Epoch 4/8 | Step 270/600] - Loss: 9.1387\n",
      "[Epoch 4/8 | Step 280/600] - Loss: 9.0575\n",
      "[Epoch 4/8 | Step 290/600] - Loss: 8.9446\n",
      "[Epoch 4/8 | Step 300/600] - Loss: 8.9596\n",
      "[Epoch 4/8 | Step 310/600] - Loss: 8.9836\n",
      "[Epoch 4/8 | Step 320/600] - Loss: 8.9811\n",
      "[Epoch 4/8 | Step 330/600] - Loss: 8.9783\n",
      "[Epoch 4/8 | Step 340/600] - Loss: 8.9741\n",
      "[Epoch 4/8 | Step 350/600] - Loss: 9.0319\n",
      "[Epoch 4/8 | Step 360/600] - Loss: 9.0246\n",
      "[Epoch 4/8 | Step 370/600] - Loss: 8.9592\n",
      "[Epoch 4/8 | Step 380/600] - Loss: 8.9917\n",
      "[Epoch 4/8 | Step 390/600] - Loss: 8.8864\n",
      "[Epoch 4/8 | Step 400/600] - Loss: 8.8683\n",
      "[Epoch 4/8 | Step 410/600] - Loss: 8.9467\n",
      "[Epoch 4/8 | Step 420/600] - Loss: 8.9490\n",
      "[Epoch 4/8 | Step 430/600] - Loss: 8.9224\n",
      "[Epoch 4/8 | Step 440/600] - Loss: 8.8909\n",
      "[Epoch 4/8 | Step 450/600] - Loss: 8.9450\n",
      "[Epoch 4/8 | Step 460/600] - Loss: 9.0107\n",
      "[Epoch 4/8 | Step 470/600] - Loss: 9.0211\n",
      "[Epoch 4/8 | Step 480/600] - Loss: 9.0322\n",
      "[Epoch 4/8 | Step 490/600] - Loss: 9.0315\n",
      "[Epoch 4/8 | Step 500/600] - Loss: 9.0255\n",
      "[Epoch 4/8 | Step 510/600] - Loss: 9.0600\n",
      "[Epoch 4/8 | Step 520/600] - Loss: 9.0758\n",
      "[Epoch 4/8 | Step 530/600] - Loss: 9.0225\n",
      "[Epoch 4/8 | Step 540/600] - Loss: 8.9583\n",
      "[Epoch 4/8 | Step 550/600] - Loss: 8.9065\n",
      "[Epoch 4/8 | Step 560/600] - Loss: 8.9257\n",
      "[Epoch 4/8 | Step 570/600] - Loss: 8.9064\n",
      "[Epoch 4/8 | Step 580/600] - Loss: 8.9056\n",
      "[Epoch 4/8 | Step 590/600] - Loss: 8.9298\n",
      "Epoch 4/8 - Avg Train Loss: 8.8941, Val Loss: 9.4102\n",
      "[Epoch 5/8 | Step 0/600] - Loss: 22.3278\n",
      "[Epoch 5/8 | Step 10/600] - Loss: 9.8015\n",
      "[Epoch 5/8 | Step 20/600] - Loss: 8.0001\n",
      "[Epoch 5/8 | Step 30/600] - Loss: 8.0517\n",
      "[Epoch 5/8 | Step 40/600] - Loss: 8.4245\n",
      "[Epoch 5/8 | Step 50/600] - Loss: 8.4476\n",
      "[Epoch 5/8 | Step 60/600] - Loss: 8.6499\n",
      "[Epoch 5/8 | Step 70/600] - Loss: 8.8465\n",
      "[Epoch 5/8 | Step 80/600] - Loss: 8.5592\n",
      "[Epoch 5/8 | Step 90/600] - Loss: 8.6260\n",
      "[Epoch 5/8 | Step 100/600] - Loss: 8.5967\n",
      "[Epoch 5/8 | Step 110/600] - Loss: 8.7387\n",
      "[Epoch 5/8 | Step 120/600] - Loss: 8.5926\n",
      "[Epoch 5/8 | Step 130/600] - Loss: 8.4312\n",
      "[Epoch 5/8 | Step 140/600] - Loss: 8.4213\n",
      "[Epoch 5/8 | Step 150/600] - Loss: 8.5883\n",
      "[Epoch 5/8 | Step 160/600] - Loss: 8.4262\n",
      "[Epoch 5/8 | Step 170/600] - Loss: 8.4730\n",
      "[Epoch 5/8 | Step 180/600] - Loss: 8.5895\n",
      "[Epoch 5/8 | Step 190/600] - Loss: 8.5994\n",
      "[Epoch 5/8 | Step 200/600] - Loss: 8.7241\n",
      "[Epoch 5/8 | Step 210/600] - Loss: 8.7170\n",
      "[Epoch 5/8 | Step 220/600] - Loss: 8.6868\n",
      "[Epoch 5/8 | Step 230/600] - Loss: 8.7442\n",
      "[Epoch 5/8 | Step 240/600] - Loss: 8.7159\n",
      "[Epoch 5/8 | Step 250/600] - Loss: 8.6346\n",
      "[Epoch 5/8 | Step 260/600] - Loss: 8.7672\n",
      "[Epoch 5/8 | Step 270/600] - Loss: 8.7605\n",
      "[Epoch 5/8 | Step 280/600] - Loss: 8.9097\n",
      "[Epoch 5/8 | Step 290/600] - Loss: 8.8797\n",
      "[Epoch 5/8 | Step 300/600] - Loss: 8.8856\n",
      "[Epoch 5/8 | Step 310/600] - Loss: 8.8630\n",
      "[Epoch 5/8 | Step 320/600] - Loss: 8.7970\n",
      "[Epoch 5/8 | Step 330/600] - Loss: 8.8955\n",
      "[Epoch 5/8 | Step 340/600] - Loss: 9.0295\n",
      "[Epoch 5/8 | Step 350/600] - Loss: 8.9741\n",
      "[Epoch 5/8 | Step 360/600] - Loss: 8.9974\n",
      "[Epoch 5/8 | Step 370/600] - Loss: 8.9763\n",
      "[Epoch 5/8 | Step 380/600] - Loss: 8.9478\n",
      "[Epoch 5/8 | Step 390/600] - Loss: 8.8995\n",
      "[Epoch 5/8 | Step 400/600] - Loss: 8.8819\n",
      "[Epoch 5/8 | Step 410/600] - Loss: 8.9135\n",
      "[Epoch 5/8 | Step 420/600] - Loss: 8.9040\n",
      "[Epoch 5/8 | Step 430/600] - Loss: 8.9411\n",
      "[Epoch 5/8 | Step 440/600] - Loss: 9.0071\n",
      "[Epoch 5/8 | Step 450/600] - Loss: 8.9811\n",
      "[Epoch 5/8 | Step 460/600] - Loss: 8.9521\n",
      "[Epoch 5/8 | Step 470/600] - Loss: 8.9860\n",
      "[Epoch 5/8 | Step 480/600] - Loss: 8.9372\n",
      "[Epoch 5/8 | Step 490/600] - Loss: 8.9699\n",
      "[Epoch 5/8 | Step 500/600] - Loss: 8.9699\n",
      "[Epoch 5/8 | Step 510/600] - Loss: 8.8834\n",
      "[Epoch 5/8 | Step 520/600] - Loss: 8.8801\n",
      "[Epoch 5/8 | Step 530/600] - Loss: 8.8185\n",
      "[Epoch 5/8 | Step 540/600] - Loss: 8.8581\n",
      "[Epoch 5/8 | Step 550/600] - Loss: 8.8627\n",
      "[Epoch 5/8 | Step 560/600] - Loss: 8.8056\n",
      "[Epoch 5/8 | Step 570/600] - Loss: 8.8046\n",
      "[Epoch 5/8 | Step 580/600] - Loss: 8.8366\n",
      "[Epoch 5/8 | Step 590/600] - Loss: 8.8213\n",
      "Epoch 5/8 - Avg Train Loss: 8.7660, Val Loss: 9.2690\n",
      "[Epoch 6/8 | Step 0/600] - Loss: 1.2730\n",
      "[Epoch 6/8 | Step 10/600] - Loss: 9.1886\n",
      "[Epoch 6/8 | Step 20/600] - Loss: 8.4469\n",
      "[Epoch 6/8 | Step 30/600] - Loss: 8.4736\n",
      "[Epoch 6/8 | Step 40/600] - Loss: 8.7236\n",
      "[Epoch 6/8 | Step 50/600] - Loss: 8.7017\n",
      "[Epoch 6/8 | Step 60/600] - Loss: 8.1450\n",
      "[Epoch 6/8 | Step 70/600] - Loss: 7.7895\n",
      "[Epoch 6/8 | Step 80/600] - Loss: 7.9277\n",
      "[Epoch 6/8 | Step 90/600] - Loss: 8.0957\n",
      "[Epoch 6/8 | Step 100/600] - Loss: 7.9590\n",
      "[Epoch 6/8 | Step 110/600] - Loss: 8.3150\n",
      "[Epoch 6/8 | Step 120/600] - Loss: 8.6955\n",
      "[Epoch 6/8 | Step 130/600] - Loss: 8.9011\n",
      "[Epoch 6/8 | Step 140/600] - Loss: 8.8331\n",
      "[Epoch 6/8 | Step 150/600] - Loss: 8.7468\n",
      "[Epoch 6/8 | Step 160/600] - Loss: 8.4780\n",
      "[Epoch 6/8 | Step 170/600] - Loss: 8.5365\n",
      "[Epoch 6/8 | Step 180/600] - Loss: 8.6332\n",
      "[Epoch 6/8 | Step 190/600] - Loss: 8.5957\n",
      "[Epoch 6/8 | Step 200/600] - Loss: 8.7069\n",
      "[Epoch 6/8 | Step 210/600] - Loss: 8.8794\n",
      "[Epoch 6/8 | Step 220/600] - Loss: 8.8220\n",
      "[Epoch 6/8 | Step 230/600] - Loss: 8.8636\n",
      "[Epoch 6/8 | Step 240/600] - Loss: 8.8374\n",
      "[Epoch 6/8 | Step 250/600] - Loss: 8.8949\n",
      "[Epoch 6/8 | Step 260/600] - Loss: 9.0147\n",
      "[Epoch 6/8 | Step 270/600] - Loss: 8.9666\n",
      "[Epoch 6/8 | Step 280/600] - Loss: 8.9239\n",
      "[Epoch 6/8 | Step 290/600] - Loss: 8.8363\n",
      "[Epoch 6/8 | Step 300/600] - Loss: 8.8871\n",
      "[Epoch 6/8 | Step 310/600] - Loss: 8.8432\n",
      "[Epoch 6/8 | Step 320/600] - Loss: 8.8782\n",
      "[Epoch 6/8 | Step 330/600] - Loss: 8.8514\n",
      "[Epoch 6/8 | Step 340/600] - Loss: 8.7705\n",
      "[Epoch 6/8 | Step 350/600] - Loss: 8.7548\n",
      "[Epoch 6/8 | Step 360/600] - Loss: 8.7102\n",
      "[Epoch 6/8 | Step 370/600] - Loss: 8.6846\n",
      "[Epoch 6/8 | Step 380/600] - Loss: 8.7112\n",
      "[Epoch 6/8 | Step 390/600] - Loss: 8.7184\n",
      "[Epoch 6/8 | Step 400/600] - Loss: 8.6644\n",
      "[Epoch 6/8 | Step 410/600] - Loss: 8.6646\n",
      "[Epoch 6/8 | Step 420/600] - Loss: 8.6164\n",
      "[Epoch 6/8 | Step 430/600] - Loss: 8.5987\n",
      "[Epoch 6/8 | Step 440/600] - Loss: 8.6912\n",
      "[Epoch 6/8 | Step 450/600] - Loss: 8.7491\n",
      "[Epoch 6/8 | Step 460/600] - Loss: 8.8234\n",
      "[Epoch 6/8 | Step 470/600] - Loss: 8.7954\n",
      "[Epoch 6/8 | Step 480/600] - Loss: 8.8307\n",
      "[Epoch 6/8 | Step 490/600] - Loss: 8.8066\n",
      "[Epoch 6/8 | Step 500/600] - Loss: 8.7473\n",
      "[Epoch 6/8 | Step 510/600] - Loss: 8.7723\n",
      "[Epoch 6/8 | Step 520/600] - Loss: 8.7259\n",
      "[Epoch 6/8 | Step 530/600] - Loss: 8.6735\n",
      "[Epoch 6/8 | Step 540/600] - Loss: 8.6615\n",
      "[Epoch 6/8 | Step 550/600] - Loss: 8.6192\n",
      "[Epoch 6/8 | Step 560/600] - Loss: 8.6134\n",
      "[Epoch 6/8 | Step 570/600] - Loss: 8.5658\n",
      "[Epoch 6/8 | Step 580/600] - Loss: 8.5977\n",
      "[Epoch 6/8 | Step 590/600] - Loss: 8.5653\n",
      "Epoch 6/8 - Avg Train Loss: 8.6248, Val Loss: 9.2020\n",
      "[Epoch 7/8 | Step 0/600] - Loss: 26.2750\n",
      "[Epoch 7/8 | Step 10/600] - Loss: 7.5895\n",
      "[Epoch 7/8 | Step 20/600] - Loss: 8.0906\n",
      "[Epoch 7/8 | Step 30/600] - Loss: 8.5748\n",
      "[Epoch 7/8 | Step 40/600] - Loss: 9.1470\n",
      "[Epoch 7/8 | Step 50/600] - Loss: 9.2051\n",
      "[Epoch 7/8 | Step 60/600] - Loss: 9.6318\n",
      "[Epoch 7/8 | Step 70/600] - Loss: 8.8715\n",
      "[Epoch 7/8 | Step 80/600] - Loss: 8.5731\n",
      "[Epoch 7/8 | Step 90/600] - Loss: 8.5444\n",
      "[Epoch 7/8 | Step 100/600] - Loss: 8.7336\n",
      "[Epoch 7/8 | Step 110/600] - Loss: 9.3419\n",
      "[Epoch 7/8 | Step 120/600] - Loss: 9.1042\n",
      "[Epoch 7/8 | Step 130/600] - Loss: 9.2279\n",
      "[Epoch 7/8 | Step 140/600] - Loss: 9.0945\n",
      "[Epoch 7/8 | Step 150/600] - Loss: 9.2129\n",
      "[Epoch 7/8 | Step 160/600] - Loss: 9.2335\n",
      "[Epoch 7/8 | Step 170/600] - Loss: 9.2445\n",
      "[Epoch 7/8 | Step 180/600] - Loss: 9.1701\n",
      "[Epoch 7/8 | Step 190/600] - Loss: 9.1806\n",
      "[Epoch 7/8 | Step 200/600] - Loss: 9.1216\n",
      "[Epoch 7/8 | Step 210/600] - Loss: 9.1804\n",
      "[Epoch 7/8 | Step 220/600] - Loss: 9.0506\n",
      "[Epoch 7/8 | Step 230/600] - Loss: 9.0244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/8 | Step 240/600] - Loss: 8.9197\n",
      "[Epoch 7/8 | Step 250/600] - Loss: 8.9007\n",
      "[Epoch 7/8 | Step 260/600] - Loss: 8.7709\n",
      "[Epoch 7/8 | Step 270/600] - Loss: 8.8475\n",
      "[Epoch 7/8 | Step 280/600] - Loss: 8.7217\n",
      "[Epoch 7/8 | Step 290/600] - Loss: 8.6705\n",
      "[Epoch 7/8 | Step 300/600] - Loss: 8.5550\n",
      "[Epoch 7/8 | Step 310/600] - Loss: 8.5340\n",
      "[Epoch 7/8 | Step 320/600] - Loss: 8.5365\n",
      "[Epoch 7/8 | Step 330/600] - Loss: 8.4717\n",
      "[Epoch 7/8 | Step 340/600] - Loss: 8.5785\n",
      "[Epoch 7/8 | Step 350/600] - Loss: 8.5440\n",
      "[Epoch 7/8 | Step 360/600] - Loss: 8.5185\n",
      "[Epoch 7/8 | Step 370/600] - Loss: 8.5181\n",
      "[Epoch 7/8 | Step 380/600] - Loss: 8.4169\n",
      "[Epoch 7/8 | Step 390/600] - Loss: 8.4687\n",
      "[Epoch 7/8 | Step 400/600] - Loss: 8.4265\n",
      "[Epoch 7/8 | Step 410/600] - Loss: 8.4188\n",
      "[Epoch 7/8 | Step 420/600] - Loss: 8.3729\n",
      "[Epoch 7/8 | Step 430/600] - Loss: 8.4128\n",
      "[Epoch 7/8 | Step 440/600] - Loss: 8.4537\n",
      "[Epoch 7/8 | Step 450/600] - Loss: 8.4449\n",
      "[Epoch 7/8 | Step 460/600] - Loss: 8.4603\n",
      "[Epoch 7/8 | Step 470/600] - Loss: 8.5004\n",
      "[Epoch 7/8 | Step 480/600] - Loss: 8.5424\n",
      "[Epoch 7/8 | Step 490/600] - Loss: 8.5415\n",
      "[Epoch 7/8 | Step 500/600] - Loss: 8.5859\n",
      "[Epoch 7/8 | Step 510/600] - Loss: 8.6247\n",
      "[Epoch 7/8 | Step 520/600] - Loss: 8.5723\n",
      "[Epoch 7/8 | Step 530/600] - Loss: 8.5699\n",
      "[Epoch 7/8 | Step 540/600] - Loss: 8.5818\n",
      "[Epoch 7/8 | Step 550/600] - Loss: 8.5992\n",
      "[Epoch 7/8 | Step 560/600] - Loss: 8.5615\n",
      "[Epoch 7/8 | Step 570/600] - Loss: 8.5375\n",
      "[Epoch 7/8 | Step 580/600] - Loss: 8.5172\n",
      "[Epoch 7/8 | Step 590/600] - Loss: 8.4746\n",
      "Epoch 7/8 - Avg Train Loss: 8.5001, Val Loss: 9.2089\n",
      "[Epoch 8/8 | Step 0/600] - Loss: 7.3578\n",
      "[Epoch 8/8 | Step 10/600] - Loss: 7.7371\n",
      "[Epoch 8/8 | Step 20/600] - Loss: 7.4634\n",
      "[Epoch 8/8 | Step 30/600] - Loss: 7.5378\n",
      "[Epoch 8/8 | Step 40/600] - Loss: 7.4715\n",
      "[Epoch 8/8 | Step 50/600] - Loss: 7.3716\n",
      "[Epoch 8/8 | Step 60/600] - Loss: 7.1443\n",
      "[Epoch 8/8 | Step 70/600] - Loss: 7.4767\n",
      "[Epoch 8/8 | Step 80/600] - Loss: 7.9104\n",
      "[Epoch 8/8 | Step 90/600] - Loss: 8.4677\n",
      "[Epoch 8/8 | Step 100/600] - Loss: 8.2268\n",
      "[Epoch 8/8 | Step 110/600] - Loss: 8.6698\n",
      "[Epoch 8/8 | Step 120/600] - Loss: 8.7101\n",
      "[Epoch 8/8 | Step 130/600] - Loss: 8.7498\n",
      "[Epoch 8/8 | Step 140/600] - Loss: 8.5944\n",
      "[Epoch 8/8 | Step 150/600] - Loss: 8.5206\n",
      "[Epoch 8/8 | Step 160/600] - Loss: 8.6344\n",
      "[Epoch 8/8 | Step 170/600] - Loss: 8.4987\n",
      "[Epoch 8/8 | Step 180/600] - Loss: 8.3794\n",
      "[Epoch 8/8 | Step 190/600] - Loss: 8.5019\n",
      "[Epoch 8/8 | Step 200/600] - Loss: 8.5540\n",
      "[Epoch 8/8 | Step 210/600] - Loss: 8.6244\n",
      "[Epoch 8/8 | Step 220/600] - Loss: 8.5410\n",
      "[Epoch 8/8 | Step 230/600] - Loss: 8.5196\n",
      "[Epoch 8/8 | Step 240/600] - Loss: 8.4398\n",
      "[Epoch 8/8 | Step 250/600] - Loss: 8.3863\n",
      "[Epoch 8/8 | Step 260/600] - Loss: 8.2349\n",
      "[Epoch 8/8 | Step 270/600] - Loss: 8.2149\n",
      "[Epoch 8/8 | Step 280/600] - Loss: 8.2200\n",
      "[Epoch 8/8 | Step 290/600] - Loss: 8.2503\n",
      "[Epoch 8/8 | Step 300/600] - Loss: 8.3252\n",
      "[Epoch 8/8 | Step 310/600] - Loss: 8.3381\n",
      "[Epoch 8/8 | Step 320/600] - Loss: 8.4233\n",
      "[Epoch 8/8 | Step 330/600] - Loss: 8.4550\n",
      "[Epoch 8/8 | Step 340/600] - Loss: 8.5040\n",
      "[Epoch 8/8 | Step 350/600] - Loss: 8.4297\n",
      "[Epoch 8/8 | Step 360/600] - Loss: 8.4220\n",
      "[Epoch 8/8 | Step 370/600] - Loss: 8.3488\n",
      "[Epoch 8/8 | Step 380/600] - Loss: 8.3159\n",
      "[Epoch 8/8 | Step 390/600] - Loss: 8.3231\n",
      "[Epoch 8/8 | Step 400/600] - Loss: 8.2998\n",
      "[Epoch 8/8 | Step 410/600] - Loss: 8.3241\n",
      "[Epoch 8/8 | Step 420/600] - Loss: 8.3281\n",
      "[Epoch 8/8 | Step 430/600] - Loss: 8.3690\n",
      "[Epoch 8/8 | Step 440/600] - Loss: 8.3710\n",
      "[Epoch 8/8 | Step 450/600] - Loss: 8.3891\n",
      "[Epoch 8/8 | Step 460/600] - Loss: 8.3989\n",
      "[Epoch 8/8 | Step 470/600] - Loss: 8.3973\n",
      "[Epoch 8/8 | Step 480/600] - Loss: 8.3773\n",
      "[Epoch 8/8 | Step 490/600] - Loss: 8.4382\n",
      "[Epoch 8/8 | Step 500/600] - Loss: 8.4043\n",
      "[Epoch 8/8 | Step 510/600] - Loss: 8.3728\n",
      "[Epoch 8/8 | Step 520/600] - Loss: 8.3626\n",
      "[Epoch 8/8 | Step 530/600] - Loss: 8.3819\n",
      "[Epoch 8/8 | Step 540/600] - Loss: 8.4123\n",
      "[Epoch 8/8 | Step 550/600] - Loss: 8.3477\n",
      "[Epoch 8/8 | Step 560/600] - Loss: 8.3893\n",
      "[Epoch 8/8 | Step 570/600] - Loss: 8.4029\n",
      "[Epoch 8/8 | Step 580/600] - Loss: 8.4315\n",
      "[Epoch 8/8 | Step 590/600] - Loss: 8.4049\n",
      "Epoch 8/8 - Avg Train Loss: 8.4206, Val Loss: 9.1939\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoConfig,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from huggingface_hub import login\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    LlamaForSequenceClassification,\n",
    "    LlamaTokenizer,LlamaModel,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoConfig,\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "from huggingface_hub import login\n",
    "import bitsandbytes as bnb\n",
    "import re\n",
    "import traceback\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Set up the GPU environment and return the appropriate device.\"\"\"\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    \n",
    "  \n",
    "    torch.manual_seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    return device\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "\n",
    "def setup_model_and_tokenizer(model_name, device):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    model_config = AutoConfig.from_pretrained(model_name)\n",
    "    model_config.num_labels = 2\n",
    "    model_config.pad_token_id = tokenizer.pad_token_id\n",
    "    model_config.use_cache = False\n",
    "\n",
    "   \n",
    "    quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        config=model_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        quantization_config=quantization_config\n",
    "    )\n",
    "\n",
    "    lora_config = LoraConfig(r=16, lora_alpha=32, target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05, bias=\"none\", task_type=\"SEQ_CLS\")\n",
    "    model = get_peft_model(base_model, lora_config)\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "class PreferenceEmailDataset(Dataset):\n",
    "    def __init__(self, emails_df, tokenizer, max_length=512):\n",
    "        \"\"\"\n",
    "        Dataset to create pairs of message, preferred response, and rejected response for DPO training.\n",
    "        \"\"\"\n",
    "        self.emails_df = emails_df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.pairs = self._create_preference_pairs()\n",
    "\n",
    "    def _create_preference_pairs(self):\n",
    "        \"\"\"\n",
    "        Create pairs using emails from the dataset based on their labels.\n",
    "        \"\"\"\n",
    "        pairs = []\n",
    "        for _, selected_email in self.emails_df.iterrows():\n",
    "            selected_label = selected_email['label']\n",
    "            ham_emails = self.emails_df[self.emails_df['label'] == 0]\n",
    "            phish_emails = self.emails_df[self.emails_df['label'] == 1]\n",
    "\n",
    "            if selected_label == 1:  # Phishing email\n",
    "                preferred_email = phish_emails[phish_emails.index != selected_email.name].sample(n=1).iloc[0]\n",
    "                rejected_email = ham_emails.sample(n=1).iloc[0]\n",
    "                pairs.append({\n",
    "                    'message': selected_email,\n",
    "                    'preferred': preferred_email,\n",
    "                    'rejected': rejected_email\n",
    "                })\n",
    "            elif selected_label == 0:  # Ham email\n",
    "                preferred_email = ham_emails[ham_emails.index != selected_email.name].sample(n=1).iloc[0]\n",
    "                rejected_email = phish_emails.sample(n=1).iloc[0]\n",
    "                pairs.append({\n",
    "                    'message': selected_email,\n",
    "                    'preferred': preferred_email,\n",
    "                    'rejected': rejected_email\n",
    "                })\n",
    "\n",
    "        return pairs\n",
    "\n",
    "    def _prepare_email_input(self, message, response):\n",
    "        \"\"\"\n",
    "        Prepare the input text with formatted message and response for tokenization.\n",
    "        \"\"\"\n",
    "        formatted_input = f\"<s>[INST] {message} [/INST] {response}</s>\"\n",
    "        return self.tokenizer(\n",
    "            formatted_input,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.pairs[idx]\n",
    "        \n",
    "        \n",
    "        if pair['message']['label'] == 1:\n",
    "            message_text = (\n",
    "                \"This email is flagged as a phishing email. \"\n",
    "                \"Carefully examine the sender's address, subject line, and content of the email. \"\n",
    "                f\"Sender: {pair['message']['sender']} [SEP] \"\n",
    "                f\"Subject: {pair['message']['subject']} [SEP] \"\n",
    "                f\"Body: {pair['message']['body']}\"\n",
    "            )\n",
    "        else:\n",
    "            message_text = (\n",
    "                \"This email is flagged as a legitimate email. \"\n",
    "                \"Look for consistent and clear sender details, subject relevance, and authentic body content. \"\n",
    "                f\"Sender: {pair['message']['sender']} [SEP] \"\n",
    "                f\"Subject: {pair['message']['subject']} [SEP] \"\n",
    "                f\"Body: {pair['message']['body']}\"\n",
    "            )\n",
    "        \n",
    "        \n",
    "        preferred_response = (\n",
    "            \"This is a similar email example to the one above. \"\n",
    "            f\"Sender: {pair['preferred']['sender']} [SEP] \"\n",
    "            f\"Subject: {pair['preferred']['subject']} [SEP] \"\n",
    "            f\"Body: {pair['preferred']['body']}\"\n",
    "        )\n",
    "        rejected_response = (\n",
    "            \"This email is different in intent. Notice the sender's address, subject, and content mismatch. \"\n",
    "            f\"Sender: {pair['rejected']['sender']} [SEP] \"\n",
    "            f\"Subject: {pair['rejected']['subject']} [SEP] \"\n",
    "            f\"Body: {pair['rejected']['body']}\"\n",
    "        )\n",
    "        \n",
    "        message_inputs = self._prepare_email_input(message_text, \"\")\n",
    "        preferred_inputs = self._prepare_email_input(message_text, preferred_response)\n",
    "        rejected_inputs = self._prepare_email_input(message_text, rejected_response)\n",
    "\n",
    "        return {\n",
    "            'message_input_ids': message_inputs['input_ids'].squeeze(),\n",
    "            'message_attention_mask': message_inputs['attention_mask'].squeeze(),\n",
    "            'preferred_input_ids': preferred_inputs['input_ids'].squeeze(),\n",
    "            'preferred_attention_mask': preferred_inputs['attention_mask'].squeeze(),\n",
    "            'rejected_input_ids': rejected_inputs['input_ids'].squeeze(),\n",
    "            'rejected_attention_mask': rejected_inputs['attention_mask'].squeeze(),\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "   \n",
    "    if not isinstance(text, str):\n",
    "        text = \"\"\n",
    "    #text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    #text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def compute_dpo_loss(policy_chosen_logits, policy_rejected_logits, \n",
    "                    reference_chosen_logits, reference_rejected_logits, \n",
    "                    beta=0.2):\n",
    "   \n",
    "    epsilon = 1e-8\n",
    "    \n",
    "   \n",
    "    policy_chosen_probs = F.softmax(policy_chosen_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    policy_rejected_probs = F.softmax(policy_rejected_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    ref_chosen_probs = F.softmax(reference_chosen_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    ref_rejected_probs = F.softmax(reference_rejected_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    \n",
    "  \n",
    "    chosen_rewards = (torch.log(policy_chosen_probs + epsilon) - \n",
    "                     torch.log(ref_chosen_probs + epsilon))\n",
    "    rejected_rewards = (torch.log(policy_rejected_probs + epsilon) - \n",
    "                       torch.log(ref_rejected_probs + epsilon))\n",
    "    \n",
    "    \n",
    "    max_reward = 50.0\n",
    "    chosen_rewards = torch.clamp(chosen_rewards, -max_reward, max_reward)\n",
    "    rejected_rewards = torch.clamp(rejected_rewards, -max_reward, max_reward)\n",
    "    \n",
    "    \n",
    "    logits_diff = (chosen_rewards - rejected_rewards) / beta\n",
    "    \n",
    "    valid_mask = ~torch.isnan(logits_diff)\n",
    "    if valid_mask.any():\n",
    "        loss = -F.logsigmoid(logits_diff[valid_mask]).mean()\n",
    "    else:\n",
    "        loss = torch.tensor(0.0, device=logits_diff.device)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def train_model_dpo(policy_model, reference_model, train_loader, val_loader, \n",
    "                   optimizer, scheduler, device, num_epochs=8, beta=0.2, gradient_accumulation_steps=2):\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    policy_model = policy_model.to(device).float()\n",
    "    reference_model = reference_model.to(device).float()\n",
    "    reference_model.eval()  # Ensure reference model does not get updated during training\n",
    "    \n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        policy_model.train()\n",
    "        total_loss = 0\n",
    "        valid_steps = 0\n",
    "        \n",
    "        for step, batch in enumerate(train_loader):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            try:\n",
    "                with torch.amp.autocast('cuda', dtype=torch.float32):\n",
    "                    policy_chosen_outputs = policy_model(\n",
    "                        input_ids=batch['preferred_input_ids'],\n",
    "                        attention_mask=batch['preferred_attention_mask']\n",
    "                    )\n",
    "                    policy_rejected_outputs = policy_model(\n",
    "                        input_ids=batch['rejected_input_ids'],\n",
    "                        attention_mask=batch['rejected_attention_mask']\n",
    "                    )\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        ref_chosen_outputs = reference_model(\n",
    "                            input_ids=batch['preferred_input_ids'],\n",
    "                            attention_mask=batch['preferred_attention_mask']\n",
    "                        )\n",
    "                        ref_rejected_outputs = reference_model(\n",
    "                            input_ids=batch['rejected_input_ids'],\n",
    "                            attention_mask=batch['rejected_attention_mask']\n",
    "                        )\n",
    "                    \n",
    "                    loss = compute_dpo_loss(\n",
    "                        policy_chosen_outputs.logits,\n",
    "                        policy_rejected_outputs.logits,\n",
    "                        ref_chosen_outputs.logits,\n",
    "                        ref_rejected_outputs.logits,\n",
    "                        beta=beta\n",
    "                    )\n",
    "                    \n",
    "                    if not torch.isnan(loss) and not torch.isinf(loss):\n",
    "                        scaler.scale(loss).backward()\n",
    "                        \n",
    "                        # Gradient accumulation logic\n",
    "                        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                            scaler.unscale_(optimizer)\n",
    "                            torch.nn.utils.clip_grad_norm_(policy_model.parameters(), max_norm=1.0)\n",
    "                            scaler.step(optimizer)\n",
    "                            scaler.update()\n",
    "                            scheduler.step()\n",
    "                            optimizer.zero_grad()\n",
    "                        \n",
    "                        total_loss += loss.item()\n",
    "                        valid_steps += 1\n",
    "                    \n",
    "                    if step % 10 == 0:\n",
    "                        avg_loss = total_loss / max(valid_steps, 1)\n",
    "                        print(f\"[Epoch {epoch+1}/{num_epochs} | Step {step}/{len(train_loader)}] - Loss: {avg_loss:.4f}\")\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error in batch {step}: {str(e)}\")\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        if valid_steps > 0:\n",
    "            avg_train_loss = total_loss / valid_steps\n",
    "            val_loss = evaluate_model_dpo(policy_model, reference_model, val_loader, device, beta)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Avg Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_state = {k: v.cpu() for k, v in policy_model.state_dict().items() if isinstance(v, torch.Tensor)}\n",
    "    \n",
    "    return best_model_state\n",
    "\n",
    "def evaluate_model_dpo(policy_model, reference_model, val_loader, device, beta):\n",
    "   \n",
    "    policy_model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            with torch.amp.autocast('cuda', dtype=torch.float32):\n",
    "                policy_chosen_outputs = policy_model(\n",
    "                    input_ids=batch['preferred_input_ids'],\n",
    "                    attention_mask=batch['preferred_attention_mask']\n",
    "                )\n",
    "                policy_rejected_outputs = policy_model(\n",
    "                    input_ids=batch['rejected_input_ids'],\n",
    "                    attention_mask=batch['rejected_attention_mask']\n",
    "                )\n",
    "                \n",
    "                ref_chosen_outputs = reference_model(\n",
    "                    input_ids=batch['preferred_input_ids'],\n",
    "                    attention_mask=batch['preferred_attention_mask']\n",
    "                )\n",
    "                ref_rejected_outputs = reference_model(\n",
    "                    input_ids=batch['rejected_input_ids'],\n",
    "                    attention_mask=batch['rejected_attention_mask']\n",
    "                )\n",
    "                \n",
    "                loss = compute_dpo_loss(\n",
    "                    policy_chosen_outputs.logits,\n",
    "                    policy_rejected_outputs.logits,\n",
    "                    ref_chosen_outputs.logits,\n",
    "                    ref_rejected_outputs.logits,\n",
    "                    beta=beta\n",
    "                )\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "def main():\n",
    "\n",
    "    login(token=\"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\")\n",
    "    device = setup_environment()\n",
    "    model_name =  \"mistralai/Mistral-7B-v0.1\"\n",
    "    data_path = os.path.expanduser(\"~/Downloads/Tune/FineTune/newdata_cleaned.csv\")\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(f\"File not found: {data_path}\")\n",
    "\n",
    "    policy_model, tokenizer = setup_model_and_tokenizer(model_name, device)\n",
    "    reference_model, _ = setup_model_and_tokenizer(model_name, device)\n",
    "    \n",
    "\n",
    "    emails_df = pd.read_csv(data_path)\n",
    "    emails_df['sender'] = emails_df['sender'].astype(str).apply(clean_text)\n",
    "    emails_df['subject'] = emails_df['subject'].astype(str).apply(clean_text)\n",
    "    emails_df['body'] = emails_df['body'].astype(str).apply(clean_text)\n",
    "\n",
    "    train_df, val_df = train_test_split(emails_df, test_size=0.2, stratify=emails_df['label'], random_state=42)\n",
    "\n",
    "  \n",
    "    train_dataset = PreferenceEmailDataset(train_df, tokenizer, max_length=512)\n",
    "    val_dataset = PreferenceEmailDataset(val_df, tokenizer, max_length=512)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # Setup optimization\n",
    "    optimizer = torch.optim.AdamW(policy_model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "    num_epochs = 8\n",
    "    num_training_steps = len(train_loader) * num_epochs\n",
    "    num_warmup_steps = num_training_steps // 20\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "\n",
    "    best_model_state = train_model_dpo(\n",
    "        policy_model,\n",
    "        reference_model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        device,\n",
    "        num_epochs=num_epochs,\n",
    "        beta=0.2\n",
    "    )\n",
    "\n",
    "   \n",
    "    output_dir = os.path.expanduser(\"~/Downloads/Tune/FineTune/dpo_Mistral\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    policy_model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "    config = {\n",
    "        \"model_name\": model_name,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"batch_size\": 8,\n",
    "        \"max_length\": 512,\n",
    "        \"warmup_steps\": num_warmup_steps,\n",
    "        \"total_steps\": num_training_steps,\n",
    "        \"device\": str(device),\n",
    "        \"beta\": 0.2\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"training_config.json\"), \"w\") as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c1cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8eed76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA RTX A5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e736da57be0d434389b927f22b13c633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at deepseek-ai/DeepSeek-R1-Distill-Qwen-7B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7487b0335fbd46478bf4b7ee4ba8f7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at deepseek-ai/DeepSeek-R1-Distill-Qwen-7B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/users/skuikel/anaconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/8 | Step 0/600] - Loss: 11.1326\n",
      "[Epoch 1/8 | Step 10/600] - Loss: 7.2902\n",
      "[Epoch 1/8 | Step 20/600] - Loss: 8.3438\n",
      "[Epoch 1/8 | Step 30/600] - Loss: 8.4150\n",
      "[Epoch 1/8 | Step 40/600] - Loss: 7.8513\n",
      "[Epoch 1/8 | Step 50/600] - Loss: 7.8507\n",
      "[Epoch 1/8 | Step 60/600] - Loss: 8.4181\n",
      "[Epoch 1/8 | Step 70/600] - Loss: 8.1368\n",
      "[Epoch 1/8 | Step 80/600] - Loss: 7.8838\n",
      "[Epoch 1/8 | Step 90/600] - Loss: 7.9143\n",
      "[Epoch 1/8 | Step 100/600] - Loss: 7.7941\n",
      "[Epoch 1/8 | Step 110/600] - Loss: 8.0048\n",
      "[Epoch 1/8 | Step 120/600] - Loss: 8.1687\n",
      "[Epoch 1/8 | Step 130/600] - Loss: 7.9420\n",
      "[Epoch 1/8 | Step 140/600] - Loss: 7.9366\n",
      "[Epoch 1/8 | Step 150/600] - Loss: 7.8189\n",
      "[Epoch 1/8 | Step 160/600] - Loss: 7.9781\n",
      "[Epoch 1/8 | Step 170/600] - Loss: 7.9747\n",
      "[Epoch 1/8 | Step 180/600] - Loss: 7.8100\n",
      "[Epoch 1/8 | Step 190/600] - Loss: 7.7166\n",
      "[Epoch 1/8 | Step 200/600] - Loss: 7.6652\n",
      "[Epoch 1/8 | Step 210/600] - Loss: 7.5877\n",
      "[Epoch 1/8 | Step 220/600] - Loss: 7.4935\n",
      "[Epoch 1/8 | Step 230/600] - Loss: 7.6036\n",
      "[Epoch 1/8 | Step 240/600] - Loss: 7.6039\n",
      "[Epoch 1/8 | Step 250/600] - Loss: 7.6518\n",
      "[Epoch 1/8 | Step 260/600] - Loss: 7.6188\n",
      "[Epoch 1/8 | Step 270/600] - Loss: 7.5100\n",
      "[Epoch 1/8 | Step 280/600] - Loss: 7.4491\n",
      "[Epoch 1/8 | Step 290/600] - Loss: 7.3997\n",
      "[Epoch 1/8 | Step 300/600] - Loss: 7.3619\n",
      "[Epoch 1/8 | Step 310/600] - Loss: 7.3639\n",
      "[Epoch 1/8 | Step 320/600] - Loss: 7.3698\n",
      "[Epoch 1/8 | Step 330/600] - Loss: 7.3533\n",
      "[Epoch 1/8 | Step 340/600] - Loss: 7.3948\n",
      "[Epoch 1/8 | Step 350/600] - Loss: 7.4338\n",
      "[Epoch 1/8 | Step 360/600] - Loss: 7.4296\n",
      "[Epoch 1/8 | Step 370/600] - Loss: 7.4086\n",
      "[Epoch 1/8 | Step 380/600] - Loss: 7.4369\n",
      "[Epoch 1/8 | Step 390/600] - Loss: 7.4460\n",
      "[Epoch 1/8 | Step 400/600] - Loss: 7.4148\n",
      "[Epoch 1/8 | Step 410/600] - Loss: 7.4085\n",
      "[Epoch 1/8 | Step 420/600] - Loss: 7.4138\n",
      "[Epoch 1/8 | Step 430/600] - Loss: 7.4091\n",
      "[Epoch 1/8 | Step 440/600] - Loss: 7.3678\n",
      "[Epoch 1/8 | Step 450/600] - Loss: 7.3696\n",
      "[Epoch 1/8 | Step 460/600] - Loss: 7.3696\n",
      "[Epoch 1/8 | Step 470/600] - Loss: 7.3311\n",
      "[Epoch 1/8 | Step 480/600] - Loss: 7.3466\n",
      "[Epoch 1/8 | Step 490/600] - Loss: 7.3154\n",
      "[Epoch 1/8 | Step 500/600] - Loss: 7.3034\n",
      "[Epoch 1/8 | Step 510/600] - Loss: 7.2658\n",
      "[Epoch 1/8 | Step 520/600] - Loss: 7.2276\n",
      "[Epoch 1/8 | Step 530/600] - Loss: 7.2258\n",
      "[Epoch 1/8 | Step 540/600] - Loss: 7.2032\n",
      "[Epoch 1/8 | Step 550/600] - Loss: 7.2088\n",
      "[Epoch 1/8 | Step 560/600] - Loss: 7.1828\n",
      "[Epoch 1/8 | Step 570/600] - Loss: 7.1747\n",
      "[Epoch 1/8 | Step 580/600] - Loss: 7.1609\n",
      "[Epoch 1/8 | Step 590/600] - Loss: 7.1219\n",
      "Epoch 1/8 - Avg Train Loss: 7.0903, Val Loss: 5.8253\n",
      "[Epoch 2/8 | Step 0/600] - Loss: 7.0433\n",
      "[Epoch 2/8 | Step 10/600] - Loss: 5.9973\n",
      "[Epoch 2/8 | Step 20/600] - Loss: 6.3085\n",
      "[Epoch 2/8 | Step 30/600] - Loss: 5.2653\n",
      "[Epoch 2/8 | Step 40/600] - Loss: 5.4584\n",
      "[Epoch 2/8 | Step 50/600] - Loss: 5.6827\n",
      "[Epoch 2/8 | Step 60/600] - Loss: 6.0327\n",
      "[Epoch 2/8 | Step 70/600] - Loss: 6.2402\n",
      "[Epoch 2/8 | Step 80/600] - Loss: 6.2715\n",
      "[Epoch 2/8 | Step 90/600] - Loss: 6.3980\n",
      "[Epoch 2/8 | Step 100/600] - Loss: 6.4275\n",
      "[Epoch 2/8 | Step 110/600] - Loss: 6.4807\n",
      "[Epoch 2/8 | Step 120/600] - Loss: 6.4142\n",
      "[Epoch 2/8 | Step 130/600] - Loss: 6.2815\n",
      "[Epoch 2/8 | Step 140/600] - Loss: 6.2664\n",
      "[Epoch 2/8 | Step 150/600] - Loss: 6.3194\n",
      "[Epoch 2/8 | Step 160/600] - Loss: 6.3328\n",
      "[Epoch 2/8 | Step 170/600] - Loss: 6.3347\n",
      "[Epoch 2/8 | Step 180/600] - Loss: 6.3984\n",
      "[Epoch 2/8 | Step 190/600] - Loss: 6.3781\n",
      "[Epoch 2/8 | Step 200/600] - Loss: 6.2919\n",
      "[Epoch 2/8 | Step 210/600] - Loss: 6.2073\n",
      "[Epoch 2/8 | Step 220/600] - Loss: 6.2385\n",
      "[Epoch 2/8 | Step 230/600] - Loss: 6.2717\n",
      "[Epoch 2/8 | Step 240/600] - Loss: 6.2679\n",
      "[Epoch 2/8 | Step 250/600] - Loss: 6.3092\n",
      "[Epoch 2/8 | Step 260/600] - Loss: 6.2538\n",
      "[Epoch 2/8 | Step 270/600] - Loss: 6.1020\n",
      "[Epoch 2/8 | Step 280/600] - Loss: 6.0564\n",
      "[Epoch 2/8 | Step 290/600] - Loss: 6.1231\n",
      "[Epoch 2/8 | Step 300/600] - Loss: 6.2010\n",
      "[Epoch 2/8 | Step 310/600] - Loss: 6.1976\n",
      "[Epoch 2/8 | Step 320/600] - Loss: 6.1742\n",
      "[Epoch 2/8 | Step 330/600] - Loss: 6.2193\n",
      "[Epoch 2/8 | Step 340/600] - Loss: 6.1932\n",
      "[Epoch 2/8 | Step 350/600] - Loss: 6.1444\n",
      "[Epoch 2/8 | Step 360/600] - Loss: 6.1343\n",
      "[Epoch 2/8 | Step 370/600] - Loss: 6.1864\n",
      "[Epoch 2/8 | Step 380/600] - Loss: 6.1572\n",
      "[Epoch 2/8 | Step 390/600] - Loss: 6.1357\n",
      "[Epoch 2/8 | Step 400/600] - Loss: 6.1030\n",
      "[Epoch 2/8 | Step 410/600] - Loss: 6.0790\n",
      "[Epoch 2/8 | Step 420/600] - Loss: 6.0895\n",
      "[Epoch 2/8 | Step 430/600] - Loss: 6.0566\n",
      "[Epoch 2/8 | Step 440/600] - Loss: 6.0443\n",
      "[Epoch 2/8 | Step 450/600] - Loss: 6.0291\n",
      "[Epoch 2/8 | Step 460/600] - Loss: 5.9811\n",
      "[Epoch 2/8 | Step 470/600] - Loss: 5.9683\n",
      "[Epoch 2/8 | Step 480/600] - Loss: 5.9367\n",
      "[Epoch 2/8 | Step 490/600] - Loss: 5.9506\n",
      "[Epoch 2/8 | Step 500/600] - Loss: 5.9381\n",
      "[Epoch 2/8 | Step 510/600] - Loss: 5.9004\n",
      "[Epoch 2/8 | Step 520/600] - Loss: 5.9285\n",
      "[Epoch 2/8 | Step 530/600] - Loss: 5.8903\n",
      "[Epoch 2/8 | Step 540/600] - Loss: 5.8509\n",
      "[Epoch 2/8 | Step 550/600] - Loss: 5.8209\n",
      "[Epoch 2/8 | Step 560/600] - Loss: 5.7859\n",
      "[Epoch 2/8 | Step 570/600] - Loss: 5.7611\n",
      "[Epoch 2/8 | Step 580/600] - Loss: 5.7932\n",
      "[Epoch 2/8 | Step 590/600] - Loss: 5.7530\n",
      "Epoch 2/8 - Avg Train Loss: 5.7497, Val Loss: 5.0313\n",
      "[Epoch 3/8 | Step 0/600] - Loss: 9.7026\n",
      "[Epoch 3/8 | Step 10/600] - Loss: 6.2239\n",
      "[Epoch 3/8 | Step 20/600] - Loss: 5.3143\n",
      "[Epoch 3/8 | Step 30/600] - Loss: 5.5650\n",
      "[Epoch 3/8 | Step 40/600] - Loss: 5.6337\n",
      "[Epoch 3/8 | Step 50/600] - Loss: 5.8361\n",
      "[Epoch 3/8 | Step 60/600] - Loss: 5.9356\n",
      "[Epoch 3/8 | Step 70/600] - Loss: 5.9025\n",
      "[Epoch 3/8 | Step 80/600] - Loss: 5.7326\n",
      "[Epoch 3/8 | Step 90/600] - Loss: 5.6595\n",
      "[Epoch 3/8 | Step 100/600] - Loss: 5.8208\n",
      "[Epoch 3/8 | Step 110/600] - Loss: 5.6861\n",
      "[Epoch 3/8 | Step 120/600] - Loss: 5.5671\n",
      "[Epoch 3/8 | Step 130/600] - Loss: 5.4304\n",
      "[Epoch 3/8 | Step 140/600] - Loss: 5.5855\n",
      "[Epoch 3/8 | Step 150/600] - Loss: 5.4177\n",
      "[Epoch 3/8 | Step 160/600] - Loss: 5.4621\n",
      "[Epoch 3/8 | Step 170/600] - Loss: 5.4240\n",
      "[Epoch 3/8 | Step 180/600] - Loss: 5.3667\n",
      "[Epoch 3/8 | Step 190/600] - Loss: 5.3570\n",
      "[Epoch 3/8 | Step 200/600] - Loss: 5.3096\n",
      "[Epoch 3/8 | Step 210/600] - Loss: 5.3109\n",
      "[Epoch 3/8 | Step 220/600] - Loss: 5.2671\n",
      "[Epoch 3/8 | Step 230/600] - Loss: 5.2533\n",
      "[Epoch 3/8 | Step 240/600] - Loss: 5.2874\n",
      "[Epoch 3/8 | Step 250/600] - Loss: 5.3432\n",
      "[Epoch 3/8 | Step 260/600] - Loss: 5.2993\n",
      "[Epoch 3/8 | Step 270/600] - Loss: 5.2595\n",
      "[Epoch 3/8 | Step 280/600] - Loss: 5.2675\n",
      "[Epoch 3/8 | Step 290/600] - Loss: 5.2614\n",
      "[Epoch 3/8 | Step 300/600] - Loss: 5.2932\n",
      "[Epoch 3/8 | Step 310/600] - Loss: 5.2588\n",
      "[Epoch 3/8 | Step 320/600] - Loss: 5.2407\n",
      "[Epoch 3/8 | Step 330/600] - Loss: 5.2001\n",
      "[Epoch 3/8 | Step 340/600] - Loss: 5.1725\n",
      "[Epoch 3/8 | Step 350/600] - Loss: 5.1662\n",
      "[Epoch 3/8 | Step 360/600] - Loss: 5.1543\n",
      "[Epoch 3/8 | Step 370/600] - Loss: 5.1532\n",
      "[Epoch 3/8 | Step 380/600] - Loss: 5.1477\n",
      "[Epoch 3/8 | Step 390/600] - Loss: 5.1666\n",
      "[Epoch 3/8 | Step 400/600] - Loss: 5.1290\n",
      "[Epoch 3/8 | Step 410/600] - Loss: 5.1028\n",
      "[Epoch 3/8 | Step 420/600] - Loss: 5.0864\n",
      "[Epoch 3/8 | Step 430/600] - Loss: 5.1718\n",
      "[Epoch 3/8 | Step 440/600] - Loss: 5.1417\n",
      "[Epoch 3/8 | Step 450/600] - Loss: 5.0687\n",
      "[Epoch 3/8 | Step 460/600] - Loss: 5.0387\n",
      "[Epoch 3/8 | Step 470/600] - Loss: 5.0089\n",
      "[Epoch 3/8 | Step 480/600] - Loss: 4.9574\n",
      "[Epoch 3/8 | Step 490/600] - Loss: 4.9560\n",
      "[Epoch 3/8 | Step 500/600] - Loss: 4.9754\n",
      "[Epoch 3/8 | Step 510/600] - Loss: 5.0058\n",
      "[Epoch 3/8 | Step 520/600] - Loss: 5.0578\n",
      "[Epoch 3/8 | Step 530/600] - Loss: 5.0214\n",
      "[Epoch 3/8 | Step 540/600] - Loss: 4.9853\n",
      "[Epoch 3/8 | Step 550/600] - Loss: 5.0015\n",
      "[Epoch 3/8 | Step 560/600] - Loss: 4.9923\n",
      "[Epoch 3/8 | Step 570/600] - Loss: 4.9820\n",
      "[Epoch 3/8 | Step 580/600] - Loss: 4.9668\n",
      "[Epoch 3/8 | Step 590/600] - Loss: 4.9917\n",
      "Epoch 3/8 - Avg Train Loss: 4.9598, Val Loss: 4.4910\n",
      "[Epoch 4/8 | Step 0/600] - Loss: 4.5671\n",
      "[Epoch 4/8 | Step 10/600] - Loss: 3.7717\n",
      "[Epoch 4/8 | Step 20/600] - Loss: 4.2514\n",
      "[Epoch 4/8 | Step 30/600] - Loss: 4.8803\n",
      "[Epoch 4/8 | Step 40/600] - Loss: 4.4370\n",
      "[Epoch 4/8 | Step 50/600] - Loss: 4.1755\n",
      "[Epoch 4/8 | Step 60/600] - Loss: 4.2786\n",
      "[Epoch 4/8 | Step 70/600] - Loss: 4.2117\n",
      "[Epoch 4/8 | Step 80/600] - Loss: 4.1766\n",
      "[Epoch 4/8 | Step 90/600] - Loss: 4.1763\n",
      "[Epoch 4/8 | Step 100/600] - Loss: 4.3531\n",
      "[Epoch 4/8 | Step 110/600] - Loss: 4.7323\n",
      "[Epoch 4/8 | Step 120/600] - Loss: 4.6211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/8 | Step 130/600] - Loss: 4.5390\n",
      "[Epoch 4/8 | Step 140/600] - Loss: 4.4785\n",
      "[Epoch 4/8 | Step 150/600] - Loss: 4.5305\n",
      "[Epoch 4/8 | Step 160/600] - Loss: 4.5443\n",
      "[Epoch 4/8 | Step 170/600] - Loss: 4.5967\n",
      "[Epoch 4/8 | Step 180/600] - Loss: 4.5678\n",
      "[Epoch 4/8 | Step 190/600] - Loss: 4.5037\n",
      "[Epoch 4/8 | Step 200/600] - Loss: 4.5059\n",
      "[Epoch 4/8 | Step 210/600] - Loss: 4.4589\n",
      "[Epoch 4/8 | Step 220/600] - Loss: 4.4713\n",
      "[Epoch 4/8 | Step 230/600] - Loss: 4.4564\n",
      "[Epoch 4/8 | Step 240/600] - Loss: 4.4210\n",
      "[Epoch 4/8 | Step 250/600] - Loss: 4.3624\n",
      "[Epoch 4/8 | Step 260/600] - Loss: 4.3544\n",
      "[Epoch 4/8 | Step 270/600] - Loss: 4.3536\n",
      "[Epoch 4/8 | Step 280/600] - Loss: 4.3268\n",
      "[Epoch 4/8 | Step 290/600] - Loss: 4.3061\n",
      "[Epoch 4/8 | Step 300/600] - Loss: 4.3422\n",
      "[Epoch 4/8 | Step 310/600] - Loss: 4.4253\n",
      "[Epoch 4/8 | Step 320/600] - Loss: 4.4725\n",
      "[Epoch 4/8 | Step 330/600] - Loss: 4.4494\n",
      "[Epoch 4/8 | Step 340/600] - Loss: 4.5038\n",
      "[Epoch 4/8 | Step 350/600] - Loss: 4.5431\n",
      "[Epoch 4/8 | Step 360/600] - Loss: 4.5875\n",
      "[Epoch 4/8 | Step 370/600] - Loss: 4.5954\n",
      "[Epoch 4/8 | Step 380/600] - Loss: 4.6227\n",
      "[Epoch 4/8 | Step 390/600] - Loss: 4.6242\n",
      "[Epoch 4/8 | Step 400/600] - Loss: 4.5907\n",
      "[Epoch 4/8 | Step 410/600] - Loss: 4.5502\n",
      "[Epoch 4/8 | Step 420/600] - Loss: 4.5591\n",
      "[Epoch 4/8 | Step 430/600] - Loss: 4.5740\n",
      "[Epoch 4/8 | Step 440/600] - Loss: 4.5138\n",
      "[Epoch 4/8 | Step 450/600] - Loss: 4.5158\n",
      "[Epoch 4/8 | Step 460/600] - Loss: 4.5580\n",
      "[Epoch 4/8 | Step 470/600] - Loss: 4.5705\n",
      "[Epoch 4/8 | Step 480/600] - Loss: 4.5704\n",
      "[Epoch 4/8 | Step 490/600] - Loss: 4.5929\n",
      "[Epoch 4/8 | Step 500/600] - Loss: 4.5748\n",
      "[Epoch 4/8 | Step 510/600] - Loss: 4.5720\n",
      "[Epoch 4/8 | Step 520/600] - Loss: 4.5369\n",
      "[Epoch 4/8 | Step 530/600] - Loss: 4.5255\n",
      "[Epoch 4/8 | Step 540/600] - Loss: 4.5146\n",
      "[Epoch 4/8 | Step 550/600] - Loss: 4.4782\n",
      "[Epoch 4/8 | Step 560/600] - Loss: 4.4643\n",
      "[Epoch 4/8 | Step 570/600] - Loss: 4.4612\n",
      "[Epoch 4/8 | Step 580/600] - Loss: 4.4572\n",
      "[Epoch 4/8 | Step 590/600] - Loss: 4.4571\n",
      "Epoch 4/8 - Avg Train Loss: 4.4463, Val Loss: 4.0878\n",
      "[Epoch 5/8 | Step 0/600] - Loss: 2.7981\n",
      "[Epoch 5/8 | Step 10/600] - Loss: 4.9667\n",
      "[Epoch 5/8 | Step 20/600] - Loss: 5.0561\n",
      "[Epoch 5/8 | Step 30/600] - Loss: 4.3871\n",
      "[Epoch 5/8 | Step 40/600] - Loss: 4.0525\n",
      "[Epoch 5/8 | Step 50/600] - Loss: 4.1553\n",
      "[Epoch 5/8 | Step 60/600] - Loss: 3.8928\n",
      "[Epoch 5/8 | Step 70/600] - Loss: 3.8578\n",
      "[Epoch 5/8 | Step 80/600] - Loss: 3.8690\n",
      "[Epoch 5/8 | Step 90/600] - Loss: 4.0588\n",
      "[Epoch 5/8 | Step 100/600] - Loss: 3.9873\n",
      "[Epoch 5/8 | Step 110/600] - Loss: 4.1201\n",
      "[Epoch 5/8 | Step 120/600] - Loss: 4.0145\n",
      "[Epoch 5/8 | Step 130/600] - Loss: 4.0928\n",
      "[Epoch 5/8 | Step 140/600] - Loss: 4.0053\n",
      "[Epoch 5/8 | Step 150/600] - Loss: 4.0844\n",
      "[Epoch 5/8 | Step 160/600] - Loss: 4.0738\n",
      "[Epoch 5/8 | Step 170/600] - Loss: 4.1287\n",
      "[Epoch 5/8 | Step 180/600] - Loss: 4.0854\n",
      "[Epoch 5/8 | Step 190/600] - Loss: 4.0508\n",
      "[Epoch 5/8 | Step 200/600] - Loss: 3.9863\n",
      "[Epoch 5/8 | Step 210/600] - Loss: 3.9734\n",
      "[Epoch 5/8 | Step 220/600] - Loss: 3.9840\n",
      "[Epoch 5/8 | Step 230/600] - Loss: 3.9578\n",
      "[Epoch 5/8 | Step 240/600] - Loss: 3.9696\n",
      "[Epoch 5/8 | Step 250/600] - Loss: 3.8954\n",
      "[Epoch 5/8 | Step 260/600] - Loss: 3.8837\n",
      "[Epoch 5/8 | Step 270/600] - Loss: 3.9506\n",
      "[Epoch 5/8 | Step 280/600] - Loss: 3.9738\n",
      "[Epoch 5/8 | Step 290/600] - Loss: 3.9897\n",
      "[Epoch 5/8 | Step 300/600] - Loss: 4.0068\n",
      "[Epoch 5/8 | Step 310/600] - Loss: 3.9787\n",
      "[Epoch 5/8 | Step 320/600] - Loss: 4.0287\n",
      "[Epoch 5/8 | Step 330/600] - Loss: 4.0428\n",
      "[Epoch 5/8 | Step 340/600] - Loss: 4.0301\n",
      "[Epoch 5/8 | Step 350/600] - Loss: 4.0700\n",
      "[Epoch 5/8 | Step 360/600] - Loss: 4.1303\n",
      "[Epoch 5/8 | Step 370/600] - Loss: 4.0977\n",
      "[Epoch 5/8 | Step 380/600] - Loss: 4.1139\n",
      "[Epoch 5/8 | Step 390/600] - Loss: 4.1606\n",
      "[Epoch 5/8 | Step 400/600] - Loss: 4.2044\n",
      "[Epoch 5/8 | Step 410/600] - Loss: 4.2053\n",
      "[Epoch 5/8 | Step 420/600] - Loss: 4.2052\n",
      "[Epoch 5/8 | Step 430/600] - Loss: 4.1652\n",
      "[Epoch 5/8 | Step 440/600] - Loss: 4.1945\n",
      "[Epoch 5/8 | Step 450/600] - Loss: 4.2088\n",
      "[Epoch 5/8 | Step 460/600] - Loss: 4.2102\n",
      "[Epoch 5/8 | Step 470/600] - Loss: 4.2486\n",
      "[Epoch 5/8 | Step 480/600] - Loss: 4.2398\n",
      "[Epoch 5/8 | Step 490/600] - Loss: 4.2091\n",
      "[Epoch 5/8 | Step 500/600] - Loss: 4.1911\n",
      "[Epoch 5/8 | Step 510/600] - Loss: 4.1915\n",
      "[Epoch 5/8 | Step 520/600] - Loss: 4.1899\n",
      "[Epoch 5/8 | Step 530/600] - Loss: 4.1565\n",
      "[Epoch 5/8 | Step 540/600] - Loss: 4.1239\n",
      "[Epoch 5/8 | Step 550/600] - Loss: 4.0966\n",
      "[Epoch 5/8 | Step 560/600] - Loss: 4.0956\n",
      "[Epoch 5/8 | Step 570/600] - Loss: 4.1168\n",
      "[Epoch 5/8 | Step 580/600] - Loss: 4.0856\n",
      "[Epoch 5/8 | Step 590/600] - Loss: 4.0747\n",
      "Epoch 5/8 - Avg Train Loss: 4.0820, Val Loss: 3.7946\n",
      "[Epoch 6/8 | Step 0/600] - Loss: 3.8467\n",
      "[Epoch 6/8 | Step 10/600] - Loss: 3.9631\n",
      "[Epoch 6/8 | Step 20/600] - Loss: 3.5276\n",
      "[Epoch 6/8 | Step 30/600] - Loss: 4.4337\n",
      "[Epoch 6/8 | Step 40/600] - Loss: 4.1127\n",
      "[Epoch 6/8 | Step 50/600] - Loss: 4.0479\n",
      "[Epoch 6/8 | Step 60/600] - Loss: 4.2091\n",
      "[Epoch 6/8 | Step 70/600] - Loss: 4.3496\n",
      "[Epoch 6/8 | Step 80/600] - Loss: 4.4538\n",
      "[Epoch 6/8 | Step 90/600] - Loss: 4.3905\n",
      "[Epoch 6/8 | Step 100/600] - Loss: 4.3021\n",
      "[Epoch 6/8 | Step 110/600] - Loss: 4.2754\n",
      "[Epoch 6/8 | Step 120/600] - Loss: 4.1291\n",
      "[Epoch 6/8 | Step 130/600] - Loss: 4.0470\n",
      "[Epoch 6/8 | Step 140/600] - Loss: 3.9553\n",
      "[Epoch 6/8 | Step 150/600] - Loss: 4.0059\n",
      "[Epoch 6/8 | Step 160/600] - Loss: 4.0139\n",
      "[Epoch 6/8 | Step 170/600] - Loss: 4.0684\n",
      "[Epoch 6/8 | Step 180/600] - Loss: 4.0232\n",
      "[Epoch 6/8 | Step 190/600] - Loss: 4.0221\n",
      "[Epoch 6/8 | Step 200/600] - Loss: 4.0443\n",
      "[Epoch 6/8 | Step 210/600] - Loss: 4.0756\n",
      "[Epoch 6/8 | Step 220/600] - Loss: 3.9922\n",
      "[Epoch 6/8 | Step 230/600] - Loss: 3.9623\n",
      "[Epoch 6/8 | Step 240/600] - Loss: 4.0175\n",
      "[Epoch 6/8 | Step 250/600] - Loss: 4.0292\n",
      "[Epoch 6/8 | Step 260/600] - Loss: 3.9817\n",
      "[Epoch 6/8 | Step 270/600] - Loss: 3.9407\n",
      "[Epoch 6/8 | Step 280/600] - Loss: 3.8801\n",
      "[Epoch 6/8 | Step 290/600] - Loss: 3.8135\n",
      "[Epoch 6/8 | Step 300/600] - Loss: 3.7717\n",
      "[Epoch 6/8 | Step 310/600] - Loss: 3.7991\n",
      "[Epoch 6/8 | Step 320/600] - Loss: 3.7943\n",
      "[Epoch 6/8 | Step 330/600] - Loss: 3.8344\n",
      "[Epoch 6/8 | Step 340/600] - Loss: 3.8335\n",
      "[Epoch 6/8 | Step 350/600] - Loss: 3.8021\n",
      "[Epoch 6/8 | Step 360/600] - Loss: 3.7969\n",
      "[Epoch 6/8 | Step 370/600] - Loss: 3.7740\n",
      "[Epoch 6/8 | Step 380/600] - Loss: 3.7543\n",
      "[Epoch 6/8 | Step 390/600] - Loss: 3.7573\n",
      "[Epoch 6/8 | Step 400/600] - Loss: 3.8001\n",
      "[Epoch 6/8 | Step 410/600] - Loss: 3.7990\n",
      "[Epoch 6/8 | Step 420/600] - Loss: 3.7950\n",
      "[Epoch 6/8 | Step 430/600] - Loss: 3.7738\n",
      "[Epoch 6/8 | Step 440/600] - Loss: 3.7675\n",
      "[Epoch 6/8 | Step 450/600] - Loss: 3.7726\n",
      "[Epoch 6/8 | Step 460/600] - Loss: 3.7426\n",
      "[Epoch 6/8 | Step 470/600] - Loss: 3.7325\n",
      "[Epoch 6/8 | Step 480/600] - Loss: 3.7373\n",
      "[Epoch 6/8 | Step 490/600] - Loss: 3.7461\n",
      "[Epoch 6/8 | Step 500/600] - Loss: 3.7302\n",
      "[Epoch 6/8 | Step 510/600] - Loss: 3.7343\n",
      "[Epoch 6/8 | Step 520/600] - Loss: 3.7528\n",
      "[Epoch 6/8 | Step 530/600] - Loss: 3.7403\n",
      "[Epoch 6/8 | Step 540/600] - Loss: 3.7360\n",
      "[Epoch 6/8 | Step 550/600] - Loss: 3.7641\n",
      "[Epoch 6/8 | Step 560/600] - Loss: 3.7477\n",
      "[Epoch 6/8 | Step 570/600] - Loss: 3.7544\n",
      "[Epoch 6/8 | Step 580/600] - Loss: 3.7732\n",
      "[Epoch 6/8 | Step 590/600] - Loss: 3.7965\n",
      "Epoch 6/8 - Avg Train Loss: 3.7999, Val Loss: 3.5873\n",
      "[Epoch 7/8 | Step 0/600] - Loss: 0.4026\n",
      "[Epoch 7/8 | Step 10/600] - Loss: 4.0283\n",
      "[Epoch 7/8 | Step 20/600] - Loss: 3.7955\n",
      "[Epoch 7/8 | Step 30/600] - Loss: 3.7222\n",
      "[Epoch 7/8 | Step 40/600] - Loss: 3.4225\n",
      "[Epoch 7/8 | Step 50/600] - Loss: 3.2536\n",
      "[Epoch 7/8 | Step 60/600] - Loss: 3.1669\n",
      "[Epoch 7/8 | Step 70/600] - Loss: 3.0639\n",
      "[Epoch 7/8 | Step 80/600] - Loss: 3.2268\n",
      "[Epoch 7/8 | Step 90/600] - Loss: 3.3424\n",
      "[Epoch 7/8 | Step 100/600] - Loss: 3.4571\n",
      "[Epoch 7/8 | Step 110/600] - Loss: 3.5560\n",
      "[Epoch 7/8 | Step 120/600] - Loss: 3.5231\n",
      "[Epoch 7/8 | Step 130/600] - Loss: 3.4988\n",
      "[Epoch 7/8 | Step 140/600] - Loss: 3.4989\n",
      "[Epoch 7/8 | Step 150/600] - Loss: 3.5061\n",
      "[Epoch 7/8 | Step 160/600] - Loss: 3.3941\n",
      "[Epoch 7/8 | Step 170/600] - Loss: 3.3910\n",
      "[Epoch 7/8 | Step 180/600] - Loss: 3.4281\n",
      "[Epoch 7/8 | Step 190/600] - Loss: 3.4355\n",
      "[Epoch 7/8 | Step 200/600] - Loss: 3.4155\n",
      "[Epoch 7/8 | Step 210/600] - Loss: 3.3990\n",
      "[Epoch 7/8 | Step 220/600] - Loss: 3.3725\n",
      "[Epoch 7/8 | Step 230/600] - Loss: 3.3813\n",
      "[Epoch 7/8 | Step 240/600] - Loss: 3.3729\n",
      "[Epoch 7/8 | Step 250/600] - Loss: 3.4183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/8 | Step 260/600] - Loss: 3.3792\n",
      "[Epoch 7/8 | Step 270/600] - Loss: 3.4037\n",
      "[Epoch 7/8 | Step 280/600] - Loss: 3.4710\n",
      "[Epoch 7/8 | Step 290/600] - Loss: 3.4164\n",
      "[Epoch 7/8 | Step 300/600] - Loss: 3.4348\n",
      "[Epoch 7/8 | Step 310/600] - Loss: 3.4249\n",
      "[Epoch 7/8 | Step 320/600] - Loss: 3.3941\n",
      "[Epoch 7/8 | Step 330/600] - Loss: 3.3928\n",
      "[Epoch 7/8 | Step 340/600] - Loss: 3.3557\n",
      "[Epoch 7/8 | Step 350/600] - Loss: 3.3390\n",
      "[Epoch 7/8 | Step 360/600] - Loss: 3.3762\n",
      "[Epoch 7/8 | Step 370/600] - Loss: 3.3593\n",
      "[Epoch 7/8 | Step 380/600] - Loss: 3.3653\n",
      "[Epoch 7/8 | Step 390/600] - Loss: 3.3405\n",
      "[Epoch 7/8 | Step 400/600] - Loss: 3.3533\n",
      "[Epoch 7/8 | Step 410/600] - Loss: 3.3973\n",
      "[Epoch 7/8 | Step 420/600] - Loss: 3.3937\n",
      "[Epoch 7/8 | Step 430/600] - Loss: 3.4050\n",
      "[Epoch 7/8 | Step 440/600] - Loss: 3.4006\n",
      "[Epoch 7/8 | Step 450/600] - Loss: 3.4020\n",
      "[Epoch 7/8 | Step 460/600] - Loss: 3.4112\n",
      "[Epoch 7/8 | Step 470/600] - Loss: 3.4525\n",
      "[Epoch 7/8 | Step 480/600] - Loss: 3.4092\n",
      "[Epoch 7/8 | Step 490/600] - Loss: 3.4216\n",
      "[Epoch 7/8 | Step 500/600] - Loss: 3.4003\n",
      "[Epoch 7/8 | Step 510/600] - Loss: 3.3674\n",
      "[Epoch 7/8 | Step 520/600] - Loss: 3.3635\n",
      "[Epoch 7/8 | Step 530/600] - Loss: 3.3482\n",
      "[Epoch 7/8 | Step 540/600] - Loss: 3.3922\n",
      "[Epoch 7/8 | Step 550/600] - Loss: 3.4005\n",
      "[Epoch 7/8 | Step 560/600] - Loss: 3.4499\n",
      "[Epoch 7/8 | Step 570/600] - Loss: 3.4644\n",
      "[Epoch 7/8 | Step 580/600] - Loss: 3.4971\n",
      "[Epoch 7/8 | Step 590/600] - Loss: 3.5407\n",
      "Epoch 7/8 - Avg Train Loss: 3.5765, Val Loss: 3.4401\n",
      "[Epoch 8/8 | Step 0/600] - Loss: 2.3882\n",
      "[Epoch 8/8 | Step 10/600] - Loss: 5.1278\n",
      "[Epoch 8/8 | Step 20/600] - Loss: 4.4586\n",
      "[Epoch 8/8 | Step 30/600] - Loss: 4.4169\n",
      "[Epoch 8/8 | Step 40/600] - Loss: 4.6439\n",
      "[Epoch 8/8 | Step 50/600] - Loss: 4.6106\n",
      "[Epoch 8/8 | Step 60/600] - Loss: 4.8352\n",
      "[Epoch 8/8 | Step 70/600] - Loss: 4.5340\n",
      "[Epoch 8/8 | Step 80/600] - Loss: 4.5089\n",
      "[Epoch 8/8 | Step 90/600] - Loss: 4.3415\n",
      "[Epoch 8/8 | Step 100/600] - Loss: 4.3425\n",
      "[Epoch 8/8 | Step 110/600] - Loss: 4.3409\n",
      "[Epoch 8/8 | Step 120/600] - Loss: 4.3837\n",
      "[Epoch 8/8 | Step 130/600] - Loss: 4.3633\n",
      "[Epoch 8/8 | Step 140/600] - Loss: 4.2463\n",
      "[Epoch 8/8 | Step 150/600] - Loss: 4.0941\n",
      "[Epoch 8/8 | Step 160/600] - Loss: 3.9552\n",
      "[Epoch 8/8 | Step 170/600] - Loss: 3.9339\n",
      "[Epoch 8/8 | Step 180/600] - Loss: 3.8764\n",
      "[Epoch 8/8 | Step 190/600] - Loss: 3.8488\n",
      "[Epoch 8/8 | Step 200/600] - Loss: 3.7446\n",
      "[Epoch 8/8 | Step 210/600] - Loss: 3.6736\n",
      "[Epoch 8/8 | Step 220/600] - Loss: 3.6323\n",
      "[Epoch 8/8 | Step 230/600] - Loss: 3.6002\n",
      "[Epoch 8/8 | Step 240/600] - Loss: 3.5387\n",
      "[Epoch 8/8 | Step 250/600] - Loss: 3.5806\n",
      "[Epoch 8/8 | Step 260/600] - Loss: 3.5661\n",
      "[Epoch 8/8 | Step 270/600] - Loss: 3.6122\n",
      "[Epoch 8/8 | Step 280/600] - Loss: 3.6506\n",
      "[Epoch 8/8 | Step 290/600] - Loss: 3.6835\n",
      "[Epoch 8/8 | Step 300/600] - Loss: 3.6617\n",
      "[Epoch 8/8 | Step 310/600] - Loss: 3.6197\n",
      "[Epoch 8/8 | Step 320/600] - Loss: 3.5919\n",
      "[Epoch 8/8 | Step 330/600] - Loss: 3.5923\n",
      "[Epoch 8/8 | Step 340/600] - Loss: 3.5372\n",
      "[Epoch 8/8 | Step 350/600] - Loss: 3.4908\n",
      "[Epoch 8/8 | Step 360/600] - Loss: 3.5510\n",
      "[Epoch 8/8 | Step 370/600] - Loss: 3.5540\n",
      "[Epoch 8/8 | Step 380/600] - Loss: 3.5404\n",
      "[Epoch 8/8 | Step 390/600] - Loss: 3.5019\n",
      "[Epoch 8/8 | Step 400/600] - Loss: 3.4878\n",
      "[Epoch 8/8 | Step 410/600] - Loss: 3.4743\n",
      "[Epoch 8/8 | Step 420/600] - Loss: 3.4495\n",
      "[Epoch 8/8 | Step 430/600] - Loss: 3.4516\n",
      "[Epoch 8/8 | Step 440/600] - Loss: 3.4294\n",
      "[Epoch 8/8 | Step 450/600] - Loss: 3.4336\n",
      "[Epoch 8/8 | Step 460/600] - Loss: 3.4254\n",
      "[Epoch 8/8 | Step 470/600] - Loss: 3.4260\n",
      "[Epoch 8/8 | Step 480/600] - Loss: 3.4112\n",
      "[Epoch 8/8 | Step 490/600] - Loss: 3.4092\n",
      "[Epoch 8/8 | Step 500/600] - Loss: 3.4202\n",
      "[Epoch 8/8 | Step 510/600] - Loss: 3.4258\n",
      "[Epoch 8/8 | Step 520/600] - Loss: 3.4203\n",
      "[Epoch 8/8 | Step 530/600] - Loss: 3.4208\n",
      "[Epoch 8/8 | Step 540/600] - Loss: 3.3958\n",
      "[Epoch 8/8 | Step 550/600] - Loss: 3.3692\n",
      "[Epoch 8/8 | Step 560/600] - Loss: 3.3853\n",
      "[Epoch 8/8 | Step 570/600] - Loss: 3.4080\n",
      "[Epoch 8/8 | Step 580/600] - Loss: 3.4184\n",
      "[Epoch 8/8 | Step 590/600] - Loss: 3.4062\n",
      "Epoch 8/8 - Avg Train Loss: 3.3962, Val Loss: 3.3197\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoConfig,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from huggingface_hub import login\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    LlamaForSequenceClassification,\n",
    "    LlamaTokenizer,LlamaModel,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AutoConfig,\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "from huggingface_hub import login\n",
    "import bitsandbytes as bnb\n",
    "import re\n",
    "import traceback\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Set up the GPU environment and return the appropriate device.\"\"\"\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    \n",
    "  \n",
    "    torch.manual_seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    return device\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "\n",
    "def setup_model_and_tokenizer(model_name, device):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    model_config = AutoConfig.from_pretrained(model_name)\n",
    "    model_config.num_labels = 2\n",
    "    model_config.pad_token_id = tokenizer.pad_token_id\n",
    "    model_config.use_cache = False\n",
    "\n",
    "   \n",
    "    quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        config=model_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        quantization_config=quantization_config\n",
    "    )\n",
    "\n",
    "    lora_config = LoraConfig(r=16, lora_alpha=32, target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05, bias=\"none\", task_type=\"SEQ_CLS\")\n",
    "    model = get_peft_model(base_model, lora_config)\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "class PreferenceEmailDataset(Dataset):\n",
    "    def __init__(self, emails_df, tokenizer, max_length=512):\n",
    "        \"\"\"\n",
    "        Dataset to create pairs of message, preferred response, and rejected response for DPO training.\n",
    "        \"\"\"\n",
    "        self.emails_df = emails_df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.pairs = self._create_preference_pairs()\n",
    "\n",
    "    def _create_preference_pairs(self):\n",
    "        \"\"\"\n",
    "        Create pairs using emails from the dataset based on their labels.\n",
    "        \"\"\"\n",
    "        pairs = []\n",
    "        for _, selected_email in self.emails_df.iterrows():\n",
    "            selected_label = selected_email['label']\n",
    "            ham_emails = self.emails_df[self.emails_df['label'] == 0]\n",
    "            phish_emails = self.emails_df[self.emails_df['label'] == 1]\n",
    "\n",
    "            if selected_label == 1:  # Phishing email\n",
    "                preferred_email = phish_emails[phish_emails.index != selected_email.name].sample(n=1).iloc[0]\n",
    "                rejected_email = ham_emails.sample(n=1).iloc[0]\n",
    "                pairs.append({\n",
    "                    'message': selected_email,\n",
    "                    'preferred': preferred_email,\n",
    "                    'rejected': rejected_email\n",
    "                })\n",
    "            elif selected_label == 0:  # Ham email\n",
    "                preferred_email = ham_emails[ham_emails.index != selected_email.name].sample(n=1).iloc[0]\n",
    "                rejected_email = phish_emails.sample(n=1).iloc[0]\n",
    "                pairs.append({\n",
    "                    'message': selected_email,\n",
    "                    'preferred': preferred_email,\n",
    "                    'rejected': rejected_email\n",
    "                })\n",
    "\n",
    "        return pairs\n",
    "\n",
    "    def _prepare_email_input(self, message, response):\n",
    "        \"\"\"\n",
    "        Prepare the input text with formatted message and response for tokenization.\n",
    "        \"\"\"\n",
    "        formatted_input = f\"<s>[INST] {message} [/INST] {response}</s>\"\n",
    "        return self.tokenizer(\n",
    "            formatted_input,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.pairs[idx]\n",
    "        \n",
    "        \n",
    "        if pair['message']['label'] == 1:\n",
    "            message_text = (\n",
    "                \"This email is flagged as a phishing email. \"\n",
    "                \"Carefully examine the sender's address, subject line, and content of the email. \"\n",
    "                f\"Sender: {pair['message']['sender']} [SEP] \"\n",
    "                f\"Subject: {pair['message']['subject']} [SEP] \"\n",
    "                f\"Body: {pair['message']['body']}\"\n",
    "            )\n",
    "        else:\n",
    "            message_text = (\n",
    "                \"This email is flagged as a legitimate email. \"\n",
    "                \"Look for consistent and clear sender details, subject relevance, and authentic body content. \"\n",
    "                f\"Sender: {pair['message']['sender']} [SEP] \"\n",
    "                f\"Subject: {pair['message']['subject']} [SEP] \"\n",
    "                f\"Body: {pair['message']['body']}\"\n",
    "            )\n",
    "        \n",
    "        \n",
    "        preferred_response = (\n",
    "            \"This is a similar email example to the one above. \"\n",
    "            f\"Sender: {pair['preferred']['sender']} [SEP] \"\n",
    "            f\"Subject: {pair['preferred']['subject']} [SEP] \"\n",
    "            f\"Body: {pair['preferred']['body']}\"\n",
    "        )\n",
    "        rejected_response = (\n",
    "            \"This email is different in intent. Notice the sender's address, subject, and content mismatch. \"\n",
    "            f\"Sender: {pair['rejected']['sender']} [SEP] \"\n",
    "            f\"Subject: {pair['rejected']['subject']} [SEP] \"\n",
    "            f\"Body: {pair['rejected']['body']}\"\n",
    "        )\n",
    "        \n",
    "        message_inputs = self._prepare_email_input(message_text, \"\")\n",
    "        preferred_inputs = self._prepare_email_input(message_text, preferred_response)\n",
    "        rejected_inputs = self._prepare_email_input(message_text, rejected_response)\n",
    "\n",
    "        return {\n",
    "            'message_input_ids': message_inputs['input_ids'].squeeze(),\n",
    "            'message_attention_mask': message_inputs['attention_mask'].squeeze(),\n",
    "            'preferred_input_ids': preferred_inputs['input_ids'].squeeze(),\n",
    "            'preferred_attention_mask': preferred_inputs['attention_mask'].squeeze(),\n",
    "            'rejected_input_ids': rejected_inputs['input_ids'].squeeze(),\n",
    "            'rejected_attention_mask': rejected_inputs['attention_mask'].squeeze(),\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "   \n",
    "    if not isinstance(text, str):\n",
    "        text = \"\"\n",
    "    #text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    #text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def compute_dpo_loss(policy_chosen_logits, policy_rejected_logits, \n",
    "                    reference_chosen_logits, reference_rejected_logits, \n",
    "                    beta=0.2):\n",
    "   \n",
    "    epsilon = 1e-8\n",
    "    \n",
    "   \n",
    "    policy_chosen_probs = F.softmax(policy_chosen_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    policy_rejected_probs = F.softmax(policy_rejected_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    ref_chosen_probs = F.softmax(reference_chosen_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    ref_rejected_probs = F.softmax(reference_rejected_logits, dim=-1)[:, 0].clamp(epsilon, 1-epsilon)\n",
    "    \n",
    "  \n",
    "    chosen_rewards = (torch.log(policy_chosen_probs + epsilon) - \n",
    "                     torch.log(ref_chosen_probs + epsilon))\n",
    "    rejected_rewards = (torch.log(policy_rejected_probs + epsilon) - \n",
    "                       torch.log(ref_rejected_probs + epsilon))\n",
    "    \n",
    "    \n",
    "    max_reward = 50.0\n",
    "    chosen_rewards = torch.clamp(chosen_rewards, -max_reward, max_reward)\n",
    "    rejected_rewards = torch.clamp(rejected_rewards, -max_reward, max_reward)\n",
    "    \n",
    "    \n",
    "    logits_diff = (chosen_rewards - rejected_rewards) / beta\n",
    "    \n",
    "    valid_mask = ~torch.isnan(logits_diff)\n",
    "    if valid_mask.any():\n",
    "        loss = -F.logsigmoid(logits_diff[valid_mask]).mean()\n",
    "    else:\n",
    "        loss = torch.tensor(0.0, device=logits_diff.device)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def train_model_dpo(policy_model, reference_model, train_loader, val_loader, \n",
    "                   optimizer, scheduler, device, num_epochs=8, beta=0.2, gradient_accumulation_steps=2):\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    policy_model = policy_model.to(device).float()\n",
    "    reference_model = reference_model.to(device).float()\n",
    "    reference_model.eval()  # Ensure reference model does not get updated during training\n",
    "    \n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        policy_model.train()\n",
    "        total_loss = 0\n",
    "        valid_steps = 0\n",
    "        \n",
    "        for step, batch in enumerate(train_loader):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            try:\n",
    "                with torch.amp.autocast('cuda', dtype=torch.float32):\n",
    "                    policy_chosen_outputs = policy_model(\n",
    "                        input_ids=batch['preferred_input_ids'],\n",
    "                        attention_mask=batch['preferred_attention_mask']\n",
    "                    )\n",
    "                    policy_rejected_outputs = policy_model(\n",
    "                        input_ids=batch['rejected_input_ids'],\n",
    "                        attention_mask=batch['rejected_attention_mask']\n",
    "                    )\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        ref_chosen_outputs = reference_model(\n",
    "                            input_ids=batch['preferred_input_ids'],\n",
    "                            attention_mask=batch['preferred_attention_mask']\n",
    "                        )\n",
    "                        ref_rejected_outputs = reference_model(\n",
    "                            input_ids=batch['rejected_input_ids'],\n",
    "                            attention_mask=batch['rejected_attention_mask']\n",
    "                        )\n",
    "                    \n",
    "                    loss = compute_dpo_loss(\n",
    "                        policy_chosen_outputs.logits,\n",
    "                        policy_rejected_outputs.logits,\n",
    "                        ref_chosen_outputs.logits,\n",
    "                        ref_rejected_outputs.logits,\n",
    "                        beta=beta\n",
    "                    )\n",
    "                    \n",
    "                    if not torch.isnan(loss) and not torch.isinf(loss):\n",
    "                        scaler.scale(loss).backward()\n",
    "                        \n",
    "                        # Gradient accumulation logic\n",
    "                        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                            scaler.unscale_(optimizer)\n",
    "                            torch.nn.utils.clip_grad_norm_(policy_model.parameters(), max_norm=1.0)\n",
    "                            scaler.step(optimizer)\n",
    "                            scaler.update()\n",
    "                            scheduler.step()\n",
    "                            optimizer.zero_grad()\n",
    "                        \n",
    "                        total_loss += loss.item()\n",
    "                        valid_steps += 1\n",
    "                    \n",
    "                    if step % 10 == 0:\n",
    "                        avg_loss = total_loss / max(valid_steps, 1)\n",
    "                        print(f\"[Epoch {epoch+1}/{num_epochs} | Step {step}/{len(train_loader)}] - Loss: {avg_loss:.4f}\")\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error in batch {step}: {str(e)}\")\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        if valid_steps > 0:\n",
    "            avg_train_loss = total_loss / valid_steps\n",
    "            val_loss = evaluate_model_dpo(policy_model, reference_model, val_loader, device, beta)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Avg Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_state = {k: v.cpu() for k, v in policy_model.state_dict().items() if isinstance(v, torch.Tensor)}\n",
    "    \n",
    "    return best_model_state\n",
    "\n",
    "def evaluate_model_dpo(policy_model, reference_model, val_loader, device, beta):\n",
    "   \n",
    "    policy_model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            with torch.amp.autocast('cuda', dtype=torch.float32):\n",
    "                policy_chosen_outputs = policy_model(\n",
    "                    input_ids=batch['preferred_input_ids'],\n",
    "                    attention_mask=batch['preferred_attention_mask']\n",
    "                )\n",
    "                policy_rejected_outputs = policy_model(\n",
    "                    input_ids=batch['rejected_input_ids'],\n",
    "                    attention_mask=batch['rejected_attention_mask']\n",
    "                )\n",
    "                \n",
    "                ref_chosen_outputs = reference_model(\n",
    "                    input_ids=batch['preferred_input_ids'],\n",
    "                    attention_mask=batch['preferred_attention_mask']\n",
    "                )\n",
    "                ref_rejected_outputs = reference_model(\n",
    "                    input_ids=batch['rejected_input_ids'],\n",
    "                    attention_mask=batch['rejected_attention_mask']\n",
    "                )\n",
    "                \n",
    "                loss = compute_dpo_loss(\n",
    "                    policy_chosen_outputs.logits,\n",
    "                    policy_rejected_outputs.logits,\n",
    "                    ref_chosen_outputs.logits,\n",
    "                    ref_rejected_outputs.logits,\n",
    "                    beta=beta\n",
    "                )\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "def main():\n",
    "\n",
    "    login(token=\"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\")\n",
    "    device = setup_environment()\n",
    "    model_name =  \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "    data_path = os.path.expanduser(\"~/Downloads/Tune/FineTune/newdata_cleaned.csv\")\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(f\"File not found: {data_path}\")\n",
    "\n",
    "    policy_model, tokenizer = setup_model_and_tokenizer(model_name, device)\n",
    "    reference_model, _ = setup_model_and_tokenizer(model_name, device)\n",
    "    \n",
    "\n",
    "    emails_df = pd.read_csv(data_path)\n",
    "    emails_df['sender'] = emails_df['sender'].astype(str).apply(clean_text)\n",
    "    emails_df['subject'] = emails_df['subject'].astype(str).apply(clean_text)\n",
    "    emails_df['body'] = emails_df['body'].astype(str).apply(clean_text)\n",
    "\n",
    "    train_df, val_df = train_test_split(emails_df, test_size=0.2, stratify=emails_df['label'], random_state=42)\n",
    "\n",
    "  \n",
    "    train_dataset = PreferenceEmailDataset(train_df, tokenizer, max_length=512)\n",
    "    val_dataset = PreferenceEmailDataset(val_df, tokenizer, max_length=512)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # Setup optimization\n",
    "    optimizer = torch.optim.AdamW(policy_model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "    num_epochs = 8\n",
    "    num_training_steps = len(train_loader) * num_epochs\n",
    "    num_warmup_steps = num_training_steps // 20\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "\n",
    "    best_model_state = train_model_dpo(\n",
    "        policy_model,\n",
    "        reference_model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        device,\n",
    "        num_epochs=num_epochs,\n",
    "        beta=0.2\n",
    "    )\n",
    "\n",
    "   \n",
    "    output_dir = os.path.expanduser(\"~/Downloads/Tune/FineTune/dpo_DistillDeepSeek\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    policy_model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "    config = {\n",
    "        \"model_name\": model_name,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"batch_size\": 8,\n",
    "        \"max_length\": 512,\n",
    "        \"warmup_steps\": num_warmup_steps,\n",
    "        \"total_steps\": num_training_steps,\n",
    "        \"device\": str(device),\n",
    "        \"beta\": 0.2\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"training_config.json\"), \"w\") as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbda425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
